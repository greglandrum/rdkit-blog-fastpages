{
  
    
        "post0": {
            "title": "Dealing with multiconformer SD files",
            "content": "A recurring question is how to save and share multi-conformer molecules. The easiest (and fastest) way to do this in the RDKit is to just pickle the molecules. It&#39;s not significantly more difficult to use rdMolInterchange.MolToJSON() to serialize the molecules as JSON. Neither of these methods work if you want to work with other tools, so we&#39;re frequently stuck with using something like SD files. . The topic came up in the lab today, so I figured I&#39;d do a blog post looking at how to create and work with multi-conformer SD files as well as multi-molecule, multi-conformer SD files with the RDKit. Memo to myself: some of this should probably also end up in the Cookbook. . from rdkit import Chem from rdkit.Chem import Draw from rdkit.Chem import rdDepictor rdDepictor.SetPreferCoordGen(True) import rdkit print(rdkit.__version__) . 2022.03.5 . Start by generating conformers for doravirine, lenalidomide, and mutanobactin: . dorav = Chem.MolFromSmiles(&#39;Cn1c(n[nH]c1=O)Cn2ccc(c(c2=O)Oc3cc(cc(c3)Cl)C#N)C(F)(F)F&#39;) lenal = Chem.MolFromSmiles(&#39;O=C1NC(=O)CCC1N3C(=O)c2cccc(c2C3)N&#39;) mutanob = Chem.MolFromSmiles(&#39;CCCCCCCCCC(=O)[C@@H]1[C@@H]2CNC(=O)[C@H](CS2)NC(=O)[C@@H](NC(=O)[C@@H]3CCCN3C(=O)[C@H](NC(=O)[C@@H](NC1=O)CC(C)C)C)C(C)C&#39;) Draw.MolsToGridImage([dorav,lenal,mutanob],subImgSize=(300,250)) . from rdkit.Chem import rdDistGeom ps = rdDistGeom.ETKDGv3() ps.randomSeed = 0xf00d ps.numThreads = 4 ps.pruneRmsThresh = 0.5 dorav = Chem.AddHs(dorav) lenal = Chem.AddHs(lenal) mutanob = Chem.AddHs(mutanob) d_cids = rdDistGeom.EmbedMultipleConfs(dorav,200,ps) l_cids = rdDistGeom.EmbedMultipleConfs(lenal,200,ps) m_cids = rdDistGeom.EmbedMultipleConfs(mutanob,200,ps) print(dorav.GetNumConformers(),lenal.GetNumConformers(),mutanob.GetNumConformers()) . 58 7 200 . Now let&#39;s start with a digression and quickly demo the two easy ways of storing and retrieving this multi-conformer molecule: pickling and using JSON: . import pickle pkl = pickle.dumps(dorav) nmol = pickle.loads(pkl) nmol.GetNumConformers() . 58 . from rdkit.Chem import rdMolInterchange mjs = rdMolInterchange.MolToJSON(dorav) nmol = rdMolInterchange.JSONToMols(mjs)[0] nmol.GetNumConformers() . 58 . Just out of curiosity let&#39;s see how long those take: . %timeit pickle.dumps(dorav) . 162 µs ± 1.33 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each) . %timeit pickle.loads(pkl) . 175 µs ± 1.44 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each) . %timeit rdMolInterchange.MolToJSON(dorav) . 646 µs ± 12.7 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each) . %timeit rdMolInterchange.JSONToMols(mjs)[0] . 252 µs ± 3.5 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each) . Write those to an SDF &quot;file&quot; . from io import StringIO sio = StringIO() w = Chem.SDWriter(sio) for cid in d_cids: w.write(dorav,confId=cid) w.flush() sdf = sio.getvalue() . sdf[:100] . &#39; n RDKit 3D n n 40 42 0 0 0 0 0 0 0 0999 V2000 n -3.5730 -0.0689 0.9965 C &#39; . from io import BytesIO bio = BytesIO(sdf.encode()) suppl = Chem.ForwardSDMolSupplier(bio) ref = next(suppl) for mol in suppl: ref.AddConformer(mol.GetConformer(),assignId=True) print(ref.GetNumConformers()) . 58 . Again: how long does this take? . %timeit sio=StringIO();w=Chem.SDWriter(sio);[w.write(dorav,confId=cid) for cid in d_cids];w.flush();sdf=sio.getvalue() . 9.85 ms ± 213 µs per loop (mean ± std. dev. of 7 runs, 100 loops each) . %timeit bio=BytesIO(sdf.encode());suppl=Chem.ForwardSDMolSupplier(bio);ref=next(suppl);[ref.AddConformer(m.GetConformer(),assignId=True) for m in suppl] . 13.1 ms ± 250 µs per loop (mean ± std. dev. of 7 runs, 100 loops each) . Ok, that was pretty easy. What about handling SDFs which contain multiple conformers of more than one molecule? . Start by creating an SDF with all conformers of all three molecules: . from io import StringIO sio = StringIO() w = Chem.SDWriter(sio) mol = Chem.Mol(dorav) mol.SetProp(&#39;_Name&#39;,&#39;doravirine&#39;) for cid in d_cids: w.write(mol,confId=cid) mol = Chem.Mol(lenal) mol.SetProp(&#39;_Name&#39;,&#39;lenalidomide&#39;) for cid in l_cids: w.write(mol,confId=cid) mol = Chem.Mol(mutanob) mol.SetProp(&#39;_Name&#39;,&#39;mutanobactin&#39;) for cid in m_cids: w.write(mol,confId=cid) w.flush() multimol_sdf = sio.getvalue() . And here&#39;s a function to return the molecules from a multi-molecule, multi-conformer supplier: . def mols_from_multimol_multiconf_supplier(supplier,propertyName=&#39;_Name&#39;): mol = None for itm in supplier: if itm is None: continue if mol is None: mol = itm refVal = mol.GetProp(propertyName) continue pVal = itm.GetProp(propertyName) if pVal == refVal: mol.AddConformer(itm.GetConformer(),assignId=True) else: # we&#39;re done with the last molecule, so let&#39;s restart the next one res = mol mol = itm refVal = pVal yield res yield mol . Now try that out: . from io import BytesIO bio = BytesIO(multimol_sdf.encode()) suppl = Chem.ForwardSDMolSupplier(bio) ms = [x for x in mols_from_multimol_multiconf_supplier(suppl)] print([m.GetNumConformers() for m in ms]) . [58, 7, 200] . By default the function uses the molecule names, but we can use other property names if we want: . from io import StringIO sio = StringIO() w = Chem.SDWriter(sio) mol = Chem.Mol(dorav) mol.SetProp(&#39;molecule_id&#39;,&#39;doravirine&#39;) for cid in d_cids: w.write(mol,confId=cid) mol = Chem.Mol(lenal) mol.SetProp(&#39;molecule_id&#39;,&#39;lenalidomide&#39;) for cid in l_cids: w.write(mol,confId=cid) mol = Chem.Mol(mutanob) mol.SetProp(&#39;molecule_id&#39;,&#39;mutanobactin&#39;) for cid in m_cids: w.write(mol,confId=cid) w.flush() multimol_sdf = sio.getvalue() bio = BytesIO(multimol_sdf.encode()) suppl = Chem.ForwardSDMolSupplier(bio) ms = [x for x in mols_from_multimol_multiconf_supplier(suppl,propertyName=&#39;molecule_id&#39;)] print([m.GetNumConformers() for m in ms]) . [58, 7, 200] .",
            "url": "https://greglandrum.github.io/rdkit-blog/3d/conformers/tutorial/2022/10/28/dealing-with-multiconformer-SD-files.html",
            "relUrl": "/3d/conformers/tutorial/2022/10/28/dealing-with-multiconformer-SD-files.html",
            "date": " • Oct 28, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Optimizing conformer generation parameters",
            "content": "Whether it&#39;s making it go faster or producing better results, we&#39;re always on the lookout for ways to improve the RDKit&#39;s conformer generator. Earlier this year I spent some time using a profiler to look in detail at where the code spends its time and saw that a lot of time is spent in optimizing structures using the so-called &quot;distance geometry forcefield&quot; (see the documentation for more details about conformer generation). Directly changing the optimization code is one of those daunting tasks which is only to be undertaken when one has a lot of time available, so I wasn&#39;t particularly enthusiastic about that. However, while looking at the code I realized that the behavior of the optimizer is controlled by a number of parameters which have rather arbitrary values. Given that I know we never really tried to systematically find the best values for these parameters and that they definitely can have an impact on how quickly the optimizations converge (as well as how well converged they are), it seemed like adjusting these would be a logical place to try and improve things. . Fortunately, we had a student, Thibault Kl&auml;y, starting a semester project in the group who was willing to take on this project. This post has a brief description of what Thibault did and an exploration of the key results from his project. . TL;DR Thibault found that increasing one of the force field convergence parameters (optimizerForceTol) from its default value of 0.001 to 0.0135 reduced the average run time of conformer generation by around 20% for the &gt;4000 molecules in the Platinum set. This improvement in run time came without a significant decrease in the quality of the conformers, as measured by how close we get to the crystal conformer. This will be the default value for optimizerForceTol starting in the 2022.09 release, but you can already change the value yourself, see below. . Finding the best parameters . At first I hoped that we&#39;d be able to adjust the parameters while only making small changes to the conformers generated... this turned out to be competely unrealistic, so we decided to evaluate the quality of the results the same way we validated the results in the ETKDG paper: by looking at how well we reproduce crystal conformers. Since using the CSD compounds we used in the original paper was complicated (from a licensing perspective), we just used the PDB structures from the Platinum set. We filtered this down to only include molecules with less than 50 heavy atoms. . Thibault explored changing the following parameters: . optimizerForceTol | basinThresh | ERROR_TOL | MOVETOL | FORCETOL | TOLX | . The first two of those can be modified by the user; the last four require recompiling the RDKit. . After running a lot of calculations Thibault found that the only parameters which really yielded a significant improvement in runtime performance were optimizerForceTol and basinThresh, that optimizerForceTol gave larger improvements, and that the results were not cumulative (so once optimizerForceTol was set to an optimal value changing basinThresh no longer really improved things). . The rest of this post repeats some of Thibault&#39;s analysis to show the impact of setting optimizerForceTol to the new recommended value. . from rdkit import Chem from rdkit.Chem.Draw import IPythonConsole IPythonConsole.ipython_3d = True from rdkit.Chem import rdDistGeom from rdkit.Chem import TorsionFingerprints from rdkit.Chem import AllChem %matplotlib inline import pylab as plt plt.style.use(&#39;tableau-colorblind10&#39;) plt.rcParams[&#39;font.size&#39;] = &#39;16&#39; import numpy as np import rdkit print(rdkit.__version__) . 2022.03.5 . Start by generating conformers using the original and updated values of optimizerForceTol. This takes quite a while to run: . import gzip import time import pickle etkdg = rdDistGeom.ETKDGv3() etkdg.randomSeed = 0xa700f etkdg.verbose = False etkdg.numThreads = 8 conformer_num=100 # 0.001 was the default value of optimizerForceTol up to and including v2022.03 timings = [] for forceTol in (&#39;0.001&#39;, &#39;0.0135&#39;): print( f&#39;&#39;&#39; forceTol: {forceTol} &#39;&#39;&#39;) inf = gzip.open(&#39;../data/platinum_dataset_2017_01.sdf.gz&#39;) outf = gzip.open(f&#39;./results/platinum_forcetol_{forceTol}.100confs.pkl.gz&#39;,&#39;wb+&#39;) etkdg.optimizerForceTol = float(forceTol) lts = [] for i,m in enumerate(Chem.ForwardSDMolSupplier(inf,removeHs=False)): if not m: continue if m.GetNumHeavyAtoms()&gt;50: continue Chem.AssignStereochemistryFrom3D(m) start = time.time() conformation_ids = rdDistGeom.EmbedMultipleConfs(m, numConfs=conformer_num, params=etkdg) lts.append(time.time()-start) if not (i+1)%1000: print(f&quot;***** done {i+1}&quot;) pickle.dump(m,outf) timings.append(lts) with open(&#39;./results/optmizer_force_tol_timings.pkl&#39;,&#39;wb+&#39;) as outf: pickle.dump(timings,outf) . Repeat that exercise for random coordinate embedding, this one takes even longer. . import gzip import time import pickle etkdg = rdDistGeom.ETKDGv3() etkdg.randomSeed = 0xa700f etkdg.verbose = False etkdg.numThreads = 8 etkdg.useRandomCoords = True conformer_num=100 # 0.001 was the default value of optimizerForceTol up to and including v2022.03 timings = [] for forceTol in (&#39;0.001&#39;, &#39;0.0135&#39;): print( f&#39;&#39;&#39; forceTol: {forceTol} &#39;&#39;&#39;) inf = gzip.open(&#39;../data/platinum_dataset_2017_01.sdf.gz&#39;) outf = gzip.open(f&#39;./results/platinum_forcetol_{forceTol}.random_coords.100confs.pkl.gz&#39;,&#39;wb+&#39;) etkdg.optimizerForceTol = float(forceTol) lts = [] for i,m in enumerate(Chem.ForwardSDMolSupplier(inf,removeHs=False)): if not m: continue if m.GetNumHeavyAtoms()&gt;50: continue Chem.AssignStereochemistryFrom3D(m) start = time.time() conformation_ids = rdDistGeom.EmbedMultipleConfs(m, numConfs=conformer_num, params=etkdg) lts.append(time.time()-start) if not (i+1)%1000: print(f&quot;***** done {i+1}&quot;) pickle.dump(m,outf) timings.append(lts) with open(&#39;./results/optmizer_force_tol_timings.random_coords.pkl&#39;,&#39;wb+&#39;) as outf: pickle.dump(timings,outf) . Standard embedding . with open(&#39;./results/optmizer_force_tol_timings.pkl&#39;,&#39;rb&#39;) as inf: timings = pickle.load(inf) base_runtimes,mod_runtimes = timings base_runtimes = np.array(base_runtimes) mod_runtimes = np.array(mod_runtimes) . Look at the impact on run time: . plt.rcParams[&#39;figure.figsize&#39;] = (7,7) plt.scatter(base_runtimes,mod_runtimes) lim = max(base_runtimes+mod_runtimes) plt.plot((0,lim),(0,lim),&#39;k&#39;) plt.xscale(&#39;log&#39;) plt.yscale(&#39;log&#39;) plt.xlabel(&#39;optimizerForceTol=0.001&#39;) plt.ylabel(&#39;optimizerForceTol=0.0135&#39;) plt.title(&#39;platinum 100 confs/mol&#39;); . It&#39;s clear that most of those points are below the diagonal, indicating that using the new value of optimizerForceTol results in shorter run times. . Do a histogram of the differences in run time: . pcts = (base_runtimes - mod_runtimes) / base_runtimes plt.hist(pcts,bins=40); plt.xlabel(&#39;fractional runtime decrease&#39;); plt.title(&#39;optimizerForceTol 0.001 vs 0.0135&#39;); . There&#39;s an extreme outlier there, remove it so that we can actually see something: . plt.hist([x for x in pcts if x&gt;-0.5],bins=40); plt.xlabel(&#39;fractional runtime decrease&#39;); plt.title(&#39;optimizerForceTol 0.001 vs 0.0135&#39;); . The fact that the histogram is clearly shifted to the right indicates that using optimizerForceTol=0.0135 speeds things up for most of the molecules. . Now lets look at the fraction of the compounds appearing in various $ Delta$ time bins: . bins = [-10,-.1,-0.05,0,0.05,0.1,0.15,0.2,0.25,0.3,10] nPts = len(pcts) for i in range(len(bins)-1): frac = len([x for x in pcts if x&gt;bins[i] and x&lt;=bins[i+1]])/nPts print(f&#39;{bins[i]: .2f} - {bins[i+1]: .2f}: {frac: .3f}&#39;) . -10.00 - -0.10: 0.017 -0.10 - -0.05: 0.009 -0.05 - 0.00: 0.014 0.00 - 0.05: 0.036 0.05 - 0.10: 0.095 0.10 - 0.15: 0.194 0.15 - 0.20: 0.263 0.20 - 0.25: 0.206 0.25 - 0.30: 0.112 0.30 - 10.00: 0.054 . And a set of quantiles for the $ Delta$ time values: . for q in [0.2,0.4,0.5,0.6,0.7,0.8,0.9]: print(f&#39;{q} {np.quantile(pcts,q):.3f}&#39;) . 0.2 0.109 0.4 0.157 0.5 0.175 0.6 0.195 0.7 0.215 0.8 0.241 0.9 0.274 . Ok, so we see an overall improvement of about 20%. . The outliers - compounds where things got slower with the change - are also interesting to look at, but that&#39;s a topic for a possible future post. . Next question: how much do the conformers change? . We start by doing a direct comparison of the conformers to each other. . import gzip import pickle from rdkit.Chem import AllChem rms_by_mol = [] with gzip.open(&#39;./results/platinum_forcetol_0.001.100confs.pkl.gz&#39;) as basef, gzip.open(&#39;./results/platinum_forcetol_0.0135.100confs.pkl.gz&#39;) as modf: while 1: try: m1 = Chem.RemoveHs(pickle.load(basef)) m2 = Chem.RemoveHs(pickle.load(modf)) except EOFError: break m_res = [] for conf1,conf2 in zip(m1.GetConformers(),m2.GetConformers()): rms = AllChem.GetBestRMS(m1,m2,conf1.GetId(),conf2.GetId()) m_res.append(rms) rms_by_mol.append(m_res) . all_rms = [] for t in rms_by_mol: all_rms.extend(t) plt.rcParams[&#39;figure.figsize&#39;] = (8,6) plt.hist(all_rms,bins=50); plt.xlabel(&#39;RMSD&#39;) plt.title(&#39;platinum 100 confs/mol, optimizerForceTol 0.001 vs 0.0135&#39;); . So there are clear differences between the conformers generated using the two different force tolerances. . Do they matter? Let&#39;s look at our ability to reproduce crystal conformers to see. . Comparison to crystal conformers . Is there an impact on our ability to find the crystal conformer? . RMSD . inf = gzip.open(&#39;../data/platinum_dataset_2017_01.sdf.gz&#39;) base_xtal_rms = [] mod_xtal_rms = [] with gzip.open(&#39;./results/platinum_forcetol_0.001.100confs.pkl.gz&#39;) as basef, gzip.open(&#39;./results/platinum_forcetol_0.0135.100confs.pkl.gz&#39;) as modf: for i,m in enumerate(Chem.ForwardSDMolSupplier(inf,removeHs=False)): if not m: continue if m.GetNumHeavyAtoms()&gt;50: continue m = Chem.RemoveHs(m) try: m1 = Chem.RemoveHs(pickle.load(basef)) m2 = Chem.RemoveHs(pickle.load(modf)) except EOFError: break base_best = 1000 mod_best = 1000 for conf1,conf2 in zip(m1.GetConformers(),m2.GetConformers()): rms = AllChem.GetBestRMS(m1,m,conf1.GetId()) base_best = min(base_best,rms) rms = AllChem.GetBestRMS(m2,m,conf2.GetId()) mod_best = min(mod_best,rms) if base_best&lt;1000 and mod_best&lt;1000: base_xtal_rms.append(base_best) mod_xtal_rms.append(mod_best) . thresh = 0.5 plt.rcParams[&#39;figure.figsize&#39;]=(7,7) plt.scatter(base_xtal_rms,mod_xtal_rms); lim = max(base_xtal_rms+mod_xtal_rms) plt.plot((0,lim),(0,lim),&#39;k&#39;) plt.plot((0,lim),(thresh,lim+thresh),ls=&#39;dashed&#39;,color=&#39;grey&#39;) plt.plot((thresh,lim),(0,lim-thresh),ls=&#39;dashed&#39;,color=&#39;grey&#39;); plt.xlabel(&#39;optimizerForceTol=0.001&#39;); plt.ylabel(&#39;optimizerForceTol=0.0135&#39;); plt.title(&#39;platinum 100 confs/mol, RMSD to xtal conf&#39;); . thresh = 0.5 plt.rcParams[&#39;figure.figsize&#39;]=(7,7) plt.hexbin(base_xtal_rms,mod_xtal_rms,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); outside = [(x,y) for x,y in zip(base_xtal_rms,mod_xtal_rms) if abs(x-y)&gt;thresh] plt.scatter([x for x,y in outside],[y for x,y in outside],marker=&#39;.&#39;) lim = max(base_xtal_rms+mod_xtal_rms) plt.plot((0,lim),(0,lim),&#39;k&#39;) plt.plot((0,lim),(thresh,lim+thresh),ls=&#39;dashed&#39;,color=&#39;grey&#39;) plt.plot((thresh,lim),(0,lim-thresh),ls=&#39;dashed&#39;,color=&#39;grey&#39;); plt.xlabel(&#39;optimizerForceTol=0.001&#39;); plt.ylabel(&#39;optimizerForceTol=0.0135&#39;); plt.title(&#39;platinum 100 confs/mol, RMSD to xtal conf&#39;); . Based on these plots it looks like we haven&#39;t negatively impacted our ability to reproduce crystal conformers. . Let&#39;s look at the $ Delta$ RMSD differences directly: . d = np.array(mod_xtal_rms)-np.array(base_xtal_rms) plt.hist(d,bins=20); plt.xlabel(&#39;RMSD(forceTol=0.0135)-RMSD(forceTol=0.001)&#39;) plt.title(&#39;platinum 100 confs/mol&#39;); . Zoom in: . d = np.array(mod_xtal_rms)-np.array(base_xtal_rms) plt.hist([x for x in d if abs(x)&lt;=0.75],bins=20); plt.xlabel(&#39;RMSD(forceTol=0.0135)-RMSD(forceTol=0.001)&#39;) plt.title(&#39;platinum 100 confs/mol&#39;); . There really aren&#39;t significant changes here. . TFD . RMSD, though familiar and intuitive, has some well-documented shortcomings. Torsion Fingerprint Differences (TFDs) were developed as an alternative metric for comparing structures which is less susceptible to some of these problems. . We used TFDs in the original ETKDG paper, so let&#39;s try them here too . # the method we need, so do it directly here: def GetBestTFDBetweenMolecules(mol1, mol2, confId1=-1, useWeights=True, maxDev=&#39;equal&#39;, symmRadius=2, ignoreColinearBonds=True): &quot;&quot;&quot; Wrapper to calculate the TFD between two molecules. All conformers of mol2 will be compared against a single conformer of mol1 and the lowest TFD returned Important: The two molecules must be instances of the same molecule Arguments: - mol1: first instance of the molecule of interest - mol2: second instance the molecule of interest - confId1: conformer index for mol1 (default: first conformer) - useWeights: flag for using torsion weights in the TFD calculation - maxDev: maximal deviation used for normalization &#39;equal&#39;: all torsions are normalized using 180.0 (default) &#39;spec&#39;: each torsion is normalized using its specific maximal deviation as given in the paper - symmRadius: radius used for calculating the atom invariants (default: 2) - ignoreColinearBonds: if True (default), single bonds adjacent to triple bonds are ignored if False, alternative not-covalently bound atoms are used to define the torsion Return: TFD value &quot;&quot;&quot; if (Chem.MolToSmiles(mol1) != Chem.MolToSmiles(mol2)): raise ValueError(&quot;The two molecules must be instances of the same molecule!&quot;) mol2 = TorsionFingerprints._getSameAtomOrder(mol1, mol2) tl, tlr = TorsionFingerprints.CalculateTorsionLists(mol1, maxDev=maxDev, symmRadius=symmRadius, ignoreColinearBonds=ignoreColinearBonds) # first molecule torsion1 = TorsionFingerprints.CalculateTorsionAngles(mol1, tl, tlr, confId=confId1) if useWeights: weights = TorsionFingerprints.CalculateTorsionWeights(mol1, ignoreColinearBonds=ignoreColinearBonds) best = 1e8 for conf in mol2.GetConformers(): # second molecule torsion2 = TorsionFingerprints.CalculateTorsionAngles(mol2, tl, tlr, confId=conf.GetId()) if useWeights: tfd = TorsionFingerprints.CalculateTFD(torsion1, torsion2, weights=weights) else: tfd = TorsionFingerprints.CalculateTFD(torsion1, torsion2) best = min(best,tfd) return best . inf = gzip.open(&#39;../data/platinum_dataset_2017_01.sdf.gz&#39;) base_xtal_tfd = [] mod_xtal_tfd = [] with gzip.open(&#39;./results/platinum_forcetol_0.001.100confs.pkl.gz&#39;) as basef, gzip.open(&#39;./results/platinum_forcetol_0.0135.100confs.pkl.gz&#39;) as modf: for i,m in enumerate(Chem.ForwardSDMolSupplier(inf,removeHs=False)): if not m: continue if m.GetNumHeavyAtoms()&gt;50: continue m = Chem.RemoveHs(m) try: m1 = Chem.RemoveHs(pickle.load(basef)) m2 = Chem.RemoveHs(pickle.load(modf)) except EOFError: break base_best = 1000 mod_best = 1000 base_best = GetBestTFDBetweenMolecules(m,m1) mod_best = GetBestTFDBetweenMolecules(m,m2) if base_best&lt;1000 and mod_best&lt;1000: base_xtal_tfd.append(base_best) mod_xtal_tfd.append(mod_best) if not (i+1)%500: print(f&quot;Done {i+1}&quot;) . Done 500 Done 1000 Done 1500 Done 2000 Done 2500 Done 3000 Done 3500 Done 4000 Done 4500 . thresh = 0.2 plt.rcParams[&#39;figure.figsize&#39;]=(7,7) plt.scatter(base_xtal_tfd,mod_xtal_tfd); lim = max(base_xtal_tfd+mod_xtal_tfd) plt.plot((0,lim),(0,lim),&#39;k&#39;) plt.plot((0,lim),(thresh,lim+thresh),ls=&#39;dashed&#39;,color=&#39;grey&#39;) plt.plot((thresh,lim),(0,lim-thresh),ls=&#39;dashed&#39;,color=&#39;grey&#39;); plt.xlabel(&#39;optimizerForceTol=0.001&#39;); plt.ylabel(&#39;optimizerForceTol=0.0135&#39;); plt.title(&#39;platinum 100 confs/mol, TFD to xtal conf&#39;); . thresh = 0.2 plt.rcParams[&#39;figure.figsize&#39;]=(7,7) plt.hexbin(base_xtal_tfd,mod_xtal_tfd,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); lim = max(base_xtal_tfd+mod_xtal_tfd) plt.plot((0,lim),(0,lim),&#39;k&#39;) plt.plot((0,lim),(thresh,lim+thresh),ls=&#39;dashed&#39;,color=&#39;grey&#39;) plt.plot((thresh,lim),(0,lim-thresh),ls=&#39;dashed&#39;,color=&#39;grey&#39;); plt.xlabel(&#39;optimizerForceTol=0.001&#39;); plt.ylabel(&#39;optimizerForceTol=0.0135&#39;); plt.title(&#39;platinum 100 confs/mol, TFD to xtal conf&#39;); . Look at the histogram of the changes in TFD between the two methods . d = np.array(mod_xtal_tfd)-np.array(base_xtal_tfd) plt.hist(d,bins=20); plt.xlabel(&#39;TFD(forceTol=0.0135)-TFD(forceTol=0.001)&#39;) plt.title(&#39;platinum 100 confs/mol&#39;); . Zoom in: . d = np.array(mod_xtal_tfd)-np.array(base_xtal_tfd) plt.hist([x for x in d if abs(x)&lt;0.1],bins=20); plt.xlabel(&#39;TFD(forceTol=0.0135)-TFD(forceTol=0.001)&#39;) plt.title(&#39;platinum 100 confs/mol&#39;); . Conclusion: the updated force field parameters don&#39;t have a much of an impact at all on our ability to reproduce crystal conformers as measured by TFD. . Repeat the analysis for random-coordinate embedding . The random-coordinate embedding scheme is more robust than standard embedding, but it is (as implemented in the RDKit) also slower. Let&#39;s see how much it is affected by the modified optimizerForceTol . import pickle with open(&#39;./results/optmizer_force_tol_timings.random_coords.pkl&#39;,&#39;rb&#39;) as inf: timings = pickle.load(inf) base_runtimes,mod_runtimes = timings base_runtimes = np.array(base_runtimes) mod_runtimes = np.array(mod_runtimes) . plt.rcParams[&#39;figure.figsize&#39;] = (7,7) plt.scatter(base_runtimes,mod_runtimes) lim = max(base_runtimes+mod_runtimes) plt.plot((0,lim),(0,lim),&#39;k&#39;) plt.xscale(&#39;log&#39;) plt.yscale(&#39;log&#39;) plt.xlabel(&#39;optimizerForceTol=0.001&#39;) plt.ylabel(&#39;optimizerForceTol=0.0135&#39;) plt.title(&#39;platinum 100 confs/mol&#39;); . pcts = (base_runtimes - mod_runtimes) / base_runtimes plt.hist(pcts,bins=40); plt.xlabel(&#39;fractional runtime decrease&#39;); plt.title(&#39;optimizerForceTol 0.001 vs 0.0135&#39;); . plt.hist([x for x in pcts if x&gt;-0.5],bins=40); plt.xlabel(&#39;fractional runtime decrease&#39;); plt.title(&#39;optimizerForceTol 0.001 vs 0.0135&#39;); . There are a small number of compounds here where things get worse, but it looks like there is an overall improvement similar to what we saw before. . Look at the bins and quantiles to quantify that: . bins = [-10,-.1,-0.05,0,0.05,0.1,0.15,0.2,0.25,0.3,10] nPts = len(pcts) for i in range(len(bins)-1): frac = len([x for x in pcts if x&gt;bins[i] and x&lt;=bins[i+1]])/nPts print(f&#39;{bins[i]: .2f} - {bins[i+1]: .2f}: {frac: .3f}&#39;) . -10.00 - -0.10: 0.040 -0.10 - -0.05: 0.010 -0.05 - 0.00: 0.019 0.00 - 0.05: 0.034 0.05 - 0.10: 0.057 0.10 - 0.15: 0.115 0.15 - 0.20: 0.210 0.20 - 0.25: 0.261 0.25 - 0.30: 0.185 0.30 - 10.00: 0.069 . for q in [0.2,0.4,0.5,0.6,0.7,0.8,0.9]: print(f&#39;{q} {np.quantile(pcts,q):.3f}&#39;) . 0.2 0.121 0.4 0.183 0.5 0.204 0.6 0.223 0.7 0.241 0.8 0.261 0.9 0.288 . So the impact here is actually a bit larger than for standard embedding. . Comparing to crystal structures . RMSD . import gzip inf = gzip.open(&#39;../data/platinum_dataset_2017_01.sdf.gz&#39;) base_xtal_rms = [] mod_xtal_rms = [] with gzip.open(&#39;./results/platinum_forcetol_0.001.random_coords.100confs.pkl.gz&#39;) as basef, gzip.open(&#39;./results/platinum_forcetol_0.0135.random_coords.100confs.pkl.gz&#39;) as modf: for i,m in enumerate(Chem.ForwardSDMolSupplier(inf,removeHs=False)): if not m: continue if m.GetNumHeavyAtoms()&gt;50: continue m = Chem.RemoveHs(m) try: m1 = Chem.RemoveHs(pickle.load(basef)) m2 = Chem.RemoveHs(pickle.load(modf)) except EOFError: break base_best = 1000 mod_best = 1000 for conf1,conf2 in zip(m1.GetConformers(),m2.GetConformers()): rms = AllChem.GetBestRMS(m1,m,conf1.GetId()) base_best = min(base_best,rms) rms = AllChem.GetBestRMS(m2,m,conf2.GetId()) mod_best = min(mod_best,rms) if base_best&lt;1000 and mod_best&lt;1000: base_xtal_rms.append(base_best) mod_xtal_rms.append(mod_best) . thresh = 0.5 plt.rcParams[&#39;figure.figsize&#39;]=(7,7) plt.scatter(base_xtal_rms,mod_xtal_rms); lim = max(base_xtal_rms+mod_xtal_rms) plt.plot((0,lim),(0,lim),&#39;k&#39;) plt.plot((0,lim),(thresh,lim+thresh),ls=&#39;dashed&#39;,color=&#39;grey&#39;) plt.plot((thresh,lim),(0,lim-thresh),ls=&#39;dashed&#39;,color=&#39;grey&#39;); plt.xlabel(&#39;optimizerForceTol=0.001&#39;); plt.ylabel(&#39;optimizerForceTol=0.0135&#39;); plt.title(&#39;platinum 100 confs/mol, RMSD to xtal conf&#39;); . thresh = 0.5 plt.rcParams[&#39;figure.figsize&#39;]=(7,7) plt.hexbin(base_xtal_rms,mod_xtal_rms,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); outside = [(x,y) for x,y in zip(base_xtal_rms,mod_xtal_rms) if abs(x-y)&gt;thresh] plt.scatter([x for x,y in outside],[y for x,y in outside],marker=&#39;.&#39;) lim = max(base_xtal_rms+mod_xtal_rms) plt.plot((0,lim),(0,lim),&#39;k&#39;) plt.plot((0,lim),(thresh,lim+thresh),ls=&#39;dashed&#39;,color=&#39;grey&#39;) plt.plot((thresh,lim),(0,lim-thresh),ls=&#39;dashed&#39;,color=&#39;grey&#39;); plt.xlabel(&#39;optimizerForceTol=0.001&#39;); plt.ylabel(&#39;optimizerForceTol=0.0135&#39;); plt.title(&#39;platinum 100 confs/mol, RMSD to xtal conf&#39;); . Once again, it looks like we haven&#39;t negatively impacted our ability to reproduce crystal conformers in any serious way. . Let&#39;s look at the $ Delta$ RMSD differences directly: . d = np.array(mod_xtal_rms)-np.array(base_xtal_rms) plt.hist(d,bins=20); plt.xlabel(&#39;RMSD(forceTol=0.0135)-RMSD(forceTol=0.001)&#39;) plt.title(&#39;platinum 100 confs/mol&#39;); . Zoom in: . d = np.array(mod_xtal_rms)-np.array(base_xtal_rms) plt.hist([x for x in d if abs(x)&lt;=0.5],bins=20); plt.xlabel(&#39;RMSD(forceTol=0.0135)-RMSD(forceTol=0.001)&#39;) plt.title(&#39;platinum 100 confs/mol&#39;); . TFDs . inf = gzip.open(&#39;../data/platinum_dataset_2017_01.sdf.gz&#39;) base_xtal_tfd = [] mod_xtal_tfd = [] with gzip.open(&#39;./results/platinum_forcetol_0.001.random_coords.100confs.pkl.gz&#39;) as basef, gzip.open(&#39;./results/platinum_forcetol_0.0135.random_coords.100confs.pkl.gz&#39;) as modf: for i,m in enumerate(Chem.ForwardSDMolSupplier(inf,removeHs=False)): if not m: continue if m.GetNumHeavyAtoms()&gt;50: continue m = Chem.RemoveHs(m) try: m1 = Chem.RemoveHs(pickle.load(basef)) m2 = Chem.RemoveHs(pickle.load(modf)) except EOFError: break base_best = 1000 mod_best = 1000 base_best = GetBestTFDBetweenMolecules(m,m1) mod_best = GetBestTFDBetweenMolecules(m,m2) if base_best&lt;1000 and mod_best&lt;1000: base_xtal_tfd.append(base_best) mod_xtal_tfd.append(mod_best) if not (i+1)%500: print(f&quot;Done {i+1}&quot;) . Done 500 Done 1000 Done 1500 Done 2000 Done 2500 Done 3000 Done 3500 Done 4000 Done 4500 . thresh = 0.2 plt.rcParams[&#39;figure.figsize&#39;]=(7,7) plt.scatter(base_xtal_tfd,mod_xtal_tfd); lim = max(base_xtal_tfd+mod_xtal_tfd) plt.plot((0,lim),(0,lim),&#39;k&#39;) plt.plot((0,lim),(thresh,lim+thresh),ls=&#39;dashed&#39;,color=&#39;grey&#39;) plt.plot((thresh,lim),(0,lim-thresh),ls=&#39;dashed&#39;,color=&#39;grey&#39;); plt.xlabel(&#39;optimizerForceTol=0.001&#39;); plt.ylabel(&#39;optimizerForceTol=0.0135&#39;); plt.title(&#39;platinum 100 confs/mol, TFD to xtal conf&#39;); . thresh = 0.2 plt.rcParams[&#39;figure.figsize&#39;]=(7,7) plt.hexbin(base_xtal_tfd,mod_xtal_tfd,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); lim = max(base_xtal_tfd+mod_xtal_tfd) plt.plot((0,lim),(0,lim),&#39;k&#39;) plt.plot((0,lim),(thresh,lim+thresh),ls=&#39;dashed&#39;,color=&#39;grey&#39;) plt.plot((thresh,lim),(0,lim-thresh),ls=&#39;dashed&#39;,color=&#39;grey&#39;); plt.xlabel(&#39;optimizerForceTol=0.001&#39;); plt.ylabel(&#39;optimizerForceTol=0.0135&#39;); plt.title(&#39;platinum 100 confs/mol, TFD to xtal conf&#39;); . Look at the histogram of the changes in TFD between the two methods . d = np.array(mod_xtal_tfd)-np.array(base_xtal_tfd) plt.hist(d,bins=20); plt.xlabel(&#39;TFD(forceTol=0.0135)-TFD(forceTol=0.001)&#39;) plt.title(&#39;platinum 100 confs/mol&#39;); . Zoom in: . d = np.array(mod_xtal_tfd)-np.array(base_xtal_tfd) plt.hist([x for x in d if abs(x)&lt;0.1],bins=20); plt.xlabel(&#39;TFD(forceTol=0.0135)-TFD(forceTol=0.001)&#39;) plt.title(&#39;platinum 100 confs/mol&#39;); . Again, there are no major changes seen here. .",
            "url": "https://greglandrum.github.io/rdkit-blog/3d/conformers/optimization/2022/09/29/optimizing-conformer-generation-parameters.html",
            "relUrl": "/3d/conformers/optimization/2022/09/29/optimizing-conformer-generation-parameters.html",
            "date": " • Sep 29, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "3D maximum common substructure",
            "content": "One of the &quot;underdocumented&quot;, and perhaps lesser known, features of the RDKit MCS code is the ability to take atomic coordinates into account when generating the MCS. The idea here is to find the MCS between a set of 3D molecules where the distance between potential matching atoms is taken into account. . This blog post shows how to do it. . from rdkit import Chem from rdkit.Chem import rdDistGeom from rdkit.Chem import rdFMCS from rdkit.Chem import Draw from rdkit.Chem.Draw import IPythonConsole from rdkit.Chem import rdDepictor rdDepictor.SetPreferCoordGen(True) IPythonConsole.ipython_3d = True import rdkit print(rdkit.__version__) . 2022.03.3 . Let&#39;s start with an artifical example as a demo: . m1 = Chem.MolFromSmiles(&#39;c1ccccc1-c1c(C(F)(F)F)cc(-c2c(C(F)(F)F)cccn2)cc1&#39;) IPythonConsole.drawOptions.addAtomIndices = True m1 . Generate a conformer: . m1 = Chem.AddHs(m1) rdDistGeom.EmbedMolecule(m1,randomSeed=0xf00d) m1 = Chem.RemoveHs(m1) . m1 . You appear to be running in JupyterLab (or JavaScript failed to load for some other reason). You need to install the 3dmol extension: jupyter labextension install jupyterlab_3dmol . Clip out the central ring and change one of the atoms to an N . m2 = Chem.RWMol(m1) keep = [6,7,12,13,24,25] remove = set(range(m2.GetNumAtoms())).difference(keep) m2.BeginBatchEdit() for aidx in remove: m2.RemoveAtom(aidx) m2.CommitBatchEdit() m2.GetAtomWithIdx(0).SetAtomicNum(7) m2 . You appear to be running in JupyterLab (or JavaScript failed to load for some other reason). You need to install the 3dmol extension: jupyter labextension install jupyterlab_3dmol . A normal MCS will, of course, match this to the N-containing ring: . ps = rdFMCS.MCSParameters() res = rdFMCS.FindMCS([m1,m2],ps) print(res.smartsString) . [#7]1:[#6]:[#6]:[#6]:[#6]:[#6]:1 . ps = rdFMCS.MCSParameters() ps.AtomCompareParameters.MaxDistance = 0.5 res = rdFMCS.FindMCS([m1,m2],ps) print(res.smartsString) . [#6]:[#6]:[#6]:[#6]:[#6] . ps = rdFMCS.MCSParameters() ps.AtomCompareParameters.MaxDistance = 0.5 ps.AtomTyper = rdFMCS.AtomCompare.CompareAny res = rdFMCS.FindMCS([m1,m2],ps) print(res.smartsString) . [#7,#6]1:[#6]:[#6]:[#6]:[#6]:[#6]:1 . A real example . ms = [x for x in Chem.ForwardSDMolSupplier(&#39;../data/1TDU-results.sdf&#39;)] ms2d = [Chem.Mol(x) for x in ms] for m in ms2d: rdDepictor.Compute2DCoords(m) IPythonConsole.drawOptions.addAtomIndices = False Draw.MolsToGridImage(ms2d) . import py3Dmol viewer = py3Dmol.view(width=350, height=350) IPythonConsole.addMolToView(ms[0],viewer) IPythonConsole.addMolToView(ms[1],viewer) IPythonConsole.addMolToView(ms[2],viewer) viewer.zoomTo() viewer.show() . You appear to be running in JupyterLab (or JavaScript failed to load for some other reason). You need to install the 3dmol extension: jupyter labextension install jupyterlab_3dmol . ps = rdFMCS.MCSParameters() res = rdFMCS.FindMCS(ms,ps) qry = Chem.MolFromSmarts(res.smartsString) qry . matches = [x.GetSubstructMatch(qry) for x in ms2d] conf = Chem.Conformer(qry.GetNumAtoms()) for i,mi in enumerate(matches[0]): conf.SetAtomPosition(i,ms2d[0].GetConformer().GetAtomPosition(mi)) qry.AddConformer(conf) rdDepictor.SetPreferCoordGen(False) # coordgen doesn&#39;t always obey the scaffold, so switch to the RDKit coordinates for m in ms2d: rdDepictor.GenerateDepictionMatching2DStructure(m,qry) rdDepictor.SetPreferCoordGen(True) Draw.MolsToGridImage(ms2d,highlightAtomLists=matches) . ps = rdFMCS.MCSParameters() ps.AtomTyper = rdFMCS.AtomCompare.CompareAny res = rdFMCS.FindMCS(ms,ps) qry = Chem.MolFromSmarts(res.smartsString) qry . matches = [x.GetSubstructMatch(qry) for x in ms2d] conf = Chem.Conformer(qry.GetNumAtoms()) for i,mi in enumerate(matches[0]): conf.SetAtomPosition(i,ms2d[0].GetConformer().GetAtomPosition(mi)) qry.AddConformer(conf) rdDepictor.SetPreferCoordGen(False) # coordgen doesn&#39;t always obey the scaffold, so switch to the RDKit coordinates for m in ms2d: rdDepictor.GenerateDepictionMatching2DStructure(m,qry) rdDepictor.SetPreferCoordGen(True) Draw.MolsToGridImage(ms2d,highlightAtomLists=matches) . This is an example where the constrained coordinates, which only match part of a ring system, cause problems. . Both of those MCS results are matching significant parts of the molecules, but we saw that the molecules didn&#39;t actually align quite that well. . What about if we take atom coordinates into account? . ps = rdFMCS.MCSParameters() ps.AtomCompareParameters.MaxDistance = 1.0 ps.AtomTyper = rdFMCS.AtomCompare.CompareAny res = rdFMCS.FindMCS(ms,ps) qry = Chem.MolFromSmarts(res.smartsString) qry . matches = [x.GetSubstructMatch(qry) for x in ms2d] conf = Chem.Conformer(qry.GetNumAtoms()) for i,mi in enumerate(matches[0]): conf.SetAtomPosition(i,ms2d[0].GetConformer().GetAtomPosition(mi)) qry.AddConformer(conf) for m in ms2d: rdDepictor.GenerateDepictionMatching2DStructure(m,qry) Draw.MolsToGridImage(ms2d,highlightAtomLists=matches) . The MCS gave us a SMARTS which matches, but unfortunately it does not provide the matching atoms. Finding those via substructure search would be easy if we could assume that the MCS only matches each molecule once, but that&#39;s not always going to be the case. . This is actually one of those examples. . Let&#39;s look at how many times the core can match each of the molecules: . allMatches = [] for m in ms: allMatches.append(m.GetSubstructMatches(qry,uniquify=False)) allMatches . [((13, 15, 17, 16, 20, 19, 18, 21), (13, 15, 18, 19, 20, 16, 17, 21)), ((12, 13, 15, 14, 18, 17, 16, 19), (12, 13, 16, 17, 18, 14, 15, 19), (19, 18, 14, 15, 13, 16, 17, 12), (19, 18, 17, 16, 13, 15, 14, 12)), ((13, 14, 17, 18, 19, 20, 21, 22), (13, 14, 21, 20, 19, 18, 17, 22))] . Now define a function which goes through all the possible substructure matches and finds the one which satisfies the 3D distance constraints on the core: . def getAlignedSubstructMatch(ms,qry,distTol=1.0): allMatches = [] for m in ms: allMatches.append(m.GetSubstructMatches(qry,uniquify=False)) keepMatches = [] for match0 in allMatches[0]: allMatched = True for i in range(1,len(ms)): imatched = False for matchi in allMatches[i]: matched = True for i0,ii in zip(match0,matchi): dist = (ms[0].GetConformer().GetAtomPosition(i0) - ms[i].GetConformer().GetAtomPosition(ii)).Length() if dist &gt; distTol: matched = False break if matched: keepMatches.append(matchi) imatched = True break if not imatched: allMatched = False keepMatches = [] break if allMatched: keepMatches = [match0] + keepMatches break else: keepMatches = [] return keepMatches . The results for our molecules and the 3D MCS core: . keepMatches = getAlignedSubstructMatch(ms,qry) keepMatches . [(13, 15, 17, 16, 20, 19, 18, 21), (12, 13, 15, 14, 18, 17, 16, 19), (13, 14, 17, 18, 19, 20, 21, 22)] . And highlight the substructures: . Draw.MolsToGridImage(ms2d,highlightAtomLists=keepMatches) . Let&#39;s redraw the molecules in 3D and highlight the atoms involved in the MCS. It&#39;s nice to see, plus I learned some stuff about how to use py3Dmol while doing it... so that&#39;s a bonus. :-) . import py3Dmol viewer = py3Dmol.view(width=450, height=450) IPythonConsole.addMolToView(ms[0],viewer) IPythonConsole.addMolToView(ms[1],viewer) IPythonConsole.addMolToView(ms[2],viewer) for idx,clr in zip((-1,-2,-3),(&#39;redCarbon&#39;,&#39;cyanCarbon&#39;,&#39;blueCarbon&#39;)): viewer.setStyle({&#39;model&#39;:idx,}, {&#39;stick&#39;:{&#39;colorscheme&#39;:clr,&#39;radius&#39;:.15}}) viewer.setStyle({&#39;model&#39;:idx,&#39;serial&#39;:keepMatches[idx]}, {&#39;stick&#39;:{&#39;colorscheme&#39;:clr},&#39;sphere&#39;:{&#39;colorscheme&#39;:clr,&#39;radius&#39;:.5}}) viewer.zoomTo() viewer.show() . You appear to be running in JupyterLab (or JavaScript failed to load for some other reason). You need to install the 3dmol extension: jupyter labextension install jupyterlab_3dmol .",
            "url": "https://greglandrum.github.io/rdkit-blog/tutorial/3d/mcs/2022/06/23/3d-mcs.html",
            "relUrl": "/tutorial/3d/mcs/2022/06/23/3d-mcs.html",
            "date": " • Jun 23, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "Variability of PMI descriptors",
            "content": "Earlier this year Axel asked about the differences in PMI (princile moments of inertia) values between different stereoisomers of the same molecule. I guessed, but wasn&#39;t sure, that the differences arising from different stereoisomers would be small relative to those arising from inter-conformer variability in the structure. . This post looks into that question. . from rdkit import Chem from rdkit.Chem import rdDistGeom from rdkit.Chem import rdMolDescriptors from rdkit.Chem import Descriptors from rdkit.Chem import rdDepictor rdDepictor.SetPreferCoordGen(True) from rdkit.Chem.Draw import IPythonConsole from rdkit.Chem import Draw import numpy as np import rdkit print(rdkit.__version__) %pylab inline . 2022.03.2 %pylab is deprecated, use %matplotlib inline and import the required libraries. Populating the interactive namespace from numpy and matplotlib . Start by reading in 50 molecules from the platinum dataset which have at least one chiral center. . Note that as of the 2022.03.3 release of the RDKit the explicit call to AssignStereochemistryFrom3D() is no longer necessary for molecules which have 3D conformers. We changed the default behavior so that this function is called whenever a molecule has a 3D conformer. . with Chem.SDMolSupplier(&#39;../data/platinum_dataset_2017_01.sdf&#39;,removeHs=False) as suppl: ms = [] while len(ms)&lt;50: m = next(suppl) if not m: continue Chem.AssignStereochemistryFrom3D(m) if len(Chem.FindMolChiralCenters(m))&lt;1: continue ms.append(m) . Look at the number of chiral centers present in each molecule . figsize(6,6) hist([len(Chem.FindPotentialStereo(m)) for m in ms],bins=20); xlabel(&#39;num chiral centers&#39;) ylabel(&#39;count&#39;); . inter-conformer variability for a single stereoisomer . Start by generating 100 conformers for each of our molecules. . We will only generate conformers which match the stereochemistry of the input structure (this is the default RDKit behavior). . ps = rdDistGeom.srETKDGv3() ps.numThreads = 6 ps.randomSeed = 0xf00d ps.pruneRmsThresh = 0.5 for m in ms: rdDistGeom.EmbedMultipleConfs(m,100,ps) . Generate the three PMI descriptors for each conformer of each molecule (note that PMI1 is the smallest principle moment). . accum = [] for m in ms: confs = m.GetConformers() d = [] for conf in confs: d.append((rdMolDescriptors.CalcPMI1(m,confId=conf.GetId()), rdMolDescriptors.CalcPMI2(m,confId=conf.GetId()), rdMolDescriptors.CalcPMI3(m,confId=conf.GetId()))) accum.append(np.array(d)) . Look at the inter-conformer variability, as measured by the relative standard deviation, of the three descriptors . figsize(9,6) means = np.array([np.average(mat,axis=0) for mat in accum]) stds = np.array([np.std(mat,axis=0) for mat in accum]) rel_stds = stds/means hist(rel_stds,bins=10,label=(&#39;PMI1&#39;,&#39;PMI2&#39;,&#39;PMI3&#39;)); legend(); title(&#39;inter-conformer variation, single stereoisomer&#39;) xlabel(&#39;relative std dev&#39;); . And let&#39;s look at the standard deviations themselves: . figsize(9,6) hist(stds,bins=10,label=(&#39;PMI1&#39;,&#39;PMI2&#39;,&#39;PMI3&#39;)); legend(); title(&#39;inter-conformer variation, single stereoisomer&#39;) xlabel(&#39;std dev&#39;); . Variability across conformers and stereoisomers . m2s = [Chem.Mol(m) for m in ms] . ps = rdDistGeom.srETKDGv3() ps.numThreads = 6 ps.randomSeed = 0xf00d ps.pruneRmsThresh = 0.5 ps.enforceChirality = False for m in m2s: rdDistGeom.EmbedMultipleConfs(m,100,ps) . accum2 = [] for m in m2s: confs = m.GetConformers() d = [] for conf in confs: d.append((rdMolDescriptors.CalcPMI1(m,confId=conf.GetId()), rdMolDescriptors.CalcPMI2(m,confId=conf.GetId()), rdMolDescriptors.CalcPMI3(m,confId=conf.GetId()))) accum2.append(np.array(d)) . figsize(9,6) means2 = np.array([np.average(mat,axis=0) for mat in accum2]) stds2 = np.array([np.std(mat,axis=0) for mat in accum2]) rel_stds2 = stds2/means2 hist(rel_stds2,bins=10,label=(&#39;PMI1&#39;,&#39;PMI2&#39;,&#39;PMI3&#39;)); legend(); title(&#39;inter-conformer variation, multiple stereoisomers&#39;) xlabel(&#39;relative std dev&#39;); . Compare the single stereisomer variability to the multiple stereoisomer variability . First make sure that the means don&#39;t actually change . figsize(6,6) scatter((means)[:,0],(means2)[:,0],label=&#39;PMI1&#39;); scatter((means)[:,1],(means2)[:,1],label=&#39;PMI2&#39;); scatter((means)[:,2],(means2)[:,2],label=&#39;PMI3&#39;); ylabel(&#39;multiple stereoisomers&#39;) xlabel(&#39;single stereoisomer&#39;); title(&#39;mean&#39;) legend() plot((0,25000),(0,25000),&#39;k&#39;); . That looks good . figsize(6,6) scatter((stds/means)[:,0],(stds2/means2)[:,0],label=&#39;PMI1&#39;); scatter((stds/means)[:,1],(stds2/means2)[:,1],label=&#39;PMI2&#39;); scatter((stds/means)[:,2],(stds2/means2)[:,2],label=&#39;PMI3&#39;); ylabel(&#39;multiple stereoisomers&#39;) xlabel(&#39;single stereoisomer&#39;); title(&#39;relative std dev&#39;) legend() plot((0,0.35),(0,0.35),&#39;k&#39;); . So, at least for this set of 50 molecules, it looks like the answer to Axel&#39;s question is that the differences in PMI which arise from differing stereoisomers are small relative to the differences between conformers. . Let&#39;s still dig into the results a little bit. Which molecule(s) have the highest deviation for each of the moments? . indices = (argmax((stds2/means2)[:,0]-(stds/means)[:,0]), argmax((stds2/means2)[:,1]-(stds/means)[:,1]), argmax((stds2/means2)[:,2]-(stds/means)[:,2])) indices . (13, 13, 37) . Let&#39;s look at those two molecules . IPythonConsole.molSize = 350,350 IPythonConsole.drawOptions.addAtomIndices = True maxdevs = [Chem.RemoveHs(Chem.Mol(ms[x])) for x in (13,37)] for md in maxdevs: rdDepictor.Compute2DCoords(md) Draw.MolsToGridImage(maxdevs,subImgSize=(350,350),molsPerRow=2) . Just to be sure, check which atoms can be stereo: . Chem.AssignStereochemistry(maxdevs[0],force=True,flagPossibleStereoCenters=True) for atom in maxdevs[0].GetAtoms(): if atom.HasProp(&#39;_ChiralityPossible&#39;): print(atom.GetIdx()) . 11 16 . Look at one of the conformers: . IPythonConsole.ipython_3d = True ms[13] . You appear to be running in JupyterLab (or JavaScript failed to load for some other reason). You need to install the 3dmol extension: jupyter labextension install jupyterlab_3dmol .",
            "url": "https://greglandrum.github.io/rdkit-blog/3d/questions/2022/06/22/variability-of-pmi-descriptors.html",
            "relUrl": "/3d/questions/2022/06/22/variability-of-pmi-descriptors.html",
            "date": " • Jun 22, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "Searching with generic groups",
            "content": "One of the features added for the v2022.03 RDKit release is support for &quot;Reaxys/Beilstein&quot; generic groups - atoms with labels like &quot;ARY&quot; or &quot;ACY&quot; which can be used to make substructure searches more specific. . This post provides a quick overview of that functionality. . from rdkit import Chem from rdkit.Chem import rdMolEnumerator from rdkit.Chem import rdTautomerQuery from rdkit.Chem import Draw from rdkit.Chem.Draw import IPythonConsole IPythonConsole.drawOptions.minFontSize = 10 IPythonConsole.molSize = 350,300 Draw.SetComicMode(IPythonConsole.drawOptions) from rdkit.Chem import rdDepictor rdDepictor.SetPreferCoordGen(True) import rdkit print(rdkit.__version__) import time print(time.asctime()) . 2022.03.1 Tue Apr 5 06:10:45 2022 . Load a SubstructLibrary created using ChEMBL_30. The code used to construct this is below. Note that I&#39;ve configured the SubstructLibrary to return search results sorted by the number of heavy atoms so that I get smaller, more specific results first. . from rdkit import RDLogger from rdkit import Chem from rdkit.Chem import rdSubstructLibrary import pickle, time import gzip import numpy as np gz = gzip.GzipFile(&#39;/home/glandrum/Downloads/chembl_30.sdf.gz&#39;) suppl = Chem.ForwardSDMolSupplier(gz) RDLogger.DisableLog(&quot;rdApp.warning&quot;) t1=time.time() data = [] for i,mol in enumerate(suppl): if not ((i+1)%50000): print(f&quot;Processed {i+1} molecules in {(time.time()-t1):.1f} seconds&quot;) if mol is None or mol.GetNumHeavyAtoms()&gt;50: continue fp = Chem.PatternFingerprint(mol,fpSize=1024,tautomerFingerprints=True) smi = Chem.MolToSmiles(mol) data.append((smi,fp,mol.GetNumHeavyAtoms())) t2=time.time() pickle.dump(data,open(&#39;./results/chembl30_sssdata.pkl&#39;,&#39;wb+&#39;)) t1=time.time() mols = rdSubstructLibrary.CachedTrustedSmilesMolHolder() fps = rdSubstructLibrary.TautomerPatternHolder(1024) natoms = [] for smi,fp,nats in data: mols.AddSmiles(smi) fps.AddFingerprint(fp) natoms.append(nats) library = rdSubstructLibrary.SubstructLibrary(mols,fps) library.SetSearchOrder([int(x) for x in np.argsort(natoms)]) t2=time.time() print(f&quot;That took {t2-t1:.2f} seconds. The library has {len(library)} molecules.&quot;) pickle.dump(library,open(&#39;./results/chembl30_ssslib.pkl&#39;,&#39;wb+&#39;)) . import pickle with open(&#39;./results/chembl30_ssslib.pkl&#39;,&#39;rb&#39;) as inf: sslib = pickle.load(inf) print(f&#39;SubstructLibrary loaded with {len(sslib)} molecules&#39;) . SubstructLibrary loaded with 2035013 molecules . Beilstein generic queries . Start with a simple query molecule which includes a generic atom in an SGroup: . mb = &#39;&#39;&#39; Mrv2108 04052206092D 0 0 0 0 0 999 V3000 M V30 BEGIN CTAB M V30 COUNTS 10 11 1 0 0 M V30 BEGIN ATOM M V30 1 C -11.4118 0.5479 0 0 M V30 2 C -11.3849 -0.9919 0 0 M V30 3 C -10.0379 -1.7385 0 0 M V30 4 C -8.7179 -0.9454 0 0 M V30 5 C -8.7448 0.5943 0 0 M V30 6 C -10.0918 1.341 0 0 M V30 7 N -7.2453 -1.3956 0 0 M V30 8 C -6.362 -0.1342 0 0 M V30 9 N -7.2888 1.0958 0 0 M V30 10 C -4.8222 -0.161 0 0 M V30 END ATOM M V30 BEGIN BOND M V30 1 1 1 2 M V30 2 2 2 3 M V30 3 1 3 4 M V30 4 2 4 5 M V30 5 1 5 6 M V30 6 2 1 6 M V30 7 1 7 8 M V30 8 1 5 9 M V30 9 1 4 7 M V30 10 2 8 9 M V30 11 1 8 10 M V30 END BOND M V30 BEGIN SGROUP M V30 1 SUP 0 - M V30 ATOMS=(1 10) - M V30 LABEL=&quot;ARY&quot; M V30 END SGROUP M V30 END CTAB M END &#39;&#39;&#39; bqry = Chem.MolFromMolBlock(mb) # show labels for the Sgroups: for sgs in Chem.GetMolSubstanceGroups(bqry): if sgs.GetProp(&#39;TYPE&#39;) == &#39;SUP&#39;: bqry.GetAtomWithIdx(sgs.GetAtoms()[0]).SetProp(&quot;atomLabel&quot;,sgs.GetProp(&quot;LABEL&quot;)) bqry . Initially the generic ARY query is not used in the substructure search: . matches = sslib.GetMatches(bqry) mols = [sslib.GetMol(x) for x in matches] print(f&#39;There are {len(mols)} matches&#39;) Draw.MolsToGridImage(mols[:12],molsPerRow=4) . There are 1000 matches . But we can limit the results to aryl substituents by expanding the generic query and telling the SubstructLib to use it: . ary_qry = Chem.Mol(bqry) # expand the query: Chem.SetGenericQueriesFromProperties(ary_qry) # do the search using generic query matchers: params = Chem.SubstructMatchParameters() params.useGenericMatchers = True matches = sslib.GetMatches(ary_qry,params) mols = [sslib.GetMol(x) for x in matches] print(f&#39;There are {len(mols)} matches&#39;) Draw.MolsToGridImage(mols[:12],molsPerRow=4) . There are 1000 matches . The full list of recognized generic atoms is here: https://github.com/rdkit/rdkit/blob/master/Code/GraphMol/GenericGroups/GenericGroups.h#L245 (And, yes, that should be in the documentation... hopefully we can get that in for the next release). . Here are a couple of more examples . AHC: heteroacyclic groups . mb = &#39;&#39;&#39; Mrv2108 03242208122D 0 0 0 0 0 999 V3000 M V30 BEGIN CTAB M V30 COUNTS 10 11 1 0 0 M V30 BEGIN ATOM M V30 1 C -11.4118 0.5479 0 0 M V30 2 C -11.3849 -0.9919 0 0 M V30 3 C -10.0379 -1.7385 0 0 M V30 4 C -8.7179 -0.9454 0 0 M V30 5 C -8.7448 0.5943 0 0 M V30 6 C -10.0918 1.341 0 0 M V30 7 N -7.2453 -1.3956 0 0 M V30 8 C -6.362 -0.1342 0 0 M V30 9 N -7.2888 1.0958 0 0 M V30 10 C -4.8222 -0.161 0 0 M V30 END ATOM M V30 BEGIN BOND M V30 1 1 1 2 M V30 2 2 2 3 M V30 3 1 3 4 M V30 4 2 4 5 M V30 5 1 5 6 M V30 6 2 1 6 M V30 7 1 7 8 M V30 8 1 5 9 M V30 9 1 4 7 M V30 10 2 8 9 M V30 11 1 8 10 M V30 END BOND M V30 BEGIN SGROUP M V30 1 SUP 0 ATOMS=(1 10) SAP=(3 10 8 1) XBONDS=(1 11) LABEL=AHC M V30 END SGROUP M V30 END CTAB M END &#39;&#39;&#39; bqry = Chem.MolFromMolBlock(mb) # show labels for the Sgroups: for sgs in Chem.GetMolSubstanceGroups(bqry): if sgs.GetProp(&#39;TYPE&#39;) == &#39;SUP&#39;: bqry.GetAtomWithIdx(sgs.GetAtoms()[0]).SetProp(&quot;atomLabel&quot;,sgs.GetProp(&quot;LABEL&quot;)) ahc_qry = Chem.Mol(bqry) # expand the query: Chem.SetGenericQueriesFromProperties(ahc_qry) # do the search using generic query matchers: params = Chem.SubstructMatchParameters() params.useGenericMatchers = True matches = sslib.GetMatches(ahc_qry,params) mols = [sslib.GetMol(x) for x in matches] print(f&#39;There are {len(mols)} matches&#39;) Draw.MolsToGridImage(mols[:12],molsPerRow=4) . There are 1000 matches . CAL: carbocyclic alkyl . mb = &#39;&#39;&#39; Mrv2108 03242208122D 0 0 0 0 0 999 V3000 M V30 BEGIN CTAB M V30 COUNTS 10 11 1 0 0 M V30 BEGIN ATOM M V30 1 C -11.4118 0.5479 0 0 M V30 2 C -11.3849 -0.9919 0 0 M V30 3 C -10.0379 -1.7385 0 0 M V30 4 C -8.7179 -0.9454 0 0 M V30 5 C -8.7448 0.5943 0 0 M V30 6 C -10.0918 1.341 0 0 M V30 7 N -7.2453 -1.3956 0 0 M V30 8 C -6.362 -0.1342 0 0 M V30 9 N -7.2888 1.0958 0 0 M V30 10 C -4.8222 -0.161 0 0 M V30 END ATOM M V30 BEGIN BOND M V30 1 1 1 2 M V30 2 2 2 3 M V30 3 1 3 4 M V30 4 2 4 5 M V30 5 1 5 6 M V30 6 2 1 6 M V30 7 1 7 8 M V30 8 1 5 9 M V30 9 1 4 7 M V30 10 2 8 9 M V30 11 1 8 10 M V30 END BOND M V30 BEGIN SGROUP M V30 1 SUP 0 ATOMS=(1 10) SAP=(3 10 8 1) XBONDS=(1 11) LABEL=CAL M V30 END SGROUP M V30 END CTAB M END &#39;&#39;&#39; bqry = Chem.MolFromMolBlock(mb) cal_qry = Chem.Mol(bqry) # expand the query: Chem.SetGenericQueriesFromProperties(cal_qry) # do the search using generic query matchers: params = Chem.SubstructMatchParameters() params.useGenericMatchers = True matches = sslib.GetMatches(cal_qry,params) mols = [sslib.GetMol(x) for x in matches] print(f&#39;There are {len(mols)} matches&#39;) Draw.MolsToGridImage(mols[:12],molsPerRow=4) . There are 784 matches . Providing the queries in CXSMILES . You can also use CXSMILES/CXSMARTS to provide these queries: . sqry = Chem.MolFromSmarts(&#39;*-c1nc2c(n1)cccc2 |$AHC;;;;;;;;;$|&#39;) sqry . ahc_qry = Chem.Mol(sqry) # expand the query: Chem.SetGenericQueriesFromProperties(ahc_qry) # do the search using generic query matchers: params = Chem.SubstructMatchParameters() params.useGenericMatchers = True matches = sslib.GetMatches(ahc_qry,params) mols = [sslib.GetMol(x) for x in matches] print(f&#39;There are {len(mols)} matches&#39;) Draw.MolsToGridImage(mols[:12],molsPerRow=4) . There are 1000 matches . Though note that if you use CXSMILES it&#39;s important to make sure the dummy atom is replaced with a query before doing the search. If you don&#39;t do so, you&#39;ll get no results since the dummy atom only matches other dummy atoms: . sqry = Chem.MolFromSmiles(&#39;*C1=NC2=C(N1)C=CC=C2 |$AHC;;;;;;;;;$|&#39;) ahc_qry = Chem.Mol(sqry) # expand the query: Chem.SetGenericQueriesFromProperties(ahc_qry) params = Chem.SubstructMatchParameters() params.useGenericMatchers = True matches = sslib.GetMatches(ahc_qry,params) print(f&#39;There are {len(matches)} matches&#39;) . There are 0 matches . Here&#39;s the fix: . qps = Chem.AdjustQueryParameters.NoAdjustments() qps.makeDummiesQueries = True sqry = Chem.AdjustQueryProperties(sqry) ahc_qry = Chem.Mol(sqry) Chem.SetGenericQueriesFromProperties(ahc_qry) params = Chem.SubstructMatchParameters() params.useGenericMatchers = True matches = sslib.GetMatches(ahc_qry,params) print(f&#39;There are {len(matches)} matches&#39;) . There are 186 matches . Search performance . Get a baseline for how long a search takes by ignoring the generic matchers: . params = Chem.SubstructMatchParameters() params.useGenericMatchers = False %timeit matches = sslib.GetMatches(cal_qry,params,maxResults=5000) . 329 ms ± 6.11 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) . We&#39;d expect the searches using generic groups to take at least a bit longer since they will results in more molecules being scanned until we find our 5000 results. The big question is whether or not merely including the generic queries results in a significant slow down. . Let&#39;s test how much longer it takes using two of the different generic groups: . params = Chem.SubstructMatchParameters() params.useGenericMatchers = True %timeit matches = sslib.GetMatches(cal_qry,params,maxResults=5000) . 415 ms ± 18.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) . That really doesn&#39;t make much of a difference at all. . params = Chem.SubstructMatchParameters() params.useGenericMatchers = True %timeit matches = sslib.GetMatches(ary_qry,params,maxResults=5000) . 1.24 s ± 139 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) . So there is definitely some impact, and it depends on which generic query is being used. . Aside . Since the ARY query mainly returns molecules which have a phenyl group attached at the ARY position, let&#39;s compare search performance with a query where we explicitly include the phenyl. Here the extra atoms/bonds will slow the substructure search down but they will also make the fingerprint screenout more effective. The question is which effect is dominant. . fullqry = Chem.MolFromSmiles(&#39;c1ccccc1-c1nc2ccccc2[nH]1&#39;) fullqry . %timeit matches = sslib.GetMatches(fullqry,maxResults=5000) . 1.05 s ± 54.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) . In this case the larger query is a bit faster. . It&#39;s worth mentioning that the query with the phenyl group returns different search results than the version with the ARY: . full_matches = sslib.GetMatches(fullqry,params,maxResults=-1) ary_matches = sslib.GetMatches(ary_qry,params,maxResults=-1) len(full_matches),len(ary_matches) . (6866, 6488) . full_not_ary = set(full_matches).difference(ary_matches) mols = [sslib.GetMol(x) for x in full_not_ary] print(f&#39;There are {len(mols)} matches&#39;) Draw.MolsToGridImage(mols[:12],molsPerRow=4) . There are 379 matches . As you&#39;d expect, there are a bunch of molecules with heterocyclic aromatic systems here. The ARY query only matches carboaryl systems. . There is only one molecule returned by the ARY query but not the full query; this one has an unusual aromatic ring system: . ary_not_full = set(ary_matches).difference(full_matches) mols = [sslib.GetMol(x) for x in ary_not_full] print(f&#39;There are {len(mols)} matches&#39;) Draw.MolsToGridImage(mols[:12],molsPerRow=4) . There are 1 matches . That&#39;s a good one to ignite a round of &quot;but that&#39;s not aromatic!&quot; arguments, but before you start down that road, please read this section of the RDKit docs: https://www.rdkit.org/docs/RDKit_Book.html#aromaticity and possibly the section on aromaticity in the Daylight Theory manual. . This seems like a great place to close this post. :-) .",
            "url": "https://greglandrum.github.io/rdkit-blog/tutorial/substructure/2022/04/05/searching-with-generic-groups.html",
            "relUrl": "/tutorial/substructure/2022/04/05/searching-with-generic-groups.html",
            "date": " • Apr 5, 2022"
        }
        
    
  
    
        ,"post5": {
            "title": "Some thoughts on refactoring the MolDraw2D code",
            "content": "The functionality described here is available in the 2022.03.1 and later releases of the RDKit . Intro . I recently merged a pull request (https://github.com/rdkit/rdkit/pull/4948) from Dave Cosgrove with some pretty significant changes (58 modified files and &gt;8000 modified lines of code according to Github) to the backend MolDraw2D code. Dave and I have been working on this (well, ok, Dave has been working, I’ve been commenting on his work ;-) ) for a couple of months. . Given the amount of effort that went into this PR, and how happy I am about it, it may be somewhat surprising to hear that I hope that most of these changes will remain more or less invisible to most of the RDKit community. All existing code and scripts should continue to work without modification, though there may be some small changes (I hope they are improvements) to the way molecules are actually drawn; see below for more information on this. . Why do something like this? . The MolDraw2D code is heavily used and, in my opinion, pretty important. Over the last few years it had also gotten pretty complex and difficult to maintain. Some of that complexity is inevitable, the rendering code is quite flexible and is solving a non-trivial problem, but a lot of it was also due to the incremental addition of features over time. This “accidental” complexity made both extending and fixing the code more difficult. So at the end of 2021 when Dave had time to do a chunk of work on the RDKit and T5 Informatics had some funds available, we took what we’ve learned over the past years and Dave rewrote the backend. The goal was to clean things up and make the code more extensible and maintainable without breaking existing code. . End-user visible changes . Molecule rendering . There are some small differences in the way molecules are rendered; these will most likely only be visible if you are really paying attention. . Reaction rendering . Here the changes are a bit larger: the reaction rendering code now makes better use of the available space. . Here’s a rendering of one of the sample reactions we use in the testing code using the 2021.09.4 release of the RDKit: . . Here’s the new version: . . New features . Drawing molecules in grids using different scales . When drawing molecules in a grid the default behavior is to draw them all at the same scale. Here’s an example of that: . . Since the last molecule is big, the other two molecules end up being drawn really small. We can change that by setting the new drawing option drawMolsSameScale to False: . . As an aside: if you’re bothered by how big small molecules like ethanol end up being, you can use the fixedBondLength drawing option (units are, roughly, pixels per angstrom) to set the maximum bond length. Combining this with drawMolsSameScale=False for the three molecules above results in: . . The “flexicanvas”: fitting the canvas size to the molecule . Aside: I added the initial version of this before Dave did the refactoring, but the new backend simplifies the implementation. . Normally the drawing code scales the molecule and font size to fit the canvas provided for it. With the SVG and Cairo renderers it’s now possible to set the font size and scale and let the drawer figure out how large the canvas needs to be. If I use this feature I get a larger canvas for oxytocin: . . than I do for ezetimibe: . . but the bond lengths and font sizes are the same in each image. . You can use this functionality by creating a MolDraw2D object with width and height set to -1. Here’s the code used to produce the image of ezetimibe above: . ezetimibe = Chem.MolFromSmiles(&#39;O=C1[C@H](CC[C@H](O)c2ccc(F)cc2)[C@@H](c2ccc(O)cc2)N1c1ccc(F)cc1&#39;) d2d = Draw.MolDraw2DCairo(-1,-1) d2d.drawOptions().scalingFactor = 20 # units are roughly pixels/angstrom d2d.drawOptions().fixedFontSize = 14 d2d.DrawMolecule(ezetimibe) d2d.FinishDrawing() Image(d2d.GetDrawingText()) . Control over font size . This is a particularly difficult one because there are just too many odd and conflicting situations which need to be handled. Here are some of the outliers: . small molecules in large canvases | large molecules in small canvases where you expect to be able to read the fonts | very large molecules in small canvases there’s no practical way to be able to read the fonts | . You have a number of ways to control the font size used when drawing molecules. Let’s start with a small drawing of oxytocin and the default font parameters: . . The relative size of the font and the bond lengths is controlled by the baseFontSize option, which defaults to 0.6. Increasing it to, for example, 0.8 increases the relative font size, this affects every drawing: . . You can also set a minimum font size in points with the minFontSize option (not shown here). . Finally, it’s possible to set an exact font size to use with the fixedFontSize option. Here, again, is oxytocin but with fixedFontSize=13(obviously this is too large for this canvas size): . . Giving the legend a bit more space . When you draw a molecule with a legend 10% of the vertical space is set aside for the canvas. This seems to work well for single-line legends: . . But results in a pretty small font if the legend has multiple lines: . . In cases like this we can set legendFraction to something like 0.15 to give the legend a bit more room: . . Legends and flexicanvas mode . When you don’t specify the size of the canvas in advance, the legendFontSize parameter is directly used to control the size of the legend. For example, here’s a 24 point legend: . . or the same legend but with legendFontSize=12: . .",
            "url": "https://greglandrum.github.io/rdkit-blog/technical/2022/03/18/refactoring-moldraw2d.html",
            "relUrl": "/technical/2022/03/18/refactoring-moldraw2d.html",
            "date": " • Mar 18, 2022"
        }
        
    
  
    
        ,"post6": {
            "title": "R-group decomposition and molzip",
            "content": "Recently a couple of customers have asked questions along the lines of: &quot;How do I do an R-group decomposition and then recombine the cores and R groups to create new molecules?&quot; That&#39;s an interesting and useful task which the RDKit has some built-in tools to help with, so I figured I&#39;d do a blog post. . from rdkit import Chem from rdkit.Chem import Draw from rdkit.Chem import rdqueries from rdkit.Chem.Draw import IPythonConsole from rdkit.Chem import rdRGroupDecomposition from rdkit.Chem import rdDepictor from rdkit import Geometry rdDepictor.SetPreferCoordGen(True) import itertools import rdkit print(rdkit.__version__) . 2022.03.1pre . Note: Though I&#39;m doing this blog post using a local build from RDKit master all of the functionality which I demonstrate here is already available in the 2021.09 release series. . Read in the dataset . Read in a bunch of molecules from a J Med Chem paper (https://doi.org/10.1021/acs.jmedchem.7b00306 the paper is open access). Here I downloaded the SMILES in the supporting information, sketched the scaffold manually, and then saved the scaffold + molecules to an SD file. The scaffold is the first molecule in the SDF. . ms = [mol for mol in Chem.SDMolSupplier(&#39;../data/jm7b00306.sdf&#39;)] core = ms[0] ms.pop(0) print(f&#39;There are {len(ms)} molecules&#39;) core . There are 31 molecules . &lt;/td&gt;&lt;/tr&gt; scaffold1 | . &lt;/table&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; Now let&#39;s look at some of the other molecules . Draw.MolsToGridImage(ms[:12],molsPerRow=4) . Doing the R-group decomposition . The RGD code takes a list of cores to be used along with a list of molecules. It returns a 2-tuple with: . a dictionary with the results | a list with the indices of the molecules which failed; these are molecules which did not match any of the cores | I&#39;ve blogged about the RGD code before here and here if you want to read more about it. It&#39;s probably time for another post with an update, but those are hopefully already useful. . rgd,failed = rdRGroupDecomposition.RGroupDecompose([core],ms,asRows=False) len(failed) . 6 . failed . [0, 1, 2, 3, 29, 30] . rgd.keys() . dict_keys([&#39;Core&#39;, &#39;R1&#39;, &#39;R2&#39;, &#39;R3&#39;]) . Let&#39;s look at the results . print(f&#39;There are {len(rgd[&quot;R1&quot;])} R1s&#39;) Draw.MolsToGridImage(rgd[&#39;R1&#39;][:12],molsPerRow=4) . There are 25 R1s . Remove any R groups which have more than one dummy atom. This happens if an R group is attached to the core at multiple points and it may mess up the rest of the analysis. . qa = rdqueries.AtomNumEqualsQueryAtom(0) r1 = [x for x in rgd[&#39;R1&#39;] if len(x.GetAtomsMatchingQuery(qa))==1] r2 = [x for x in rgd[&#39;R2&#39;] if len(x.GetAtomsMatchingQuery(qa))==1] r3 = [x for x in rgd[&#39;R3&#39;] if len(x.GetAtomsMatchingQuery(qa))==1] . Now find the unique members in each set of R groups: . def uniquify(rgs): seen = set() keep = [] for rg in rgs: smi = Chem.MolToSmiles(rg) if smi not in seen: keep.append(rg) seen.add(smi) return keep . r1s = uniquify(r1) r2s = uniquify(r2) r3s= uniquify(r3) print(len(r1s),len(r2s),len(r3s)) . 15 6 6 . Look at the unique R1s: . Draw.MolsToGridImage(r1s[:12],molsPerRow=4) . Enumerating all possible molecules from the R groups . Quick intro to molzip . We&#39;ll use the RDKit&#39;s molzip() function to recombine the cores with the side chains. . molzip lets you take a molecule containing multiple fragments and &quot;zip&quot; them together. The atoms which should be bonded in the final molecule are labelled by connecting them to dummy atoms. The code identifies matching dummy atoms (by default this means dummies with the same isotopic label) in the fragments, adds bonds between the atoms connected to the dummies, and then removes the dummies. . Here&#39;s a simple example using a molecule with three fragments: . sample = Chem.MolFromSmiles(&#39;[*:1]c1nc([*:2])ncc1.CO[*:1].[*:2]N(C)C&#39;) sample . And this is what happens when we zip those together: . Chem.molzip(sample) . Using molzip with RGD output . The molzip function is perfect for working with the output from an R-group decomposition. . Here I&#39;ll define the function we&#39;re going to use to enumerate all of the products: . import random def enumerate_all_products(core,*rgroups,randomOrder=False): # preserve the positions of the non-dummy core atoms, # we will use these to make sure the cores are drawn # the same way in each molecule we generate corePos = {} conf = core.GetConformer() for i in range(conf.GetNumAtoms()): corePos[i] = Geometry.Point2D(conf.GetAtomPosition(i)) # Python&#39;s itertools handles doing the combinatorics of generating # every possible combination of R groups: order = itertools.product(*rgroups) if randomOrder: order = list(order) random.shuffle(order) # now we just loop over each combination, copy all the pieces into # one molecule, and zip it. That&#39;s our product for tpl in order: tm = Chem.RWMol(core) for r in tpl: tm.InsertMol(r) prod = Chem.molzip(tm) if prod is not None: # generate 2d coordinates with the core fixed in place rdDepictor.Compute2DCoords(prod,canonOrient=False,coordMap=corePos) # and finally yield the product molecule yield prod . We&#39;re going to use the core which came from the RGD since it&#39;s labelled in the same way as the sidechains . rgd_core = rgd[&#39;Core&#39;][0] rgd_core . &lt;/td&gt;&lt;/tr&gt; scaffold1 | . &lt;/table&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; Let&#39;s try it out: . prod_gen = enumerate_all_products(rgd_core,r1s,r2s,r3s) # now get the first unique products prods = [] seen = set() for prod in prod_gen: if prod is not None: Chem.SanitizeMol(prod) smi = Chem.MolToSmiles(prod) if smi not in seen: prods.append(prod) seen.add(smi) if len(prods)&gt;=12: break Draw.MolsToGridImage(prods,molsPerRow=4) . Those come back ordered by the R groups (i.e. all products created using the first value of R1, then all products created using the second value of R1, etc.). This is fine if we&#39;re planning on enumerating all the molecules, but if we only need a subset we can tell enumerate_all_products() to return the results in a random order: . random.seed(0xbaff7ed) prod_gen = enumerate_all_products(rgd_core,r1s,r2s,r3s,randomOrder=True) prods = [] seen = set() for prod in prod_gen: if prod is not None: Chem.SanitizeMol(prod) smi = Chem.MolToSmiles(prod) if smi not in seen: prods.append(prod) seen.add(smi) if len(prods)&gt;=12: break Draw.MolsToGridImage(prods,molsPerRow=4) . Hopefully this brief post is useful! . &lt;/div&gt; | . | .",
            "url": "https://greglandrum.github.io/rdkit-blog/tutorial/rgd/2022/03/14/rgd-and-molzip.html",
            "relUrl": "/tutorial/rgd/2022/03/14/rgd-and-molzip.html",
            "date": " • Mar 14, 2022"
        }
        
    
  
    
        ,"post7": {
            "title": "The number of unique fingerprint bits",
            "content": "How many molecules do we need to add before we&#39;ve seen all the bits? . I did an updated post last year looking at the average number of bits set per molecule by the various fingerprinting algorithms in the RDKit. . This one explores a couple of related topics: . If we look at a large set of organic molecules, how many different atom environments (as defined by the individual fingerprints) do we observe? | How quickly does this number converge with the number of compounds considered? | Obviously the answer to these questions is extremely dependent on the set of molecules you use. For this post I will use a set of around six million random molecules from Zinc20&#39;s &quot;in-stock&quot; set. The six million included all have less than 50 heavy atoms after being salt stripped. . The experiment itself could hardly be simpler: read in the molecules, generate fingerprints, and keep track of the unique bits set as a function of number of molecules considered. For this analysis I limit myself to fingerprints which have not been &quot;folded&quot; to fit into a particular bit length (with the exception of the Avalon FP, which currently only supports generating folded forms). . The code and raw data are below, here are the curves showing the saturation behavior for the various fingerprints: . Note that the saturation behavior of the avalon fingerprint here is an artifact of the fact that the fingerprint being used was only 9192 bits long (yes, I made a typo when I entered the value in the script to generate the data); 9185 of those bits end up being set. . For a bit more resolution, here&#39;s a table with the number of unique bits set per fingerprint in that set of 6 million, the number of new bits found in the last 100K of the 6 million, as well as how many molecules needed to be considered to reach 90, 95, and 99% of the number of unique bits: . # unique bits # in last 100K 0.90 0.95 0.99 . FeatMorgan0 | 15 | 0 | N/A | N/A | N/A | . FeatMorgan1 | 1621 | 2 | 2760000 | 4080000 | 5460000 | . FeatMorgan2 | 116975 | 464 | 4000000 | 4870000 | 5750000 | . FeatMorgan3 | 1350464 | 7478 | 4400000 | 5130000 | 5810000 | . Morgan0 | 143 | 0 | 2850000 | 4080000 | 5080000 | . Morgan1 | 19428 | 67 | 3870000 | 4750000 | 5720000 | . Morgan2 | 575817 | 2941 | 4320000 | 5080000 | 5790000 | . Morgan3 | 3606676 | 22970 | 4580000 | 5240000 | 5830000 | . RDKit5 | 131029 | 347 | 3490000 | 4600000 | 5690000 | . RDKit6 | 538500 | 1627 | 3600000 | 4680000 | 5700000 | . RDKit7 | 1989958 | 6897 | 3740000 | 4760000 | 5720000 | . RDKit-linear5 | 49852 | 136 | 3400000 | 4520000 | 5680000 | . RDKit-linear6 | 133904 | 402 | 3480000 | 4570000 | 5690000 | . RDKit-linear7 | 315293 | 1032 | 3570000 | 4640000 | 5700000 | . ap-counts | 16585 | 18 | 2470000 | 3840000 | 5410000 | . avalon | 9185 | 0 | 20000 | 70000 | 490000 | . tt-counts | 20723 | 49 | 3530000 | 4570000 | 5640000 | . To help with the interpretation of this: a total of 131029 unique bits were found for the RDKit5 fingerprint in the set of 6 million molecules and 95% of those bits had been found after looking at 4.6 million molecules. The last 100K molecules added 347 new bits. . The thing that I find most interesting (and somewhat surprising) about these results is how far we are from having encountered &quot;all&quot; of the bits; new bits are being encountered for almost all of the fingerprint types even after 5.9 million molecules have been encountered. I can probably still wave my hands and estimate the order-of-magnitude number of distinct bits for each of the FP types in the full set of ~14 million substances in the ZINC20 &quot;in-stock&quot; set. Here&#39;s a few of those estimates: . FeatMorgan2: 120-150K | FeatMorgan3: 1.4-1.6 million | Morgan1: 20-25K | Morgan2: 600-700K | Morgan3: 3.6-4.0 million | . These are also rough lower bounds on the number of atom environments in those compounds (it&#39;s a lower bound due to the possibility of hash collisions causing multiple atom environments to hash to the same fingerprint bit). . Aside: it&#39;s worth mentioning that this, of course, isn&#39;t the first time someone has looked at this topic. I don&#39;t normally include references for blog posts, but this paper from the PubChem team is a nice look at the atom environments in the (huge) PubChem dataset: http://www.jcheminf.com/content/7/1/41 . The rest of the post has the code for generating the data and doing the analysis. . from rdkit import Chem,DataStructs import time,random,gzip,pickle,copy import numpy as np from collections import Counter,defaultdict from rdkit.Chem import Draw from rdkit.Chem import rdMolDescriptors from rdkit.Chem.MolStandardize import rdMolStandardize from rdkit.Avalon import pyAvalonTools from rdkit.Chem.Draw import IPythonConsole from rdkit import DataStructs from rdkit import rdBase from rdkit import RDLogger %pylab inline print(rdBase.rdkitVersion) import time print(time.asctime()) . Populating the interactive namespace from numpy and matplotlib 2021.09.3 Tue Jan 4 13:17:00 2022 . /home/glandrum/miniconda3/envs/rdkit_blog/lib/python3.9/site-packages/IPython/core/magics/pylab.py:159: UserWarning: pylab import has clobbered these variables: [&#39;random&#39;, &#39;copy&#39;] `%matplotlib` prevents importing * from pylab and numpy warn(&#34;pylab import has clobbered these variables: %s&#34; % clobbered + . try: import ipyparallel as ipp rc = ipp.Client() dview = rc[:] dview.execute(&#39;from rdkit import Chem&#39;) dview.execute(&#39;from rdkit import Descriptors&#39;) dview.execute(&#39;from rdkit.Chem import rdMolDescriptors&#39;) dview.execute(&#39;from rdkit.Avalon import pyAvalonTools&#39;) except: print(&quot;could not use ipyparallel&quot;) dview = None . Here&#39;s my local copy of the ~14 million &quot;in stock&quot; compounds I grabbed from ZINC (this file is too big for github): . filen=&#39;/scratch/RDKit_git/LocalData/Zinc20/purchasable/zinc20_instock.pkl.shuffled.gz&#39; . Loop over the molecules, strip salts, skip anything with more than 50 atoms, and build fingerprints for all the others. . The fingerprints I generate for this analysis are: . Sparse Morgan with radii 1, 2, and 3 | Sparse FeatureMorgan with radii 1, 2, and 3 | Sparse RDKit with maxPath 5, 6, and 7 | Sparse RDKit, no branches, with maxPath 5, 6, and 7 | Avalon BitVect | Sparse Atom Pairs | Sparse Topological Torsions | . All of the BitVect fingerprints are 4096 bits long . import copy from collections import defaultdict historyf = gzip.open(&#39;../data/fp_bit_counts.history.pkl.gz&#39;,&#39;wb+&#39;) RDLogger.DisableLog(&#39;rdApp.info&#39;) frm = rdMolStandardize.LargestFragmentChooser() counts=defaultdict(list) accum=defaultdict(set) t1 = time.time() with gzip.open(filen,&#39;rb&#39;) as inf: i = 0 ms = [] while 1: try: m,nm = pickle.load(inf) except EOFError: break if not m: continue # strip salts: m = frm.choose(m) if m.GetNumHeavyAtoms()&gt;50: continue ms.append(m) i+=1 if len(ms)&gt;=10000: for v in 0,1,2,3: k = (&#39;Morgan&#39;,v) cnts = dview.map_sync(lambda x,v=v:set(rdMolDescriptors.GetMorganFingerprint(x,v).GetNonzeroElements().keys()), ms) for obc in cnts: accum[k].update(obc) counts[k].append((i,len(accum[k]))) for v in 0,1,2,3: k = (&#39;FeatMorgan&#39;,v) cnts = dview.map_sync(lambda x,v=v:set(rdMolDescriptors.GetMorganFingerprint(x,v,useFeatures=True).GetNonzeroElements().keys()), ms) for obc in cnts: accum[k].update(obc) counts[k].append((i,len(accum[k]))) for v in 5,6,7: k = (&#39;RDKit&#39;,v) cnts = dview.map_sync(lambda x,v=v:set(Chem.UnfoldedRDKFingerprintCountBased(x,maxPath=v).GetNonzeroElements().keys()), ms) for obc in cnts: accum[k].update(obc) counts[k].append((i,len(accum[k]))) for v in 5,6,7: k = (&#39;RDKit-linear&#39;,v) cnts = dview.map_sync(lambda x,v=v:set(Chem.UnfoldedRDKFingerprintCountBased(x,maxPath=v,branchedPaths=False).GetNonzeroElements().keys()), ms) for obc in cnts: accum[k].update(obc) counts[k].append((i,len(accum[k]))) k = (&#39;avalon&#39;,-1) cnts = dview.map_sync(lambda x:set(pyAvalonTools.GetAvalonFP(x,nBits=9192).GetOnBits()), ms) for obc in cnts: accum[k].update(obc) counts[k].append((i,len(accum[k]))) k = (&#39;ap-counts&#39;,-1) cnts = dview.map_sync(lambda x:set(rdMolDescriptors.GetAtomPairFingerprint(x).GetNonzeroElements().keys()), ms) for obc in cnts: accum[k].update(obc) counts[k].append((i,len(accum[k]))) k = (&#39;tt-counts&#39;,-1) cnts = dview.map_sync(lambda x:set(rdMolDescriptors.GetTopologicalTorsionFingerprint(x).GetNonzeroElements().keys()), ms) for obc in cnts: accum[k].update(obc) counts[k].append((i,len(accum[k]))) ms = [] if not i%50000: t2 = time.time() print(&quot;Done %d in %.2f sec&quot;%(i,t2-t1)) if not i%500000: pickle.dump(dict(counts),historyf) pickle.dump(dict(accum),historyf) if i&gt;=5500000: break . with gzip.open(&#39;../data/fp_bit_counts.history.pkl.gz&#39;,&#39;wb+&#39;) as outf: pickle.dump(dict(counts),outf) pickle.dump(dict(accum),outf) . with gzip.open(&#39;../data/fp_bit_counts.history.pkl.gz&#39;,&#39;rb&#39;) as inf: counts = pickle.load(inf) . Now plot the distributions of the number of bits set . We have a few extra data points, let&#39;s stick to the first 6 million molecules . for k,v in counts.items(): v = [x for x in v if x[0]&lt;6000000] counts[k] = v . morgan_ks = [x for x in sorted(counts.keys()) if x[0] ==&#39;Morgan&#39;] featmorgan_ks = [x for x in sorted(counts.keys()) if x[0] ==&#39;FeatMorgan&#39;] rdkit_ks = [x for x in sorted(counts.keys()) if x[0] == &#39;RDKit&#39;] rdkitlin_ks = [x for x in sorted(counts.keys()) if x[0] == &#39;RDKit-linear&#39;] figure(figsize=(15,20)) pidx=1 subplot(3,2,pidx) for n,r in rdkit_ks: cnts = counts[(n,r)] plot([x for x,y in cnts],[y for x,y in cnts],label= f&quot;r={r}&quot;) _=title(&quot;RDKit&quot;) _=ylabel(&quot;unique bits observed&quot;) _=xlabel(&quot;num molecules&quot;) _=legend() pidx=2 subplot(3,2,pidx) for n,r in rdkitlin_ks: cnts = counts[(n,r)] plot([x for x,y in cnts],[y for x,y in cnts],label= f&quot;r={r}&quot;) _=title(&quot;RDKit linear&quot;) _=ylabel(&quot;unique bits observed&quot;) _=xlabel(&quot;num molecules&quot;) _=legend() pidx=3 subplot(3,2,pidx) for n,r in morgan_ks: cnts = counts[(n,r)] plot([x for x,y in cnts],[y for x,y in cnts],label= f&quot;r={r}&quot;) _=title(&quot;Morgan&quot;) _=ylabel(&quot;unique bits observed&quot;) _=xlabel(&quot;num molecules&quot;) _=legend() pidx=4 subplot(3,2,pidx) for n,r in featmorgan_ks: cnts = counts[(n,r)] plot([x for x,y in cnts],[y for x,y in cnts],label= f&quot;r={r}&quot;) _=title(&quot;FeatMorgan&quot;) _=ylabel(&quot;unique bits observed&quot;) _=xlabel(&quot;num molecules&quot;) _=legend() pidx+=1 subplot(3,2,pidx) for k in counts.keys(): if k[0].startswith(&#39;Morgan&#39;) or k[0].startswith(&#39;FeatMorgan&#39;) or k[0].startswith(&#39;RDKit&#39;): continue pidx+=1 cnts = counts[k] plot([x for x,y in cnts],[y for x,y in cnts],label=k[0]) _=title(&#39;others&#39;) _=ylabel(&quot;unique bits observed&quot;) _=xlabel(&quot;num molecules&quot;) _=legend() tight_layout(); . Mabye better to plot those on a log scale? . morgan_ks = [x for x in sorted(counts.keys()) if x[0] ==&#39;Morgan&#39;] featmorgan_ks = [x for x in sorted(counts.keys()) if x[0] ==&#39;FeatMorgan&#39;] rdkit_ks = [x for x in sorted(counts.keys()) if x[0] == &#39;RDKit&#39;] rdkitlin_ks = [x for x in sorted(counts.keys()) if x[0] == &#39;RDKit-linear&#39;] figure(figsize=(15,20)) pidx=1 subplot(3,2,pidx) for n,r in rdkit_ks: cnts = counts[(n,r)] plot([x for x,y in cnts],[y for x,y in cnts],label= f&quot;r={r}&quot;) _=title(&quot;RDKit&quot;) _=ylabel(&quot;unique bits observed&quot;) _=xlabel(&quot;num molecules&quot;) _=yscale(&#39;log&#39;) _=legend() pidx=2 subplot(3,2,pidx) for n,r in rdkitlin_ks: cnts = counts[(n,r)] plot([x for x,y in cnts],[y for x,y in cnts],label= f&quot;r={r}&quot;) _=title(&quot;RDKit linear&quot;) _=ylabel(&quot;unique bits observed&quot;) _=xlabel(&quot;num molecules&quot;) _=yscale(&#39;log&#39;) _=legend() pidx=3 subplot(3,2,pidx) for n,r in morgan_ks: cnts = counts[(n,r)] plot([x for x,y in cnts],[y for x,y in cnts],label= f&quot;r={r}&quot;) _=title(&quot;Morgan&quot;) _=ylabel(&quot;unique bits observed&quot;) _=xlabel(&quot;num molecules&quot;) _=yscale(&#39;log&#39;) _=legend() pidx=4 subplot(3,2,pidx) for n,r in featmorgan_ks: cnts = counts[(n,r)] plot([x for x,y in cnts],[y for x,y in cnts],label= f&quot;r={r}&quot;) _=title(&quot;FeatMorgan&quot;) _=ylabel(&quot;unique bits observed&quot;) _=xlabel(&quot;num molecules&quot;) _=yscale(&#39;log&#39;) _=legend() pidx+=1 subplot(3,2,pidx) for k in counts.keys(): if k[0].startswith(&#39;Morgan&#39;) or k[0].startswith(&#39;FeatMorgan&#39;) or k[0].startswith(&#39;RDKit&#39;): continue pidx+=1 cnts = counts[k] plot([x for x,y in cnts],[y for x,y in cnts],label=k[0]) _=title(&#39;others&#39;) _=ylabel(&quot;unique bits observed&quot;) _=yscale(&#39;log&#39;) _=xlabel(&quot;num molecules&quot;) _=legend() tight_layout(); . Notes: . FeatMorgan with r=0 is super boring since there are only 15 types observed and 14 of them appear within the first 10K compounds (the last appears after around 1.2 million compounds). By way of comparison, there are 143 different Morgan0 types observed and the last of those doesn&#39;t show up until after about 5.1 million compounds. | The Avalon fingerprint was 9192 bits long and it ends up setting all essentially of those bits (9185). It probably would have been better to run this with a longer fingerprint. | . How many compounds do we need to look at in order to see particular fractions of the total number of bits there? . bins = (0.9,0.95,0.99) print(&#39;|&#39;,&#39; &#39;*15,&#39;|&#39;,&#39;# unique bits&#39;,&#39;|&#39;,&#39;# in last 100K&#39;,&#39;|&#39;,&#39; | &#39;.join(f&#39;{x:7.2f}&#39; for x in bins),&#39;|&#39;) print(&#39;|&#39;,&#39;-&#39;*15,&#39;|&#39;,&#39;-&#39;*13,&#39;|&#39;,&#39;-&#39;*14,&#39;|&#39;,&#39; | &#39;.join(&#39;-&#39;*7 for x in bins),&#39;|&#39;) for k,cnts in sorted(counts.items()): label = &#39;&#39;.join(str(x) for x in k if x!=-1) maxv = cnts[-1][1] last100K = cnts[-1][1] - cnts[-11][1] if label==&#39;FeatMorgan0&#39;: accum = &#39; | &#39;.join([f&#39;{&quot;N/A&quot;:7s}&#39;]*3) else: accum = [] for bin in bins: for idx in range(len(cnts),0,-1): if cnts[idx-1][1]&lt;bin*maxv: accum.append(cnts[idx-1][0]) break accum = &#39; | &#39;.join(f&#39;{x:7d}&#39; for x in accum) print(&#39;|&#39;,f&#39;{label:15s}&#39;,&#39;|&#39;,f&#39;{maxv:13d}&#39;,&#39;|&#39;,f&#39;{last100K:14d}&#39;,&#39;|&#39;,accum,&#39;|&#39;) . | | # unique bits | # in last 100K | 0.90 | 0.95 | 0.99 | | | - | -- | - | - | - | | FeatMorgan0 | 15 | 0 | N/A | N/A | N/A | | FeatMorgan1 | 1621 | 2 | 2760000 | 4080000 | 5460000 | | FeatMorgan2 | 116975 | 464 | 4000000 | 4870000 | 5750000 | | FeatMorgan3 | 1350464 | 7478 | 4400000 | 5130000 | 5810000 | | Morgan0 | 143 | 0 | 2850000 | 4080000 | 5080000 | | Morgan1 | 19428 | 67 | 3870000 | 4750000 | 5720000 | | Morgan2 | 575817 | 2941 | 4320000 | 5080000 | 5790000 | | Morgan3 | 3606676 | 22970 | 4580000 | 5240000 | 5830000 | | RDKit5 | 131029 | 347 | 3490000 | 4600000 | 5690000 | | RDKit6 | 538500 | 1627 | 3600000 | 4680000 | 5700000 | | RDKit7 | 1989958 | 6897 | 3740000 | 4760000 | 5720000 | | RDKit-linear5 | 49852 | 136 | 3400000 | 4520000 | 5680000 | | RDKit-linear6 | 133904 | 402 | 3480000 | 4570000 | 5690000 | | RDKit-linear7 | 315293 | 1032 | 3570000 | 4640000 | 5700000 | | ap-counts | 16585 | 18 | 2470000 | 3840000 | 5410000 | | avalon | 9185 | 0 | 20000 | 70000 | 490000 | | tt-counts | 20723 | 49 | 3530000 | 4570000 | 5640000 | . What fraction of the overall number of bits appear in the last 100K compounds? . bins = (0.9,0.95,0.99) for k,cnts in sorted(counts.items()): label = &#39;&#39;.join(str(x) for x in k if x!=-1) maxv = cnts[-1][1] last100K = cnts[-1][1] - cnts[-11][1] print(label,last100K/maxv) . FeatMorgan0 0.0 FeatMorgan1 0.0012338062924120913 FeatMorgan2 0.003966659542637315 FeatMorgan3 0.005537356049476328 Morgan0 0.0 Morgan1 0.0034486308420835906 Morgan2 0.005107525481185863 Morgan3 0.006368745071639371 RDKit5 0.0026482687038747147 RDKit6 0.003021355617455896 RDKit7 0.0034659022954253308 RDKit-linear5 0.0027280751023028163 RDKit-linear6 0.003002150794599116 RDKit-linear7 0.00327314593092774 ap-counts 0.0010853180584865843 avalon 0.0 tt-counts 0.002364522511219418 .",
            "url": "https://greglandrum.github.io/rdkit-blog/exploratory/reference/2022/01/04/number-of-unique-fp-bits.html",
            "relUrl": "/exploratory/reference/2022/01/04/number-of-unique-fp-bits.html",
            "date": " • Jan 4, 2022"
        }
        
    
  
    
        ,"post8": {
            "title": "A Ternary GHOST",
            "content": "Intro . When we published the GHOST paper on shifting the decision boundary to improve the predictive performance of classification models built on imbalanced datasets, we only considered binary classifiers (e.g. active/inactive, soluble/insoluble, etc.). I was recently asked if the method could be extended to ternary (three-class) classifiers. This post is about doing that. . The code here isn&#39;t set up for easy re-use at the moment. It will eventually find its way into the open-source ghostml package once we&#39;ve had a chance to review and test it more thoroughly. . Aside:the ghostml package is now pip installable: python -m pip install ghostml to install it in your environment In order for this to make sense, I think I should start with some explanation of the way I&#39;ve approached the problem: . Using thresholds in ternary problems . Things are a bit more complicated here than with binary classifiers. For the binary case we just have a single threshold which determines whether an instance is predicted to be in class 0 or 1. So, assuming that we optimized based on the probability of class 1, we can formulate the decision as: . if probabilities[1] &gt;= threshold: prediction = 1 else: prediction = 0 . Before doing any optimization threshold is equal to 0.5. . For ternary predictions we have two different decision boundaries and there&#39;s no longer a simple threshold; instead the default decision rule can be expressed as: . prediction = argmax(probabilities) . i.e., the prediction is the class which has the highest predicted probability. . Aside:the same decision rule can be used for a binary classifier with the default threshold. It&#39;s just easier to explain using the threshold of 0.5. If we want to introduce two thresholds for the ternary classifier, and assuming that we optimize the thresholds for classes 0 and 2, we have to use a more complex decision rule: . if probabilities[0]&gt;=thresholds[0]: # we might still be in class 2 if the relative probability of that # is larger than the probability of class 0 if (probabilities[2]-thresholds[1])&gt;(probabilities[0]-thresholds[0]): prediction = 2 else: prediction = 0 elif probabilities[2]&gt;=thresholds[1]: prediction = 0 else: prediction = 1 . Optimizing thresholds for ternary problems . For the sake of this post let&#39;s assume that we&#39;re optimizing the thresholds for classes 0 and 2; we could also do 0 and 1, or 1 and 2, the results should still be the same. . In this post I explore two different approaches for optimizing these thresholds. . Greedy optimization . Here I optimize the two thresholds independently of each other by constructing two binary classification problems and optimizing the thresholds for those problems. Here&#39;s the process: . Create a binary classification set by setting the training-set y values to 1 if the original value is 0 and to 0 otherwise. | Use the original ghostml approach with that binary classification data and the predicted probabilities of each training point to be 0 in order to set threshold0, the threshold for the predicted probability of being 0. | Create a binary classification set by setting the training-set y values to 1 if the original value is 2 and to 0 otherwise. | Use the original ghostml approach with that binary classification data and the predicted probabilities of each training point to be 2 in order to set threshold2, the threshold for the predicted probability of being 2. | Since the current ghostml code doesn&#39;t support using balanced accuracy for optimization, I just use kappa for the greedy optimization. . Grid search . Explore the full grid of possible (threshold0, threshold2) pairs and pick the one which produces the optimal Cohen&#39;s kappa value. I also try a variant of this which optimizes balanced accuracy instead of Cohen&#39;s kappa. . TL;DR Results summary . Both approaches work well with both simulated data and a couple of datasets from ChEMBL. There doesn&#39;t seem to be a large or consistent difference in the quality of the results generated with the two different methods. The greedy optimization approach is, however, quite a bit faster. . Here&#39;s the improvement in three scoring metrics (kappa, balanced accuracy, and overall accuracy) when using the greedy optimization procedure on 50 simulated datasets with a 10-80-10 class split; the threshold shift improves both kappa and balanced accuracy on all datasets: . And here&#39;s the same plot for 20 different random stratified train/tests splits with target CHEMBL205 (carbonic anhydrase II) with activity thresholds chosen to give a 19-72-9 class split. Once again, the threshold shift improves predictive performance: . Note: the original version of this notebook and the two CHEMBL data files (file1, file2), are both in github in the older rdkit blog repo. . Beyond ternary problems . I put some thought into figuring out how to extend this to the general multi-class prediction case, but that turned out to be more difficult than I&#39;d anticipated. If you have suggestions, ideally suggestions accompanied by code, please let me know in the comments! . Acknowledgements . Many thanks to Ryo Kunimoto and Takayuki Serizawa at Daiichi Sankyo for inspiring and funding the initial part of this work. . And now onto the code and more detailed exploration . from rdkit import Chem from rdkit.Chem import rdMolDescriptors from rdkit.Chem import rdFingerprintGenerator from rdkit.Chem import PandasTools # note that you can install ghost using pip: python -m pip install ghostml import ghostml import pandas as pd from sklearn import metrics import numpy as np %pylab inline . Populating the interactive namespace from numpy and matplotlib . Code we&#39;ll use . def ternary_rebin(probs,thresholds): &#39;&#39;&#39; returns a list of classifications based on the provided predicted probabilities and thresholds &#39;&#39;&#39; res = [] for prob in probs: if prob[0]&gt;=thresholds[0]: # we might still be in class 2 if the relative probability of that # is larger than the probability of class 0 if (prob[2]-thresholds[1])&gt;(prob[0]-thresholds[0]): res.append(2) else: res.append(0) elif prob[2]&gt;=thresholds[1]: res.append(2) else: res.append(1) return res def run_ternary_oob_optimization(oob_probs, labels_train, thresholds, ThOpt_metrics = &#39;Kappa&#39;): &#39;&#39;&#39; does a grid search to optimize the decision thresholds for a ternary problem &#39;&#39;&#39; res = [] tscores = [] for t1 in thresholds: for t2 in thresholds: preds = ternary_rebin(oob_probs,(t1,t2)) if ThOpt_metrics == &#39;Kappa&#39;: tgt = metrics.cohen_kappa_score(labels_train,preds) elif ThOpt_metrics == &#39;BalancedAccuracy&#39;: tgt = metrics.balanced_accuracy_score(labels_train,preds) elif ThOpt_metrics == &#39;F1&#39;: tgt = metrics.f1_score(labels_train,preds) tscores.append((np.round(tgt,3),(t1,t2))) tscores.sort(reverse=True) thresh = tscores[0][-1] return thresh . from sklearn.ensemble import RandomForestClassifier from sklearn.model_selection import train_test_split def run_ternary_experiment(X,y,accum,random_state=0): &#39;&#39;&#39; experiment wrapper for the ternary bounds optimization &#39;&#39;&#39; n_classes = max(y)+1 local = {} # -- # Train - test split X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y, random_state=random_state) # -- # Train a RF classifier cls = RandomForestClassifier(n_estimators=500,max_depth=10,oob_score=True,n_jobs=8) cls.fit(X_train, y_train) # -- # Calculate the baseline accuracy values test_preds = cls.predict(X_test) test_probs = cls.predict_proba(X_test) kappa = metrics.cohen_kappa_score(y_test,test_preds) balanced = metrics.balanced_accuracy_score(y_test,test_preds) accuracy = metrics.accuracy_score(y_test,test_preds) confusion = metrics.confusion_matrix(y_test,test_preds,labels=list(set(y_test))) print(&#39;original&#39;) print(f&#39;accuracy: {accuracy:.3f} balanced accuracy: {balanced:.3f} kappa: {kappa:.3f}&#39;) print(confusion) local[&#39;orig-accuracy&#39;] = accuracy local[&#39;orig-balanced&#39;] = balanced local[&#39;orig-kappa&#39;] = kappa local[&#39;orig-confusion&#39;] = confusion # -- # optimize the two thresholds individually thresholds = [0]*(n_classes-1) for i,clsv in enumerate((0,2)): d_tform = [1 if y==clsv else 0 for y in y_train] d_probs = [x[clsv] for x in cls.oob_decision_function_] thresholds[i] = ghostml.optimize_threshold_from_oob_predictions(d_tform,d_probs,thresholds=np.arange(0.05,1.0,0.05)) local[&#39;thresholds&#39;] = thresholds # calculate the accuracy values for those thresholds: test_preds = ternary_rebin(test_probs,thresholds) kappa = metrics.cohen_kappa_score(y_test,test_preds) balanced = metrics.balanced_accuracy_score(y_test,test_preds) accuracy = metrics.accuracy_score(y_test,test_preds) confusion = metrics.confusion_matrix(y_test,test_preds,labels=list(set(y_test))) print(&#39;rebalanced&#39;) print(f&#39;thresholds: {thresholds}&#39;) print(f&#39;accuracy: {accuracy:.3f} balanced accuracy: {balanced:.3f} kappa: {kappa:.3f}&#39;) print(confusion) local[&#39;shift-accuracy&#39;] = accuracy local[&#39;shift-balanced&#39;] = balanced local[&#39;shift-kappa&#39;] = kappa local[&#39;shift-confusion&#39;] = confusion # -- # grid-search optimization of the threshold values based on kappa thresholds = run_ternary_oob_optimization(cls.oob_decision_function_,y_train, thresholds=np.arange(0.05,1.00,0.05), ThOpt_metrics = &#39;Kappa&#39;) test_preds = ternary_rebin(test_probs,thresholds) kappa = metrics.cohen_kappa_score(y_test,test_preds) balanced = metrics.balanced_accuracy_score(y_test,test_preds) accuracy = metrics.accuracy_score(y_test,test_preds) confusion = metrics.confusion_matrix(y_test,test_preds,labels=list(set(y_test))) print(&#39;global kappa rebalanced&#39;) print(f&#39;thresholds: {thresholds}&#39;) print(f&#39;accuracy: {accuracy:.3f} balanced accuracy: {balanced:.3f} kappa: {kappa:.3f}&#39;) print(confusion) local[&#39;global-k-shift-accuracy&#39;] = accuracy local[&#39;global-k-shift-balanced&#39;] = balanced local[&#39;global-k-shift-kappa&#39;] = kappa local[&#39;global-k-shift-confusion&#39;] = confusion # -- # grid-search optimization of the threshold values based on the balanced accuracy thresholds = run_ternary_oob_optimization(cls.oob_decision_function_,y_train, thresholds=np.arange(0.05,1.00,0.05), ThOpt_metrics = &#39;BalancedAccuracy&#39;) test_preds = ternary_rebin(test_probs,thresholds) kappa = metrics.cohen_kappa_score(y_test,test_preds) balanced = metrics.balanced_accuracy_score(y_test,test_preds) accuracy = metrics.accuracy_score(y_test,test_preds) confusion = metrics.confusion_matrix(y_test,test_preds,labels=list(set(y_test))) print(&#39;global balanced_accuracy rebalanced&#39;) print(f&#39;thresholds: {thresholds}&#39;) print(f&#39;accuracy: {accuracy:.3f} balanced accuracy: {balanced:.3f} kappa: {kappa:.3f}&#39;) print(confusion) local[&#39;global-ba-shift-accuracy&#39;] = accuracy local[&#39;global-ba-shift-balanced&#39;] = balanced local[&#39;global-ba-shift-kappa&#39;] = kappa local[&#39;global-ba-shift-confusion&#39;] = confusion accum.append(local) . Synthetic datasets . I will try out a couple of real datasets below, but I want to start by verifying that the process works with some synthetic datasest. Scikit-learn&#39;s make_classification() function makes this really easy. . Try a 10-80-10 split . I will test this with multiple different forms of imbalance, just to be sure that it generalizes. Let&#39;s start with an example where the majority class is in the middle: . from sklearn.datasets import make_classification accum_10_80_10 = [] for rep in range(50): print(&#39;--&#39;) # Generate a ternary imbalanced classification problem X, y = make_classification(n_samples=6000, n_features=20, n_informative=10, n_redundant=0, n_classes=3, random_state=0xf00d+rep, shuffle=False, weights = [0.1, 0.8, 0.1]) run_ternary_experiment(X,y,accum_10_80_10) . Start by comparing the model-performance metrics kappa, balanced accuracy, and accuracy between the model with the greedy threshold shift based on kappa and the model with &quot;default thresholds&quot;. . accum = accum_10_80_10 figsize(9,6) scatter([x[&#39;orig-kappa&#39;] for x in accum],[x[&#39;shift-kappa&#39;] for x in accum],label=&#39;kappa&#39;); scatter([x[&#39;orig-balanced&#39;] for x in accum],[x[&#39;shift-balanced&#39;] for x in accum],label=&#39;balanced accuracy&#39;); scatter([x[&#39;orig-accuracy&#39;] for x in accum],[x[&#39;shift-accuracy&#39;] for x in accum],label=&#39;accuracy&#39;); plot([.4,1],[.4,1]); legend(); xlabel(&#39;orig&#39;) ylabel(&#39;greedy shift&#39;); title(&#39;10-80-10&#39;); . The shift improves all three metrics for every dataset. . Now compare the results for using a grid search based on Cohen&#39;s kappa to the greedy shift results: . scatter([x[&#39;shift-kappa&#39;] for x in accum],[x[&#39;global-k-shift-kappa&#39;] for x in accum],label=&#39;kappa&#39;); scatter([x[&#39;shift-balanced&#39;] for x in accum],[x[&#39;global-k-shift-balanced&#39;] for x in accum],label=&#39;balanced accuracy&#39;); scatter([x[&#39;shift-accuracy&#39;] for x in accum],[x[&#39;global-k-shift-accuracy&#39;] for x in accum],label=&#39;accuracy&#39;); plot([.4,1],[.4,1]); legend(); xlabel(&#39;greedy shift&#39;) ylabel(&#39;grid-kappa&#39;); title(&#39;10-80-10&#39;); . Here the changes are reasonably small, but they do tend to slightly favor the results of the grid search. . Finally, do the equivalent plot comparing the result from using balanced accuracy in the grid search to the results from the greedy shift: . scatter([x[&#39;shift-kappa&#39;] for x in accum],[x[&#39;global-ba-shift-kappa&#39;] for x in accum],label=&#39;kappa&#39;); scatter([x[&#39;shift-balanced&#39;] for x in accum],[x[&#39;global-ba-shift-balanced&#39;] for x in accum],label=&#39;balanced accuracy&#39;); scatter([x[&#39;shift-accuracy&#39;] for x in accum],[x[&#39;global-ba-shift-accuracy&#39;] for x in accum],label=&#39;accuracy&#39;); plot([.4,1],[.4,1]); legend(); xlabel(&#39;greedy shift&#39;) ylabel(&#39;grid-balanced&#39;); title(&#39;10-80-10&#39;); . That plot makes it look like doing the threshold shifts using balanced accuracy doesn&#39;t improve kappa, but it&#39;s important to remember that this comparing the balanced accuracy shift vs the kappa shift. . Using balanced accuracy to do the shift instead of kappa does actually help kappa too, as this plot shows: . scatter([x[&#39;orig-kappa&#39;] for x in accum],[x[&#39;global-ba-shift-kappa&#39;] for x in accum],label=&#39;kappa&#39;); scatter([x[&#39;orig-balanced&#39;] for x in accum],[x[&#39;global-ba-shift-balanced&#39;] for x in accum],label=&#39;balanced accuracy&#39;); scatter([x[&#39;orig-accuracy&#39;] for x in accum],[x[&#39;global-ba-shift-accuracy&#39;] for x in accum],label=&#39;accuracy&#39;); plot([.4,1],[.4,1]); legend(); xlabel(&#39;orig&#39;) ylabel(&#39;grid-balanced&#39;); title(&#39;10-80-10&#39;); . Still, with these datasets it looks like optimizing the threshold with kappa instead of balanced accuracy is a better idea. . 0 is the majority class . Now let&#39;s make sure that the code doesn&#39;t have some &quot;feature&quot; which causes it to only work with the middle class is the majority: . accum_80_10_10 = [] for rep in range(50): print(&#39;--&#39;) # Generate a ternary imbalanced classification problem X, y = make_classification(n_samples=6000, n_features=20, n_informative=10, n_redundant=0, n_classes=3, random_state=0xf00d+rep, shuffle=False, weights = [0.8, 0.1, 0.1]) run_ternary_experiment(X,y,accum_80_10_10) . accum = accum_80_10_10 figsize(9,6) scatter([x[&#39;orig-kappa&#39;] for x in accum],[x[&#39;shift-kappa&#39;] for x in accum],label=&#39;kappa&#39;); scatter([x[&#39;orig-balanced&#39;] for x in accum],[x[&#39;shift-balanced&#39;] for x in accum],label=&#39;balanced accuracy&#39;); scatter([x[&#39;orig-accuracy&#39;] for x in accum],[x[&#39;shift-accuracy&#39;] for x in accum],label=&#39;accuracy&#39;); plot([.4,1],[.4,1]); legend(); xlabel(&#39;orig&#39;) ylabel(&#39;greedy shift&#39;); title(&#39;80-10-10&#39;); . scatter([x[&#39;shift-kappa&#39;] for x in accum],[x[&#39;global-k-shift-kappa&#39;] for x in accum],label=&#39;kappa&#39;); scatter([x[&#39;shift-balanced&#39;] for x in accum],[x[&#39;global-k-shift-balanced&#39;] for x in accum],label=&#39;balanced accuracy&#39;); scatter([x[&#39;shift-accuracy&#39;] for x in accum],[x[&#39;global-k-shift-accuracy&#39;] for x in accum],label=&#39;accuracy&#39;); plot([.4,1],[.4,1]); legend(); xlabel(&#39;greedy shift&#39;) ylabel(&#39;grid-kappa&#39;); title(&#39;80-10-10&#39;); . scatter([x[&#39;shift-kappa&#39;] for x in accum],[x[&#39;global-ba-shift-kappa&#39;] for x in accum],label=&#39;kappa&#39;); scatter([x[&#39;shift-balanced&#39;] for x in accum],[x[&#39;global-ba-shift-balanced&#39;] for x in accum],label=&#39;balanced accuracy&#39;); scatter([x[&#39;shift-accuracy&#39;] for x in accum],[x[&#39;global-ba-shift-accuracy&#39;] for x in accum],label=&#39;accuracy&#39;); plot([.4,1],[.4,1]); legend(); xlabel(&#39;greedy shift&#39;) ylabel(&#39;grid-balanced&#39;); title(&#39;80-10-10&#39;); . Same conclusions as before (good thing!) . 2 is the majority class . accum_10_10_80 = [] for rep in range(50): print(&#39;--&#39;) # Generate a ternary imbalanced classification problem X, y = make_classification(n_samples=6000, n_features=20, n_informative=10, n_redundant=0, n_classes=3, random_state=0xf00d+rep, shuffle=False, weights = [0.1, 0.1, 0.8]) run_ternary_experiment(X,y,accum_10_10_80) . accum = accum_10_10_80 figsize(9,6) scatter([x[&#39;orig-kappa&#39;] for x in accum],[x[&#39;shift-kappa&#39;] for x in accum],label=&#39;kappa&#39;); scatter([x[&#39;orig-balanced&#39;] for x in accum],[x[&#39;shift-balanced&#39;] for x in accum],label=&#39;balanced accuracy&#39;); scatter([x[&#39;orig-accuracy&#39;] for x in accum],[x[&#39;shift-accuracy&#39;] for x in accum],label=&#39;accuracy&#39;); plot([.4,1],[.4,1]); legend(); xlabel(&#39;orig&#39;) ylabel(&#39;greedy shift&#39;); title(&#39;10-10-80&#39;); . scatter([x[&#39;shift-kappa&#39;] for x in accum],[x[&#39;global-k-shift-kappa&#39;] for x in accum],label=&#39;kappa&#39;); scatter([x[&#39;shift-balanced&#39;] for x in accum],[x[&#39;global-k-shift-balanced&#39;] for x in accum],label=&#39;balanced accuracy&#39;); scatter([x[&#39;shift-accuracy&#39;] for x in accum],[x[&#39;global-k-shift-accuracy&#39;] for x in accum],label=&#39;accuracy&#39;); plot([.4,1],[.4,1]); legend(); xlabel(&#39;greedy shift&#39;) ylabel(&#39;grid-kappa&#39;); title(&#39;10-10-80&#39;); . scatter([x[&#39;shift-kappa&#39;] for x in accum],[x[&#39;global-ba-shift-kappa&#39;] for x in accum],label=&#39;kappa&#39;); scatter([x[&#39;shift-balanced&#39;] for x in accum],[x[&#39;global-ba-shift-balanced&#39;] for x in accum],label=&#39;balanced accuracy&#39;); scatter([x[&#39;shift-accuracy&#39;] for x in accum],[x[&#39;global-ba-shift-accuracy&#39;] for x in accum],label=&#39;accuracy&#39;); plot([.4,1],[.4,1]); legend(); xlabel(&#39;greedy shift&#39;) ylabel(&#39;grid-balanced&#39;); title(&#39;10-10-80&#39;); . Same conclusions as before (good thing!) . Some ChEMBL datasets . Let&#39;s just be sure that this approach works with bioactivity data too. I don&#39;t think it&#39;s necessary do a comprehensive evaluation here, but I want to show a couple of examples. I didn&#39;t cherry pick these. . CHEMBL205: Carbonic Anhydrase II . data = pd.read_csv(&#39;../data/target_CHEMBL205.csv.gz&#39;) PandasTools.AddMoleculeColumnToFrame(data,smilesCol=&#39;canonical_smiles&#39;) data[&#39;pKi&#39;] = [-math.log10(x*1e-9) for x in data[&#39;standard_value&#39;]] data.head() . compound_chembl_id canonical_smiles standard_value standard_units standard_relation standard_type year ROMol pKi . 0 CHEMBL1054 | NS(=O)(=O)c1cc2c(cc1Cl)NC(C(Cl)Cl)NS2(=O)=O | 91.0 | nM | = | Ki | 2009 | | 7.040959 | . 1 CHEMBL1055 | NS(=O)(=O)c1cc(C2(O)NC(=O)c3ccccc32)ccc1Cl | 138.0 | nM | = | Ki | 2009 | | 6.860121 | . 2 CHEMBL1060 | O=P([O-])([O-])O.[Na+].[Na+] | 13200000.0 | nM | = | Ki | 2004 | | 1.879426 | . 3 CHEMBL106848 | NS(=O)(=O)c1ccc(SCCO)cc1 | 21.0 | nM | = | Ki | 2013 | | 7.677781 | . 4 CHEMBL107217 | CCN(CC)C(=S)[S-].[Na+] | 3100.0 | nM | = | Ki | 2009 | | 5.508638 | . Pick two pKi values for binning . def binner(act,bins=(5,8.5)): for i,bin in enumerate(bins): if act&lt;=bin: return i return len(bins) data[&#39;activity&#39;] = [binner(x) for x in data.pKi] data.groupby(&#39;activity&#39;).describe() . standard_value year pKi . count mean std min 25% 50% 75% max count mean ... 75% max count mean std min 25% 50% 75% max . activity . 0 968.0 | 1.242009e+18 | 3.864224e+19 | 10000.000 | 10000.0000 | 50000.0 | 196700.000 | 1.202264e+21 | 968.0 | 2012.994835 | ... | 2016.0 | 2020.0 | 968.0 | 4.069107 | 1.200449 | -12.080000 | 3.706216 | 4.301030 | 5.000000 | 5.00000 | . 1 3582.0 | 7.292523e+02 | 1.778519e+03 | 3.200 | 13.5000 | 73.4 | 417.750 | 9.900000e+03 | 3582.0 | 2013.261307 | ... | 2017.0 | 2020.0 | 3582.0 | 7.050231 | 0.915651 | 5.004365 | 6.379084 | 7.134306 | 7.869666 | 8.49485 | . 2 427.0 | 1.309327e+00 | 8.709364e-01 | 0.008 | 0.6355 | 1.0 | 2.035 | 3.100000e+00 | 427.0 | 2014.962529 | ... | 2017.0 | 2020.0 | 427.0 | 9.050659 | 0.500779 | 8.508638 | 8.691437 | 9.000000 | 9.196895 | 11.09691 | . 3 rows × 24 columns . Ok, that&#39;s imbalanced :-) . Generate fingerprints: . from rdkit.Chem import SaltRemover sr = SaltRemover.SaltRemover() stripped = [sr.StripMol(m) for m in data.ROMol] fpgen = rdFingerprintGenerator.GetMorganGenerator(radius=2) fps = [fpgen.GetFingerprint(m) for m in stripped] . And now run the experiment with 20 random splits: . accum_chembl205 = [] for i in range(20): run_ternary_experiment(fps,data.activity,accum_chembl205,random_state=0xf00d+i) . accum = accum_chembl205 figsize(9,6) scatter([x[&#39;orig-kappa&#39;] for x in accum],[x[&#39;shift-kappa&#39;] for x in accum],label=&#39;kappa&#39;); scatter([x[&#39;orig-balanced&#39;] for x in accum],[x[&#39;shift-balanced&#39;] for x in accum],label=&#39;balanced accuracy&#39;); scatter([x[&#39;orig-accuracy&#39;] for x in accum],[x[&#39;shift-accuracy&#39;] for x in accum],label=&#39;accuracy&#39;); plot([.4,1],[.4,1]); legend(); xlabel(&#39;orig&#39;) ylabel(&#39;greedy shift&#39;); title(&#39;CHEMBL205&#39;); . scatter([x[&#39;shift-kappa&#39;] for x in accum],[x[&#39;global-k-shift-kappa&#39;] for x in accum],label=&#39;kappa&#39;); scatter([x[&#39;shift-balanced&#39;] for x in accum],[x[&#39;global-k-shift-balanced&#39;] for x in accum],label=&#39;balanced accuracy&#39;); scatter([x[&#39;shift-accuracy&#39;] for x in accum],[x[&#39;global-k-shift-accuracy&#39;] for x in accum],label=&#39;accuracy&#39;); plot([.4,1],[.4,1]); legend(); xlabel(&#39;greedy shift&#39;) ylabel(&#39;grid-kappa&#39;); title(&#39;CHEMBL205&#39;); . scatter([x[&#39;shift-kappa&#39;] for x in accum],[x[&#39;global-ba-shift-kappa&#39;] for x in accum],label=&#39;kappa&#39;); scatter([x[&#39;shift-balanced&#39;] for x in accum],[x[&#39;global-ba-shift-balanced&#39;] for x in accum],label=&#39;balanced accuracy&#39;); scatter([x[&#39;shift-accuracy&#39;] for x in accum],[x[&#39;global-ba-shift-accuracy&#39;] for x in accum],label=&#39;accuracy&#39;); plot([.4,1],[.4,1]); legend(); xlabel(&#39;greedy shift&#39;) ylabel(&#39;grid-balanced&#39;); title(&#39;CHEMBL205&#39;); . We see the same behavior as before: shifting the descision thresholds using either the greedy approach or grid-based approach improves prediction accuracy over the default decision thresholds. . CHEMBL217: Dopamine D2 . data = pd.read_csv(&#39;../data/target_CHEMBL217.csv.gz&#39;) PandasTools.AddMoleculeColumnToFrame(data,smilesCol=&#39;canonical_smiles&#39;) data[&#39;pKi&#39;] = [-math.log10(x*1e-9) for x in data[&#39;standard_value&#39;]] def binner(act,bins=(5,8)): for i,bin in enumerate(bins): if act&lt;=bin: return i return len(bins) data[&#39;activity&#39;] = [binner(x) for x in data.pKi] data.groupby(&#39;activity&#39;).describe() . standard_value year pKi . count mean std min 25% 50% 75% max count mean ... 75% max count mean std min 25% 50% 75% max . activity . 0 356.0 | 143415.189354 | 781194.668326 | 10000.000 | 10000.0000 | 10000.00 | 24234.5 | 10000000.00 | 356.0 | 2011.679775 | ... | 2017.0 | 2019.0 | 356.0 | 4.672916 | 0.581865 | 2.000000 | 4.615626 | 5.000000 | 5.000000 | 5.000000 | . 1 4014.0 | 830.546163 | 1471.610125 | 10.000 | 63.1875 | 238.51 | 931.0 | 9906.00 | 4014.0 | 2011.100648 | ... | 2015.0 | 2020.0 | 4014.0 | 6.620074 | 0.724919 | 5.004102 | 6.031050 | 6.622494 | 7.199370 | 8.000000 | . 2 607.0 | 3.715942 | 2.786155 | 0.027 | 1.2150 | 3.00 | 5.9 | 9.86 | 607.0 | 2011.957166 | ... | 2016.0 | 2019.0 | 607.0 | 8.614671 | 0.475862 | 8.006123 | 8.229148 | 8.522879 | 8.915457 | 10.568636 | . 3 rows × 24 columns . from rdkit.Chem import SaltRemover sr = SaltRemover.SaltRemover() stripped = [sr.StripMol(m) for m in data.ROMol] fpgen = rdFingerprintGenerator.GetMorganGenerator(radius=2) fps = [fpgen.GetFingerprint(m) for m in stripped] . accum_chembl217 = [] for i in range(20): run_ternary_experiment(fps,data.activity,accum_chembl217,random_state=0xf00d+i) . accum = accum_chembl217 figsize(9,6) scatter([x[&#39;orig-kappa&#39;] for x in accum],[x[&#39;shift-kappa&#39;] for x in accum],label=&#39;kappa&#39;); scatter([x[&#39;orig-balanced&#39;] for x in accum],[x[&#39;shift-balanced&#39;] for x in accum],label=&#39;balanced accuracy&#39;); scatter([x[&#39;orig-accuracy&#39;] for x in accum],[x[&#39;shift-accuracy&#39;] for x in accum],label=&#39;accuracy&#39;); plot([.2,1],[.2,1]); legend(); xlabel(&#39;orig&#39;) ylabel(&#39;greedy shift&#39;); title(&#39;CHEMBL217&#39;); . scatter([x[&#39;shift-kappa&#39;] for x in accum],[x[&#39;global-k-shift-kappa&#39;] for x in accum],label=&#39;kappa&#39;); scatter([x[&#39;shift-balanced&#39;] for x in accum],[x[&#39;global-k-shift-balanced&#39;] for x in accum],label=&#39;balanced accuracy&#39;); scatter([x[&#39;shift-accuracy&#39;] for x in accum],[x[&#39;global-k-shift-accuracy&#39;] for x in accum],label=&#39;accuracy&#39;); plot([.4,1],[.4,1]); legend(); xlabel(&#39;greedy shift&#39;) ylabel(&#39;grid-kappa&#39;); title(&#39;CHEMBL217&#39;); . scatter([x[&#39;shift-kappa&#39;] for x in accum],[x[&#39;global-ba-shift-kappa&#39;] for x in accum],label=&#39;kappa&#39;); scatter([x[&#39;shift-balanced&#39;] for x in accum],[x[&#39;global-ba-shift-balanced&#39;] for x in accum],label=&#39;balanced accuracy&#39;); scatter([x[&#39;shift-accuracy&#39;] for x in accum],[x[&#39;global-ba-shift-accuracy&#39;] for x in accum],label=&#39;accuracy&#39;); plot([.4,1],[.4,1]); legend(); xlabel(&#39;greedy shift&#39;) ylabel(&#39;grid-balanced&#39;); title(&#39;CHEMBL217&#39;); . Again, the same conclusions hold here. .",
            "url": "https://greglandrum.github.io/rdkit-blog/exploratory/machinelearning/2021/12/23/ternary-ghost.html",
            "relUrl": "/exploratory/machinelearning/2021/12/23/ternary-ghost.html",
            "date": " • Dec 23, 2021"
        }
        
    
  
    
        ,"post9": {
            "title": "Some new features in the SubstructLibrary",
            "content": "Earlier this year I did a blog post on &quot;Generalized substructure search&quot; with the RDKit. That demonstrated how to use some advanced query features like link nodes, variable attachment points, and tautomer insensitivity to search through the compounds from ChEMBL 29 with the RDKit&#39;s SubstructLibrary. . This post uses the same ChEMBL 29 SubstructLibrary to demonstrate a couple of new features which were added in the 2021.09 release of the RDKit: . Changing the search order | Specifying which compounds are actually searched | Saving a molecule key (or name) together with the molecules in the SubstructLibrary | For more about the SubstructLibrary, take a look at this earlier post about generalized substructure search. . from rdkit import Chem from rdkit.Chem.Draw import IPythonConsole from rdkit.Chem import Draw from rdkit.Chem import rdSubstructLibrary from rdkit import RDLogger from rdkit import rdBase import pickle import time import gzip print(rdBase.rdkitVersion) print(time.asctime()) . 2021.09.3 Mon Dec 20 05:14:01 2021 . Here&#39;s the code to build the SubstructLibrary from the sdf file distributed by the ChEMBL team. This uses a feature added in RDKit v2021.09 to allow a molecule key (or name) to be stored with the molecules in a SubstructLibrary. . Executing this takes about 45 minutes on my machine. . RDLogger.DisableLog(&quot;rdApp.warning&quot;) molholder = rdSubstructLibrary.CachedTrustedSmilesMolHolder() patts = rdSubstructLibrary.TautomerPatternHolder() # this will automatically grab the &quot;_Name&quot; property for each molecule # in the ChEMBL SD file this contains the ChEMBL ID for the molecules. keys = rdSubstructLibrary.KeyFromPropHolder() slib = rdSubstructLibrary.SubstructLibrary(molholder,patts,keys) t1 = time.time() with gzip.GzipFile(&#39;/home/glandrum/Downloads/chembl_29.sdf.gz&#39;) as gz, Chem.ForwardSDMolSupplier(gz) as suppl: nDone = 0 for m in suppl: if m is None: continue # skip huge molecules if m.GetNumHeavyAtoms()&gt;75: continue slib.AddMol(m) nDone += 1 if not nDone%50000: print(f&#39; did {nDone} in {time.time()-t1:.2f}s&#39;) with open(&#39;./results/chembl29_ssslib.pkl&#39;,&#39;wb+&#39;) as outf: pickle.dump(slib,outf) print(f&#39;That took {time.time()-t1:.2f}s in total.&#39;) with open(&#39;./results/chembl29_ssslib.pkl&#39;,&#39;wb+&#39;) as outf: pickle.dump(slib,outf) We&#39;re going to use the number of heavy atoms to determine the search order. Since that takes a while, go ahead and pre-calculate those values and store them in the same pickle file as the SubstructLibrary: . holder = slib.GetMolHolder() nats = sorted([(holder.GetMol(x).GetNumHeavyAtoms(),x) for x in range(len(slib))]) order = [y for x,y in nats] # append that to the pickle file with the substruct lib: with open(&#39;./results/chembl29_ssslib.pkl&#39;,&#39;ab&#39;) as outf: pickle.dump(order,outf) Read in the saved data: . with open(&#39;./results/chembl29_ssslib.pkl&#39;,&#39;rb&#39;) as inf: slib = pickle.load(inf) nat_order = pickle.load(inf) . Here&#39;s the query we&#39;ll use for this post: . qry = Chem.MolFromSmarts(&#39;[O,N]=C-c:1:c:c:n:c:c:1&#39;) qry . Let&#39;s look at doing a search. We also take advantage of the SubstructLibrary&#39;s KeyHolder (a new feature in v2021.09) to include the compound ChEMBL IDs in the results: . mids = slib.GetMatches(qry) print(f&#39;{len(mids)} results&#39;) ms = [slib.GetMolHolder().GetMol(x) for x in mids[:9]] legends = [slib.GetKeyHolder().GetKey(x) for x in mids[:9]] Draw.MolsToGridImage(ms,legends=legends,subImgSize=(250,200)) . 1000 results . One of the new features is that we can change the search order; this allows us to get the smallest molecules first (always a good idea with a substructure search). . Here we&#39;re using the number of heavy atoms to set the search order: . slib.SetSearchOrder(nat_order) mids = slib.GetMatches(qry) print(f&#39;{len(mids)} results&#39;) ms = [slib.GetMolHolder().GetMol(x) for x in mids[:9]] legends = [slib.GetKeyHolder().GetKey(x) for x in mids[:9]] Draw.MolsToGridImage(ms,legends=legends,subImgSize=(250,200)) . 1000 results . It&#39;s important to note that we are not just sorting the results from the search here: we&#39;re changing the order in which the search is done. So even though we&#39;re only getting 1000 results (the default max number of results from the SubstructLibrary), we know that they are the 1000 smallest results. . So if we change the maximum number of results to three, we&#39;ll get the same first three results: . slib.SetSearchOrder(nat_order) mids2 = slib.GetMatches(qry,maxResults=3) print(f&#39;{len(mids2)} results&#39;) ms = [slib.GetMolHolder().GetMol(x) for x in mids2[:9]] legends = [slib.GetKeyHolder().GetKey(x) for x in mids2[:9]] Draw.MolsToGridImage(ms,legends=legends,subImgSize=(250,200)) . 3 results . We can also use the search order to limit the compounds we search. In this case I&#39;m going to refine the results of the previous search and identify compounds which also contain Br: . slib.SetSearchOrder(mids) mids_new = slib.GetMatches(Chem.MolFromSmarts(&#39;[Br]&#39;)) print(f&#39;{len(mids_new)} sub-results&#39;) ms = [slib.GetMolHolder().GetMol(x) for x in mids_new[:9]] legends = [slib.GetKeyHolder().GetKey(x) for x in mids_new[:9]] Draw.MolsToGridImage(ms,legends=legends,subImgSize=(250,200)) . 66 sub-results . Notice that the results are still coming back sorted by the number of heavy atoms. That&#39;s because the IDs of the molecules being used for the search search is sorted. . We almost certainly ran up against the default limit on the number of results (1000 compounds) when doing the first search. Let&#39;s loosen that to 50K. This will take longer since the first query ends up having to run through the entire database. . slib.SetSearchOrder(nat_order) mids = slib.GetMatches(qry,maxResults=50000) print(f&#39;{len(mids)} results&#39;) slib.SetSearchOrder(mids) mids_new = slib.GetMatches(Chem.MolFromSmarts(&#39;[Br]&#39;)) print(f&#39;{len(mids_new)} sub-results&#39;) . 17764 results 919 sub-results . It&#39;s never a bad idea to check the performance of these queries. . Here&#39;s the run time for the default value of maxResults: . slib.SetSearchOrder(nat_order) %timeit mids = slib.GetMatches(qry) . 71.7 ms ± 710 µs per loop (mean ± std. dev. of 7 runs, 10 loops each) . And here&#39;s the search time for going through the entire database (we only get 17K results here, so maxResults=50K corresponds to searching through the entire database): . slib.SetSearchOrder(nat_order) %timeit mids = slib.GetMatches(qry,maxResults=50000) . 5.09 s ± 79.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) .",
            "url": "https://greglandrum.github.io/rdkit-blog/tutorial/substructure/2021/12/20/substructlibrary-search-order.html",
            "relUrl": "/tutorial/substructure/2021/12/20/substructlibrary-search-order.html",
            "date": " • Dec 20, 2021"
        }
        
    
  
    
        ,"post10": {
            "title": "Using single-molecule reactions",
            "content": "This short post was inspired by a recent question on the RDKit-discuss mailing list: https://www.mail-archive.com/rdkit-discuss@lists.sourceforge.net/msg10905.html . The idea is to provide a quick introduction to a piece of chemical reaction functionality which was added to the 2021.09 RDKit release. . from rdkit import Chem from rdkit.Chem import rdChemReactions from rdkit.Chem.Draw import IPythonConsole from rdkit.Chem import Draw import rdkit print(rdkit.__version__) . 2021.09.3 . This was the molecule that Lewis asked about. . m1 = Chem.MolFromSmiles(&#39;COC(=O)C1=C(C=CC=C1)C1=CC=C(C[N+]#[N]=[N-])C=C1&#39;,sanitize=False) m1 . The RDKit won&#39;t accept this with default settings because there&#39;s an odd representation of an azide group which includes a five-valent neutral nitrogen. . It&#39;s straight forward to define a reaction which can convert this odd azide form to the more normal variant: . tf1 = rdChemReactions.ReactionFromSmarts(&#39;[#6:1]-[N+:2]#[N:3]=[N-:4]&gt;&gt;[#6:1]-[N+0:2]=[N+1:3]=[N-:4]&#39;) tf1 . The usual way to use this would be with the RunReactants() method, which returns a list of lists of new molecules. In this case though, we have a reaction which operates on a single reactant and has a single product, so we can take advantage of the new RunReactantInPlace() method. . As the method name implies, this modifies the reactant molecule in place instead of creating new molecules which are returned as products: . tf1.RunReactantInPlace(m1) # now sanitize the molecule so that we do chemistry perception and can get decent drawings: Chem.SanitizeMol(m1) m1 . It&#39;s important to note that his only modifies one match at a time, so if we have multiple functional groups which need to be modified, we&#39;ll need to call RunReactantInPlace() multiple times. . Here&#39;s a demonstration of that using a molecule which has two of these weird azide constructions . m1 = Chem.MolFromSmiles(&#39;c1cc([N+]#[N]=[N-])ccc1[N+]#[N]=[N-]&#39;,sanitize=False) m1 . The first application of RunReactantInPlace() changes one of the groups: . tf1.RunReactantInPlace(m1) m1 . If we call RunReactantInPlace() again, the second occurance is replaced: . tf1.RunReactantInPlace(m1) m1 . RunReactantInPlace() makes it easy to know when to stop because it returns a boolean letting you know whether or not the molecule was modified. So in this case we&#39;ll get false: . tf1.RunReactantInPlace(m1) . False . This makes it easy to do all the transformations to a molecule with a while loop: . m1 = Chem.MolFromSmiles(&#39;c1cc([N+]#[N]=[N-])ccc1[N+]#[N]=[N-]&#39;,sanitize=False) while tf1.RunReactantInPlace(m1): pass Chem.SanitizeMol(m1) m1 . RunReactantInPlace() is limited, it can only be used with reactions which only have one reactant and product and which do not add atoms in the product. . tf2 = rdChemReactions.ReactionFromSmarts(&#39;[#6:1]-[NH2:2]&gt;&gt;[#6:1]-[NH2:2]C&#39;) tmp = Chem.MolFromSmiles(&#39;CCN&#39;) tf2.RunReactantInPlace(tmp) . ValueError Traceback (most recent call last) &lt;ipython-input-10-98e2aab1842b&gt; in &lt;module&gt; 1 tf2 = rdChemReactions.ReactionFromSmarts(&#39;[#6:1]-[NH2:2]&gt;&gt;[#6:1]-[NH2:2]C&#39;) 2 tmp = Chem.MolFromSmiles(&#39;CCN&#39;) -&gt; 3 tf2.RunReactantInPlace(tmp) ValueError: ChemicalParserException: single component reactions which add atoms in the product are not supported . Note that it can be used with reactions which remove atoms: . tf2 = rdChemReactions.ReactionFromSmarts(&#39;[#6:1]-[NH2:2]&gt;&gt;[#6:1]&#39;) tmp = Chem.MolFromSmiles(&#39;CCN&#39;) tf2.RunReactantInPlace(tmp) . True . tmp . Aside from being easier to use when working with this simple transformations, it&#39;s worth pointing out that RunReactantInPlace() is significantly faster than using RunReactants() with the same reaction: . m1 = Chem.MolFromSmiles(&#39;COC(=O)C1=C(C=CC=C1)C1=CC=C(C[N+]#[N]=[N-])C=C1&#39;,sanitize=False) %timeit tf1.RunReactantInPlace(Chem.Mol(m1)) . 9.93 µs ± 125 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each) . m1 = Chem.MolFromSmiles(&#39;COC(=O)C1=C(C=CC=C1)C1=CC=C(C[N+]#[N]=[N-])C=C1&#39;,sanitize=False) %timeit tf1.RunReactants((Chem.Mol(m1),)) . 22.6 µs ± 81.2 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each) .",
            "url": "https://greglandrum.github.io/rdkit-blog/tutorial/reactions/2021/12/15/single-molecule-reactions.html",
            "relUrl": "/tutorial/reactions/2021/12/15/single-molecule-reactions.html",
            "date": " • Dec 15, 2021"
        }
        
    
  
    
        ,"post11": {
            "title": "Highlighting changing atoms and bonds in reactions",
            "content": "A while ago there was a question on Twitter about highlighting the bonds which changed in a reaction. I put together a quick bit of example code to answer that question and made a note to do a blog post on the topic. I&#39;m finally getting around to doing that blog post. . Fair warning: This one is heavy on code and light on words. :-) . from rdkit import Chem from rdkit.Chem import Draw from rdkit.Chem.Draw import IPythonConsole from rdkit.Chem import rdChemReactions import rdkit print(rdkit.__version__) . 2021.09.2 . Here&#39;s something similar to the reaction from the question: . rxn1 = rdChemReactions.ReactionFromRxnBlock(&#39;&#39;&#39;$RXN Mrv2102 111820212128 2 1 $MOL Mrv2102 11182121282D 13 13 0 0 0 0 999 V2000 -7.5723 2.6505 0.0000 C 0 0 0 0 0 0 0 0 0 1 0 0 -6.8579 2.2380 0.0000 O 0 0 0 0 0 0 0 0 0 2 0 0 -6.8580 1.4130 0.0000 C 0 0 0 0 0 0 0 0 0 3 0 0 -6.1435 1.0004 0.0000 O 0 0 0 0 0 0 0 0 0 4 0 0 -7.5725 1.0005 0.0000 C 0 0 0 0 0 0 0 0 0 5 0 0 -7.5725 0.1755 0.0000 N 0 0 0 0 0 0 0 0 0 6 0 0 -8.2869 -0.2369 0.0000 C 0 0 0 0 0 0 0 0 0 7 0 0 -8.2870 -1.0620 0.0000 C 0 0 0 0 0 0 0 0 0 8 0 0 -9.0015 -1.4745 0.0000 C 0 0 0 0 0 0 0 0 0 9 0 0 -9.0015 -2.2995 0.0000 C 0 0 0 0 0 0 0 0 0 10 0 0 -8.2870 -2.7120 0.0000 C 0 0 0 0 0 0 0 0 0 11 0 0 -7.5726 -2.2995 0.0000 C 0 0 0 0 0 0 0 0 0 12 0 0 -7.5726 -1.4745 0.0000 C 0 0 0 0 0 0 0 0 0 13 0 0 1 2 1 0 0 0 0 2 3 1 0 0 0 0 3 4 2 0 0 0 0 3 5 1 0 0 0 0 5 6 1 0 0 0 0 6 7 2 0 0 0 0 7 8 1 0 0 0 0 8 9 1 0 0 0 0 8 13 2 0 0 0 0 9 10 2 0 0 0 0 10 11 1 0 0 0 0 11 12 2 0 0 0 0 12 13 1 0 0 0 0 M END $MOL Mrv2102 11182121282D 12 11 0 0 0 0 999 V2000 -3.7934 0.7703 0.0000 C 0 0 0 0 0 0 0 0 0 14 0 0 -3.0790 1.1828 0.0000 C 0 0 0 0 0 0 0 0 0 15 0 0 -2.3645 0.7703 0.0000 C 0 0 0 0 0 0 0 0 0 16 0 0 -3.7934 -0.0547 0.0000 C 0 0 0 0 0 0 0 0 0 17 0 0 -4.5078 -0.4672 0.0000 O 0 0 0 0 0 0 0 0 0 18 0 0 -3.0789 -0.4671 0.0000 O 0 0 0 0 0 0 0 0 0 19 0 0 -1.6500 1.1828 0.0000 O 0 0 0 0 0 0 0 0 0 20 0 0 -2.3645 -0.0547 0.0000 O 0 0 0 0 0 0 0 0 0 21 0 0 -3.0788 -1.2922 0.0000 C 0 0 0 0 0 0 0 0 0 22 0 0 -1.6500 -0.4672 0.0000 C 0 0 0 0 0 0 0 0 0 23 0 0 -2.3644 -1.7046 0.0000 C 0 0 0 0 0 0 0 0 0 24 0 0 -1.6500 -1.2922 0.0000 C 0 0 0 0 0 0 0 0 0 25 0 0 1 2 2 0 0 0 0 1 4 1 0 0 0 0 2 3 1 0 0 0 0 3 7 2 0 0 0 0 3 8 1 0 0 0 0 4 5 2 0 0 0 0 4 6 1 0 0 0 0 6 9 1 0 0 0 0 8 10 1 0 0 0 0 9 11 1 0 0 0 0 10 12 1 0 0 0 0 M END $MOL Mrv2102 11182121282D 25 26 0 0 0 0 999 V2000 5.1328 0.9532 0.0000 C 0 0 0 0 0 0 0 0 0 5 0 0 5.8002 0.4683 0.0000 N 0 0 0 0 0 0 0 0 0 6 0 0 5.5453 -0.3163 0.0000 C 0 0 0 0 0 0 0 0 0 7 0 0 4.7203 -0.3163 0.0000 C 0 0 0 0 0 0 0 0 0 14 0 0 4.4654 0.4683 0.0000 C 0 0 0 0 0 0 0 0 0 15 0 0 5.1328 1.7782 0.0000 C 0 0 0 0 0 0 0 0 0 3 0 0 3.6807 0.7232 0.0000 C 0 0 0 0 0 0 0 0 0 16 0 0 4.2354 -0.9838 0.0000 C 0 0 0 0 0 0 0 0 0 17 0 0 6.0302 -0.9838 0.0000 C 0 0 0 0 0 0 0 0 0 8 0 0 6.8507 -0.8975 0.0000 C 0 0 0 0 0 0 0 0 0 9 0 0 7.3356 -1.5650 0.0000 C 0 0 0 0 0 0 0 0 0 10 0 0 7.0001 -2.3187 0.0000 C 0 0 0 0 0 0 0 0 0 11 0 0 6.1796 -2.4049 0.0000 C 0 0 0 0 0 0 0 0 0 12 0 0 5.6947 -1.7375 0.0000 C 0 0 0 0 0 0 0 0 0 13 0 0 3.4149 -0.8975 0.0000 O 0 0 0 0 0 0 0 0 0 18 0 0 4.5709 -1.7375 0.0000 O 0 0 0 0 0 0 0 0 0 19 0 0 4.0860 -2.4049 0.0000 C 0 0 0 0 0 0 0 0 0 22 0 0 3.2655 -2.3187 0.0000 C 0 0 0 0 0 0 0 0 0 24 0 0 3.5092 1.5302 0.0000 O 0 0 0 0 0 0 0 0 0 20 0 0 3.0676 0.1712 0.0000 O 0 0 0 0 0 0 0 0 0 21 0 0 2.2830 0.4261 0.0000 C 0 0 0 0 0 0 0 0 0 23 0 0 1.6699 -0.1259 0.0000 C 0 0 0 0 0 0 0 0 0 25 0 0 5.8473 2.1907 0.0000 O 0 0 0 0 0 0 0 0 0 4 0 0 4.4183 2.1907 0.0000 O 0 0 0 0 0 0 0 0 0 2 0 0 4.4183 3.0157 0.0000 C 0 0 0 0 0 0 0 0 0 1 0 0 1 2 1 0 0 0 0 2 3 1 0 0 0 0 3 4 1 0 0 0 0 4 5 1 0 0 0 0 1 5 1 0 0 0 0 1 6 1 0 0 0 0 5 7 1 0 0 0 0 4 8 1 0 0 0 0 3 9 1 0 0 0 0 10 11 2 0 0 0 0 11 12 1 0 0 0 0 12 13 2 0 0 0 0 13 14 1 0 0 0 0 9 10 1 0 0 0 0 9 14 2 0 0 0 0 8 15 2 0 0 0 0 8 16 1 0 0 0 0 16 17 1 0 0 0 0 17 18 1 0 0 0 0 7 19 2 0 0 0 0 7 20 1 0 0 0 0 20 21 1 0 0 0 0 21 22 1 0 0 0 0 6 23 2 0 0 0 0 6 24 1 0 0 0 0 24 25 1 0 0 0 0 M END &#39;&#39;&#39;) . Let&#39;s take a look at the reaction: . IPythonConsole.molSize = (600,250) IPythonConsole.highlightByReactant = True rxn1 . We can ask the reaction to tell us which atoms in the reactants are modified in the reaction: . rxn1.Initialize() rxn1.GetReactingAtoms() . ((4, 5, 6), (0, 1)) . The information about which atoms react is enough to figure out which bonds change, but we have to do some additional work for this: . from collections import namedtuple AtomInfo = namedtuple(&#39;AtomInfo&#39;,(&#39;mapnum&#39;,&#39;reactant&#39;,&#39;reactantAtom&#39;,&#39;product&#39;,&#39;productAtom&#39;)) def map_reacting_atoms_to_products(rxn,reactingAtoms): &#39;&#39;&#39; figures out which atoms in the products each mapped atom in the reactants maps to &#39;&#39;&#39; res = [] for ridx,reacting in enumerate(reactingAtoms): reactant = rxn.GetReactantTemplate(ridx) for raidx in reacting: mapnum = reactant.GetAtomWithIdx(raidx).GetAtomMapNum() foundit=False for pidx,product in enumerate(rxn.GetProducts()): for paidx,patom in enumerate(product.GetAtoms()): if patom.GetAtomMapNum()==mapnum: res.append(AtomInfo(mapnum,ridx,raidx,pidx,paidx)) foundit = True break if foundit: break return res def get_mapped_neighbors(atom): &#39;&#39;&#39; test all mapped neighbors of a mapped atom&#39;&#39;&#39; res = {} amap = atom.GetAtomMapNum() if not amap: return res for nbr in atom.GetNeighbors(): nmap = nbr.GetAtomMapNum() if nmap: if amap&gt;nmap: res[(nmap,amap)] = (atom.GetIdx(),nbr.GetIdx()) else: res[(amap,nmap)] = (nbr.GetIdx(),atom.GetIdx()) return res BondInfo = namedtuple(&#39;BondInfo&#39;,(&#39;product&#39;,&#39;productAtoms&#39;,&#39;productBond&#39;,&#39;status&#39;)) def find_modifications_in_products(rxn): &#39;&#39;&#39; returns a 2-tuple with the modified atoms and bonds from the reaction &#39;&#39;&#39; reactingAtoms = rxn.GetReactingAtoms() amap = map_reacting_atoms_to_products(rxn,reactingAtoms) res = [] seen = set() # this is all driven from the list of reacting atoms: for _,ridx,raidx,pidx,paidx in amap: reactant = rxn.GetReactantTemplate(ridx) ratom = reactant.GetAtomWithIdx(raidx) product = rxn.GetProductTemplate(pidx) patom = product.GetAtomWithIdx(paidx) rnbrs = get_mapped_neighbors(ratom) pnbrs = get_mapped_neighbors(patom) for tpl in pnbrs: pbond = product.GetBondBetweenAtoms(*pnbrs[tpl]) if (pidx,pbond.GetIdx()) in seen: continue seen.add((pidx,pbond.GetIdx())) if not tpl in rnbrs: # new bond in product res.append(BondInfo(pidx,pnbrs[tpl],pbond.GetIdx(),&#39;New&#39;)) else: # present in both reactants and products, check to see if it changed rbond = reactant.GetBondBetweenAtoms(*rnbrs[tpl]) if rbond.GetBondType()!=pbond.GetBondType(): res.append(BondInfo(pidx,pnbrs[tpl],pbond.GetIdx(),&#39;Changed&#39;)) return amap,res . Let&#39;s look at what that function returns for our reaction: . atms,bnds = find_modifications_in_products(rxn1) print(atms) print(bnds) . [AtomInfo(mapnum=5, reactant=0, reactantAtom=4, product=0, productAtom=0), AtomInfo(mapnum=6, reactant=0, reactantAtom=5, product=0, productAtom=1), AtomInfo(mapnum=7, reactant=0, reactantAtom=6, product=0, productAtom=2), AtomInfo(mapnum=14, reactant=1, reactantAtom=0, product=0, productAtom=3), AtomInfo(mapnum=15, reactant=1, reactantAtom=1, product=0, productAtom=4)] [BondInfo(product=0, productAtoms=(4, 0), productBond=4, status=&#39;New&#39;), BondInfo(product=0, productAtoms=(2, 1), productBond=1, status=&#39;Changed&#39;), BondInfo(product=0, productAtoms=(3, 2), productBond=2, status=&#39;New&#39;), BondInfo(product=0, productAtoms=(4, 3), productBond=3, status=&#39;Changed&#39;)] . Finally, define the funciton which we&#39;ll use to draw the product molecule with highlights shown for bonds and atoms involved in the reaction: . from IPython.display import Image def draw_product_with_modified_bonds(rxn,atms,bnds,productIdx=None,showAtomMaps=False): if productIdx is None: pcnts = [x.GetNumAtoms() for x in rxn.GetProducts()] largestProduct = list(sorted(zip(pcnts,range(len(pcnts))),reverse=True))[0][1] productIdx = largestProduct d2d = Draw.rdMolDraw2D.MolDraw2DCairo(350,300) pmol = Chem.Mol(rxn.GetProductTemplate(productIdx)) Chem.SanitizeMol(pmol) if not showAtomMaps: for atom in pmol.GetAtoms(): atom.SetAtomMapNum(0) bonds_to_highlight=[] highlight_bond_colors={} atoms_seen = set() for binfo in bnds: if binfo.product==productIdx and binfo.status==&#39;New&#39;: bonds_to_highlight.append(binfo.productBond) atoms_seen.update(binfo.productAtoms) highlight_bond_colors[binfo.productBond] = (1,.4,.4) if binfo.product==productIdx and binfo.status==&#39;Changed&#39;: bonds_to_highlight.append(binfo.productBond) atoms_seen.update(binfo.productAtoms) highlight_bond_colors[binfo.productBond] = (.4,.4,1) atoms_to_highlight=set() for ainfo in atms: if ainfo.product != productIdx or ainfo.productAtom in atoms_seen: continue atoms_to_highlight.add(ainfo.productAtom) d2d.drawOptions().useBWAtomPalette() d2d.drawOptions().continuousHighlight=False d2d.drawOptions().highlightBondWidthMultiplier = 24 d2d.drawOptions().setHighlightColour((.9,.9,0)) d2d.drawOptions().fillHighlights=False atoms_to_highlight.update(atoms_seen) d2d.DrawMolecule(pmol,highlightAtoms=atoms_to_highlight,highlightBonds=bonds_to_highlight, highlightBondColors=highlight_bond_colors) d2d.FinishDrawing() return d2d.GetDrawingText() . Now we can draw the highlighted product molecule: . Image(draw_product_with_modified_bonds(rxn1,atms,bnds)) . Let&#39;s look at some other reactions. I will use the SI data from . import pandas as pd df = pd.read_csv(&#39;../data/reaction_data_ci6b00564/dataSetB.csv&#39;) df.head() . rxn_Class patentID rxnSmiles_Mapping_NameRxn reactantSet_NameRxn NameRxn_Mapping_Complete rxnSmiles_Mapping_IndigoTK reactantSet_IndigoTK IndigoTK_Mapping_Complete rxnSmiles_IndigoAutoMapperKNIME reactantSet_IndigoAutoMapperKNIME IndigoAutoMapperKNIME_Mapping_Complete . 0 6 | US05849732 | C.CCCCCC.CO.O=C(OCc1ccccc1)[NH:1][CH2:2][CH2:3... | set([3, 4]) | True | C(OC([NH:11][CH2:12][CH2:13][CH2:14][CH2:15][C... | set([0, 2]) | True | C.CCCCCC.CO.[CH3:10][O:11][C:12]([C@@H:14]([NH... | set([3, 4]) | True | . 1 2 | US20120114765A1 | O[C:1](=[O:2])[c:3]1[cH:4][c:5]([N+:6](=[O:7])... | set([0, 1]) | True | [Cl:1][c:2]1[cH:3][n:4][cH:5][c:6]([Cl:20])[c:... | set([0, 1]) | True | [NH2:1][c:2]1[c:11]2[c:6]([cH:7][n:8][cH:9][cH... | set([0, 1]) | True | . 2 1 | US08003648B2 | Cl.O=[CH:1][c:2]1[cH:3][cH:4][c:5](-[c:6]2[n:7... | set([1, 3]) | True | [CH2:1]([NH:3][CH2:4][CH3:5])[CH3:2].C([BH3-])... | set([0, 3]) | True | [CH3:1][CH2:2][NH:3][CH2:4][CH3:5].[CH3:6][c:7... | set([0, 1]) | True | . 3 1 | US09045475B2 | CC(=O)O[BH-](OC(C)=O)OC(C)=O.ClCCl.O=[C:1]([CH... | set([2, 3]) | True | [nH:1]1[c:5]2[n:6][cH:7][c:8]([O:10][c:11]3[cH... | set([0, 3]) | True | CC(O[BH-](OC(=O)C)OC(=O)C)=O.[CH3:14][C:15]1([... | set([1, 3]) | True | . 4 2 | US08188098B2 | CCN(C(C)C)C(C)C.ClCCl.Cl[C:1](=[O:2])[O:3][CH:... | set([2, 5]) | True | Cl[C:2]([O:4][CH:5]1[CH2:9][CH2:8][CH2:7][CH2:... | set([0, 2]) | True | CCN(C(C)C)C(C)C.[CH3:10][CH2:11][O:12][c:13]1[... | set([1, 4]) | True | . rxnclass = 1 class_smis = df[df[&#39;rxn_Class&#39;]==rxnclass].rxnSmiles_Mapping_NameRxn.to_list() rxn = rdChemReactions.ReactionFromSmarts(class_smis[3],useSmiles=True) rxn.Initialize() atms,bnds = find_modifications_in_products(rxn) print(atms) print(bnds) Image(draw_product_with_modified_bonds(rxn,atms,bnds)) . [AtomInfo(mapnum=1, reactant=3, reactantAtom=1, product=0, productAtom=0), AtomInfo(mapnum=7, reactant=4, reactantAtom=0, product=0, productAtom=6)] [BondInfo(product=0, productAtoms=(6, 0), productBond=5, status=&#39;New&#39;)] . rxnclass = 4 class_smis = df[df[&#39;rxn_Class&#39;]==rxnclass].rxnSmiles_Mapping_NameRxn.to_list() rxn = rdChemReactions.ReactionFromSmarts(class_smis[1],useSmiles=True) rxn.Initialize() atms,bnds = find_modifications_in_products(rxn) print(atms) print(bnds) Image(draw_product_with_modified_bonds(rxn,atms,bnds)) . [AtomInfo(mapnum=1, reactant=1, reactantAtom=1, product=0, productAtom=0), AtomInfo(mapnum=2, reactant=1, reactantAtom=2, product=0, productAtom=9), AtomInfo(mapnum=16, reactant=2, reactantAtom=0, product=0, productAtom=18), AtomInfo(mapnum=17, reactant=2, reactantAtom=1, product=0, productAtom=16), AtomInfo(mapnum=19, reactant=2, reactantAtom=3, product=0, productAtom=15)] [BondInfo(product=0, productAtoms=(9, 0), productBond=8, status=&#39;Changed&#39;), BondInfo(product=0, productAtoms=(18, 0), productBond=18, status=&#39;New&#39;), BondInfo(product=0, productAtoms=(15, 9), productBond=14, status=&#39;New&#39;), BondInfo(product=0, productAtoms=(16, 18), productBond=17, status=&#39;Changed&#39;), BondInfo(product=0, productAtoms=(15, 16), productBond=15, status=&#39;Changed&#39;)] . Look at an example where there are no changed bonds in the products but where there is a changed atom: . rxnclass = 7 class_smis = df[df[&#39;rxn_Class&#39;]==rxnclass].rxnSmiles_Mapping_NameRxn.to_list() rxn = rdChemReactions.ReactionFromSmarts(class_smis[1],useSmiles=True) rxn.Initialize() atms,bnds = find_modifications_in_products(rxn) print(atms) print(bnds) Image(draw_product_with_modified_bonds(rxn,atms,bnds)) . [AtomInfo(mapnum=1, reactant=1, reactantAtom=1, product=0, productAtom=0)] [] .",
            "url": "https://greglandrum.github.io/rdkit-blog/tutorial/reactions/2021/11/26/highlighting-changed-bonds-in-reactions.html",
            "relUrl": "/tutorial/reactions/2021/11/26/highlighting-changed-bonds-in-reactions.html",
            "date": " • Nov 26, 2021"
        }
        
    
  
    
        ,"post12": {
            "title": "R-Group Decomposition and Highlighting",
            "content": "Note: This is a slightly updated version of a post from 2020 . This one was inspired by a conversation that happened at the 2020 RDKit (virtual) UGM. . During Dominique Sydow&#39;s presentation she showed some pictures of molecules with some regions of the molecule highlighted (in her case to indicate which kinase pocket they interact with). Dominique had created the images by hand, but I wanted to explore what&#39;s possible using the 2020.09 RDKit release. . What this post is going to demonstrate is doing R-group decomposition (RGD) on a set of molecules that share a common scaffold, generating coordinates for those molecules that are aligned to the scaffold, and generating images of the molecules where the R groups are colored to make them easy to pick out. . The final images we create will look like this: . . The rest of this post will go through the steps to create images like this. . Let&#39;s get started . from rdkit import Chem from rdkit.Chem import Draw from rdkit.Chem.Draw import IPythonConsole IPythonConsole.molSize=(450,350) from rdkit.Chem import rdRGroupDecomposition from rdkit.Chem import rdqueries from rdkit.Chem import rdDepictor from rdkit.Chem.Draw import rdMolDraw2D from rdkit import Geometry rdDepictor.SetPreferCoordGen(True) import pandas as pd from IPython.display import SVG,Image from ipywidgets import interact import rdkit print(rdkit.__version__) . 2021.03.4 . Start by reading in the data we will use. This is a collection of ChEMBL compounds with Ki data measured for CDK2. The dataset includes compounds from a number of different documents and, since these are medchem papers, many of the documents contain groups of compounds that share a common scaffold. . df = pd.read_csv(&#39;../data/cdk2_rgd_dataset.csv&#39;) df.head() . assay_id doc_id description assay_organism assay_chembl_id aidx pref_name activity_id molregno standard_relation ... src_id (#1) type relation value units text_value standard_text_value standard_inchi_key canonical_smiles compound_chembl_id . 0 50641 | 17759 | Inhibitory activity against human CDK2 (Cyclin... | NaN | CHEMBL658107 | CLD0 | Cyclin-dependent kinase 2 | 265814 | 68026 | &gt; | ... | 1 | Ki | &gt; | 20.00 | uM | NaN | NaN | RPXWUUDZINQPTJ-UHFFFAOYSA-N | CNc1nccc(n1)c2sc(C)nc2C | CHEMBL46474 | . 1 50641 | 17759 | Inhibitory activity against human CDK2 (Cyclin... | NaN | CHEMBL658107 | CLD0 | Cyclin-dependent kinase 2 | 265817 | 67880 | = | ... | 1 | Ki | = | 0.14 | uM | NaN | NaN | GDZTURHUKDAJGD-UHFFFAOYSA-N | Cc1nc(C)c(s1)c2ccnc(Nc3ccc(O)cc3)n2 | CHEMBL442957 | . 2 50641 | 17759 | Inhibitory activity against human CDK2 (Cyclin... | NaN | CHEMBL658107 | CLD0 | Cyclin-dependent kinase 2 | 267078 | 67751 | = | ... | 1 | Ki | = | 6.50 | uM | NaN | NaN | CTFDMGIBHFQWKB-UHFFFAOYSA-N | Cc1nc(C)c(s1)c2ccnc(N)n2 | CHEMBL47302 | . 3 50641 | 17759 | Inhibitory activity against human CDK2 (Cyclin... | NaN | CHEMBL658107 | CLD0 | Cyclin-dependent kinase 2 | 267081 | 67782 | = | ... | 1 | Ki | = | 1.20 | uM | NaN | NaN | HOKDXVAONYXHJK-UHFFFAOYSA-N | Cc1nc(C)c(s1)c2ccnc(Nc3ccccc3F)n2 | CHEMBL297447 | . 4 50641 | 17759 | Inhibitory activity against human CDK2 (Cyclin... | NaN | CHEMBL658107 | CLD0 | Cyclin-dependent kinase 2 | 267084 | 67961 | = | ... | 1 | Ki | = | 0.11 | uM | NaN | NaN | XNKSRGHGPSHYIW-UHFFFAOYSA-N | CNc1nc(C)c(s1)c2ccnc(Nc3cccc(O)c3)n2 | CHEMBL44119 | . 5 rows × 28 columns . We pick a group of compounds by selecting all the rows with a given assay ID: . df_doc1 = df[df.assay_chembl_id==&#39;CHEMBL827377&#39;] print(len(df_doc1)) df_doc1.head() . 91 . assay_id doc_id description assay_organism assay_chembl_id aidx pref_name activity_id molregno standard_relation ... src_id (#1) type relation value units text_value standard_text_value standard_inchi_key canonical_smiles compound_chembl_id . 47 302524 | 21080 | Binding affinity for human cyclin-dependent ki... | Homo sapiens | CHEMBL827377 | CLD0 | Cyclin-dependent kinase 2 | 1438958 | 305637 | &gt; | ... | 1 | Ki | &gt; | 19.95 | uM | NaN | NaN | TWQUOUJLNRGSRZ-UHFFFAOYSA-N | Cc1ccc2c(c3ccnc(Nc4cccc(c4)C(F)(F)F)n3)c(nn2n1... | CHEMBL182493 | . 48 302524 | 21080 | Binding affinity for human cyclin-dependent ki... | Homo sapiens | CHEMBL827377 | CLD0 | Cyclin-dependent kinase 2 | 1438962 | 305651 | &gt; | ... | 1 | Ki | &gt; | 19.95 | uM | NaN | NaN | CYHPFZLFUXOCJJ-UHFFFAOYSA-N | Cc1ccc2c(c3ccnc(Nc4ccc(F)c(F)c4)n3)c(nn2n1)c5c... | CHEMBL182326 | . 49 302524 | 21080 | Binding affinity for human cyclin-dependent ki... | Homo sapiens | CHEMBL827377 | CLD0 | Cyclin-dependent kinase 2 | 1439061 | 305664 | &gt; | ... | 1 | Ki | &gt; | 19.95 | uM | NaN | NaN | MYSOMHSTKVRJRA-UHFFFAOYSA-N | Cc1ccc2c(c3ccnc(Nc4ccc5OCCOc5c4)n3)c(nn2n1)c6c... | CHEMBL183064 | . 50 302524 | 21080 | Binding affinity for human cyclin-dependent ki... | Homo sapiens | CHEMBL827377 | CLD0 | Cyclin-dependent kinase 2 | 1439063 | 305674 | &gt; | ... | 1 | Ki | &gt; | 19.95 | uM | NaN | NaN | VUGNSTAXWJUVEZ-UHFFFAOYSA-N | Cc1ccc2c(c3ccnc(Nc4ccc(Cl)c(c4)C(F)(F)F)n3)c(n... | CHEMBL361038 | . 51 302524 | 21080 | Binding affinity for human cyclin-dependent ki... | Homo sapiens | CHEMBL827377 | CLD0 | Cyclin-dependent kinase 2 | 1439065 | 305687 | = | ... | 1 | Ki | = | 3.98 | uM | NaN | NaN | BWBMBCPGRIOUNV-UHFFFAOYSA-N | C1CC1c2nn3ncccc3c2c4ccnc(Nc5ccccc5)n4 | CHEMBL362296 | . 5 rows × 28 columns . Look at some of the compounds: . rdDepictor.SetPreferCoordGen(True) smis = df_doc1[&#39;canonical_smiles&#39;] cids = list(df_doc1.compound_chembl_id) ms = [Chem.MolFromSmiles(x) for x in smis] for m in ms: rdDepictor.Compute2DCoords(m) Draw.MolsToGridImage(ms[:12],legends=cids,molsPerRow=4) . Define a core. I&#39;m doing this manually and am only specifically labeling four of the seven R-groups in this set of molecules. The others will be labelled automatically by the RGD code. . core = Chem.MolFromSmiles(&#39;c1cc(-c2c([*:1])nn3nc([*:2])ccc23)nc(N(c2ccc([*:4])c([*:3])c2))n1&#39;) rdDepictor.SetPreferCoordGen(True) rdDepictor.Compute2DCoords(core) core . Some pre-processing work we need to do: . convert the dummy atoms in the scaffold into query atoms that match anything | add hydrogens to the molecules | select only the subset of molecules which match the core | set a property on each atom which is used to track its original index (we use this later in the RGD analysis) | . ps = Chem.AdjustQueryParameters.NoAdjustments() ps.makeDummiesQueries=True qcore = Chem.AdjustQueryProperties(core,ps) mhs = [Chem.AddHs(x,addCoords=True) for x in ms] mms = [x for x in mhs if x.HasSubstructMatch(qcore)] for m in mms: for atom in m.GetAtoms(): atom.SetIntProp(&quot;SourceAtomIdx&quot;,atom.GetIdx()) print(len(mhs),len(mms)) . 91 91 . Now do the actual RGD: . rdkit.RDLogger.DisableLog(&#39;rdApp.warning&#39;) groups,_ = rdRGroupDecomposition.RGroupDecompose([qcore],mms,asSmiles=False,asRows=True) . This is the function that actually does the work of generating aligned coordinates and creating the image with highlighted R groups . from collections import defaultdict def highlight_rgroups(mol,row,core,width=350,height=200, fillRings=True,legend=&quot;&quot;, sourceIdxProperty=&quot;SourceAtomIdx&quot;, lbls=(&#39;R1&#39;,&#39;R2&#39;,&#39;R3&#39;,&#39;R4&#39;)): # copy the molecule and core mol = Chem.Mol(mol) core = Chem.Mol(core) # - # include the atom map numbers in the substructure search in order to # try to ensure a good alignment of the molecule to symmetric cores for at in core.GetAtoms(): if at.GetAtomMapNum(): at.ExpandQuery(rdqueries.IsotopeEqualsQueryAtom(200+at.GetAtomMapNum())) for lbl in row: if lbl==&#39;Core&#39;: continue rg = row[lbl] for at in rg.GetAtoms(): if not at.GetAtomicNum() and at.GetAtomMapNum() and at.HasProp(&#39;dummyLabel&#39;) and at.GetProp(&#39;dummyLabel&#39;)==lbl: # attachment point. the atoms connected to this # should be from the molecule for nbr in at.GetNeighbors(): if nbr.HasProp(sourceIdxProperty): mAt = mol.GetAtomWithIdx(nbr.GetIntProp(sourceIdxProperty)) if mAt.GetIsotope(): mAt.SetIntProp(&#39;_OrigIsotope&#39;,mAt.GetIsotope()) mAt.SetIsotope(200+at.GetAtomMapNum()) # remove unmapped hs so that they don&#39;t mess up the depiction rhps = Chem.RemoveHsParameters() rhps.removeMapped = False tmol = Chem.RemoveHs(mol,rhps) rdDepictor.GenerateDepictionMatching2DStructure(tmol,core) oldNewAtomMap={} # reset the original isotope values and account for the fact that # removing the Hs changed atom indices for i,at in enumerate(tmol.GetAtoms()): if at.HasProp(sourceIdxProperty): oldNewAtomMap[at.GetIntProp(sourceIdxProperty)] = i if at.HasProp(&quot;_OrigIsotope&quot;): at.SetIsotope(at.GetIntProp(&quot;_OrigIsotope&quot;)) at.ClearProp(&quot;_OrigIsotope&quot;) else: at.SetIsotope(0) # # set up our colormap # the three choices here are all &quot;colorblind&quot; colormaps # &quot;Tol&quot; colormap from https://davidmathlogic.com/colorblind colors = [(51,34,136),(17,119,51),(68,170,153),(136,204,238),(221,204,119),(204,102,119),(170,68,153),(136,34,85)] # &quot;IBM&quot; colormap from https://davidmathlogic.com/colorblind colors = [(100,143,255),(120,94,240),(220,38,127),(254,97,0),(255,176,0)] # Okabe_Ito colormap from https://jfly.uni-koeln.de/color/ colors = [(230,159,0),(86,180,233),(0,158,115),(240,228,66),(0,114,178),(213,94,0),(204,121,167)] for i,x in enumerate(colors): colors[i] = tuple(y/255 for y in x) #- # Identify and store which atoms, bonds, and rings we&#39;ll be highlighting highlightatoms = defaultdict(list) highlightbonds = defaultdict(list) atomrads = {} widthmults = {} rings = [] for i,lbl in enumerate(lbls): color = colors[i%len(colors)] rquery = row[lbl] Chem.GetSSSR(rquery) rinfo = rquery.GetRingInfo() for at in rquery.GetAtoms(): if at.HasProp(sourceIdxProperty): origIdx = oldNewAtomMap[at.GetIntProp(sourceIdxProperty)] highlightatoms[origIdx].append(color) atomrads[origIdx] = 0.4 if fillRings: for aring in rinfo.AtomRings(): tring = [] allFound = True for aid in aring: at = rquery.GetAtomWithIdx(aid) if not at.HasProp(sourceIdxProperty): allFound = False break tring.append(oldNewAtomMap[at.GetIntProp(sourceIdxProperty)]) if allFound: rings.append((tring,color)) for qbnd in rquery.GetBonds(): batom = qbnd.GetBeginAtom() eatom = qbnd.GetEndAtom() if batom.HasProp(sourceIdxProperty) and eatom.HasProp(sourceIdxProperty): origBnd = tmol.GetBondBetweenAtoms(oldNewAtomMap[batom.GetIntProp(sourceIdxProperty)], oldNewAtomMap[eatom.GetIntProp(sourceIdxProperty)]) bndIdx = origBnd.GetIdx() highlightbonds[bndIdx].append(color) widthmults[bndIdx] = 2 d2d = rdMolDraw2D.MolDraw2DCairo(width,height) dos = d2d.drawOptions() dos.useBWAtomPalette() #- # if we are filling rings, go ahead and do that first so that we draw # the molecule on top of the filled rings if fillRings and rings: # a hack to set the molecule scale d2d.DrawMoleculeWithHighlights(tmol,legend,dict(highlightatoms), dict(highlightbonds), atomrads,widthmults) d2d.ClearDrawing() conf = tmol.GetConformer() for (aring,color) in rings: ps = [] for aidx in aring: pos = Geometry.Point2D(conf.GetAtomPosition(aidx)) ps.append(pos) d2d.SetFillPolys(True) d2d.SetColour(color) d2d.DrawPolygon(ps) dos.clearBackground = False #- # now draw the molecule, with highlights: d2d.DrawMoleculeWithHighlights(tmol,legend,dict(highlightatoms),dict(highlightbonds), atomrads,widthmults) d2d.FinishDrawing() png = d2d.GetDrawingText() return png . Interactively try that out on all the molecules in our set: . @interact(idx=range(0,len(ms))) def draw_it(idx=0): m = mms[idx] row = groups[idx] return Image(highlight_rgroups(m,row,qcore,lbls=(&#39;R1&#39;,&#39;R2&#39;,&#39;R3&#39;,&#39;R4&#39;))) . It would be cool to do see multiple molecules at once. Unforunately DrawMolsToGridImage() doesn&#39;t support the multiple highlighting we&#39;re doing here (we decided that the API for that would just be too complex; this may change in the future if we can figure out a sensible API for it), so we have to manually combine the images. Fortunately the pillow package makes that easy: . from PIL import Image as pilImage from io import BytesIO def draw_multiple(ms,groups,qcore,lbls,legends=None,nPerRow=4,subImageSize=(250,200)): nRows = len(ms)//nPerRow if len(ms)%nPerRow: nRows+=1 nCols = nPerRow imgSize = (subImageSize[0]*nCols,subImageSize[1]*nRows) res = pilImage.new(&#39;RGB&#39;,imgSize) for i,m in enumerate(ms): col = i%nPerRow row = i//nPerRow if legends: legend = legends[i] else: legend = &#39;&#39; png = highlight_rgroups(m,groups[i],qcore,lbls=lbls,legend=legend, width=subImageSize[0],height=subImageSize[1]) bio = BytesIO(png) img = pilImage.open(bio) res.paste(img,box=(col*subImageSize[0],row*subImageSize[1])) bio = BytesIO() res.save(bio,format=&#39;PNG&#39;) return bio.getvalue() . Now let&#39;s look at the first 16 molecules in the dataset: . Image(draw_multiple(mms[:16],groups,qcore,(&#39;R1&#39;,&#39;R2&#39;,&#39;R3&#39;,&#39;R4&#39;),legends=cids,subImageSize=(300,250))) . Repeat that analysis with the compounds from another document just to make sure we did everything sufficiently generally: . df_doc2 = df[df.assay_chembl_id==&#39;CHEMBL658107&#39;] print(len(df_doc2)) df_doc2.head() . 33 . assay_id doc_id description assay_organism assay_chembl_id aidx pref_name activity_id molregno standard_relation ... src_id (#1) type relation value units text_value standard_text_value standard_inchi_key canonical_smiles compound_chembl_id . 0 50641 | 17759 | Inhibitory activity against human CDK2 (Cyclin... | NaN | CHEMBL658107 | CLD0 | Cyclin-dependent kinase 2 | 265814 | 68026 | &gt; | ... | 1 | Ki | &gt; | 20.00 | uM | NaN | NaN | RPXWUUDZINQPTJ-UHFFFAOYSA-N | CNc1nccc(n1)c2sc(C)nc2C | CHEMBL46474 | . 1 50641 | 17759 | Inhibitory activity against human CDK2 (Cyclin... | NaN | CHEMBL658107 | CLD0 | Cyclin-dependent kinase 2 | 265817 | 67880 | = | ... | 1 | Ki | = | 0.14 | uM | NaN | NaN | GDZTURHUKDAJGD-UHFFFAOYSA-N | Cc1nc(C)c(s1)c2ccnc(Nc3ccc(O)cc3)n2 | CHEMBL442957 | . 2 50641 | 17759 | Inhibitory activity against human CDK2 (Cyclin... | NaN | CHEMBL658107 | CLD0 | Cyclin-dependent kinase 2 | 267078 | 67751 | = | ... | 1 | Ki | = | 6.50 | uM | NaN | NaN | CTFDMGIBHFQWKB-UHFFFAOYSA-N | Cc1nc(C)c(s1)c2ccnc(N)n2 | CHEMBL47302 | . 3 50641 | 17759 | Inhibitory activity against human CDK2 (Cyclin... | NaN | CHEMBL658107 | CLD0 | Cyclin-dependent kinase 2 | 267081 | 67782 | = | ... | 1 | Ki | = | 1.20 | uM | NaN | NaN | HOKDXVAONYXHJK-UHFFFAOYSA-N | Cc1nc(C)c(s1)c2ccnc(Nc3ccccc3F)n2 | CHEMBL297447 | . 4 50641 | 17759 | Inhibitory activity against human CDK2 (Cyclin... | NaN | CHEMBL658107 | CLD0 | Cyclin-dependent kinase 2 | 267084 | 67961 | = | ... | 1 | Ki | = | 0.11 | uM | NaN | NaN | XNKSRGHGPSHYIW-UHFFFAOYSA-N | CNc1nc(C)c(s1)c2ccnc(Nc3cccc(O)c3)n2 | CHEMBL44119 | . 5 rows × 28 columns . smis = df_doc2[&#39;canonical_smiles&#39;] cids = list(df_doc2.compound_chembl_id) ms = [Chem.MolFromSmiles(x) for x in smis] for m in ms: rdDepictor.Compute2DCoords(m) Draw.MolsToGridImage(ms[:12],legends=cids,molsPerRow=4) . core = Chem.MolFromSmiles(&#39;Cc1nc([*:3])sc1-c1ccnc(N([*:1])[*:2])n1&#39;) ps = Chem.AdjustQueryParameters.NoAdjustments() ps.makeDummiesQueries=True qcore = Chem.AdjustQueryProperties(core,ps) mhs = [Chem.AddHs(x,addCoords=True) for x in ms] mms = [x for x in mhs if x.HasSubstructMatch(qcore)] for m in mms: for atom in m.GetAtoms(): atom.SetIntProp(&quot;SourceAtomIdx&quot;,atom.GetIdx()) print(len(mhs),len(mms)) rdDepictor.SetPreferCoordGen(True) rdDepictor.Compute2DCoords(qcore) qcore . 33 33 . rdkit.RDLogger.DisableLog(&#39;rdApp.warning&#39;) groups,_ = rdRGroupDecomposition.RGroupDecompose([qcore],mms,asSmiles=False,asRows=True) . @interact(idx=range(0,len(mms))) def draw_it(idx=0): m = mms[idx] row = groups[idx] return Image(highlight_rgroups(m,row,qcore,lbls=(&#39;R1&#39;,&#39;R2&#39;,&#39;R3&#39;))) . Image(draw_multiple(mms[:12],groups,qcore,(&#39;R1&#39;,&#39;R2&#39;,&#39;R3&#39;),subImageSize=(300,250))) . df_doc3 = df[df.assay_chembl_id==&#39;CHEMBL3101313&#39;] print(len(df_doc3)) df_doc3.head() . 25 . assay_id doc_id description assay_organism assay_chembl_id aidx pref_name activity_id molregno standard_relation ... src_id (#1) type relation value units text_value standard_text_value standard_inchi_key canonical_smiles compound_chembl_id . 1129 1281340 | 76402 | Displacement of B-Alexa-Fluor647 from CDK2 (un... | Homo sapiens | CHEMBL3101313 | CLD0 | Cyclin-dependent kinase 2 | 13859835 | 1610535 | &lt; | ... | 1 | Ki | &lt; | 0.10 | uM | NaN | NaN | USOUMMYIFYDJEI-ZZTDINLMSA-N | COC[C@H](Cc1ccc(O)cc1)NC(=O)c2cc(C(=O)O)c3cc( ... | CHEMBL3099753 | . 1130 1281340 | 76402 | Displacement of B-Alexa-Fluor647 from CDK2 (un... | Homo sapiens | CHEMBL3101313 | CLD0 | Cyclin-dependent kinase 2 | 13859836 | 1610534 | = | ... | 1 | Ki | = | 0.10 | uM | NaN | NaN | DLJWCYCMLMVSML-FQEVSTJZSA-N | COC[C@H](Cc1ccc(O)cc1)NC(=O)c2cc(C(=O)O)c3cc(c... | CHEMBL3099752 | . 1131 1281340 | 76402 | Displacement of B-Alexa-Fluor647 from CDK2 (un... | Homo sapiens | CHEMBL3101313 | CLD0 | Cyclin-dependent kinase 2 | 13859837 | 1610533 | = | ... | 1 | Ki | = | 0.16 | uM | NaN | NaN | BHBDKGIDYKROMY-BAJJQUEBSA-N | CN(C)C(=O)[C@H](Cc1ccc(O)cc1)NC(=O)c2cc(C(=O)O... | CHEMBL3099751 | . 1132 1281340 | 76402 | Displacement of B-Alexa-Fluor647 from CDK2 (un... | Homo sapiens | CHEMBL3101313 | CLD0 | Cyclin-dependent kinase 2 | 13859838 | 1610532 | = | ... | 1 | Ki | = | 0.10 | uM | NaN | NaN | IYRLCOILNQBJEJ-ZNOKPGKASA-N | CNC(=O)[C@H](Cc1ccc(O)cc1)NC(=O)c2cc(C(=O)O)c3... | CHEMBL3099750 | . 1133 1281340 | 76402 | Displacement of B-Alexa-Fluor647 from CDK2 (un... | Homo sapiens | CHEMBL3101313 | CLD0 | Cyclin-dependent kinase 2 | 13859839 | 1610531 | = | ... | 1 | Ki | = | 0.30 | uM | NaN | NaN | DDIHZTFUIFPFOO-OAQYLSRUSA-N | CCC[C@H](Cc1ccc(O)cc1)NC(=O)c2cc(C(=O)O)c3cc(c... | CHEMBL3099749 | . 5 rows × 28 columns . Finally, do another document, just because it&#39;s fun. :-) . smis = df_doc3[&#39;canonical_smiles&#39;] cids = list(df_doc3.compound_chembl_id) ms = [Chem.MolFromSmiles(x) for x in smis] for m in ms: rdDepictor.Compute2DCoords(m) Draw.MolsToGridImage(ms[:12],legends=cids,molsPerRow=4) . core = Chem.MolFromSmiles(&#39;OC(=O)c1cc(C(=O)NC(C[*:1])[*:2])nc2ccc([*:3])cc12&#39;) ps = Chem.AdjustQueryParameters.NoAdjustments() ps.makeDummiesQueries=True qcore = Chem.AdjustQueryProperties(core,ps) mhs = [Chem.AddHs(x,addCoords=True) for x in ms] mms = [x for x in mhs if x.HasSubstructMatch(qcore)] for m in mms: for atom in m.GetAtoms(): atom.SetIntProp(&quot;SourceAtomIdx&quot;,atom.GetIdx()) print(len(mhs),len(mms)) rdDepictor.SetPreferCoordGen(True) rdDepictor.Compute2DCoords(qcore) qcore . 25 22 . rdkit.RDLogger.DisableLog(&#39;rdApp.warning&#39;) groups,_ = rdRGroupDecomposition.RGroupDecompose([qcore],mms,asSmiles=False,asRows=True) . @interact(idx=range(0,len(mms))) def draw_it(idx=0): m = mms[idx] row = groups[idx] return Image(highlight_rgroups(m,row,qcore,lbls=(&#39;R1&#39;,&#39;R2&#39;,&#39;R3&#39;))) . Image(draw_multiple(mms[:12],groups,qcore,(&#39;R1&#39;,&#39;R2&#39;,&#39;R3&#39;),subImageSize=(300,250))) .",
            "url": "https://greglandrum.github.io/rdkit-blog/tutorial/prototypes/drawing/2021/08/07/rgd-and-highlighting.html",
            "relUrl": "/tutorial/prototypes/drawing/2021/08/07/rgd-and-highlighting.html",
            "date": " • Aug 7, 2021"
        }
        
    
  
    
        ,"post13": {
            "title": "Generalized substructure search",
            "content": "[Updated 19.12.2021 to use new functionality from the 2021.09 RDKit release] . Over the last couple of releases we&#39;ve added a number of RDKit features which allow useage of more advanced substructure query features and more control over the results returned by substructure searches. These include . Chem.AdjustQueryProperties() to tune the results returned by a substructure query | rdMolEnumerator.Enumerate() to enumerate some V3000 mol block query features (as of the 2021.03 release the supported features are variable attachment points and link nodes) | rdTautomerQuery.TautomerQuery() to allow tautomer-insensitive substructures search | . In this post I&#39;ll show how to use all of those together to do &quot;generalized substructures searching&quot; with the RDKit. Towards the bottom of the post there are a couple of Python functions which can be used in other scripts to make this process easier. I&#39;ll also try and figure out a good way to get that into a future RDKit release. . AAs an example, here&#39;s a query: and here are four ChEMBL molecules returned using that query: . from rdkit import Chem from rdkit.Chem import rdMolEnumerator from rdkit.Chem import rdTautomerQuery from rdkit.Chem import Draw from rdkit.Chem.Draw import IPythonConsole IPythonConsole.drawOptions.minFontSize = 10 Draw.SetComicMode(IPythonConsole.drawOptions) from rdkit.Chem import rdDepictor rdDepictor.SetPreferCoordGen(True) import rdkit print(rdkit.__version__) import time print(time.asctime()) . 2021.09.3 Sun Dec 19 06:14:00 2021 . Load a SubstructLibrary created using ChEMBL_29. The code used to construct this is: . from rdkit import RDLogger from rdkit import Chem from rdkit.Chem import rdSubstructLibrary import pickle, time import gzip gz = gzip.GzipFile(&#39;/home/glandrum/Downloads/chembl_29.sdf.gz&#39;) suppl = Chem.ForwardSDMolSupplier(gz) RDLogger.DisableLog(&quot;rdApp.warning&quot;) t1=time.time() data = [] for i,mol in enumerate(suppl): if not ((i+1)%50000): print(f&quot;Processed {i+1} molecules in {(time.time()-t1):.1f} seconds&quot;) if mol is None or mol.GetNumAtoms()&gt;50: continue fp = Chem.PatternFingerprint(mol,fpSize=1024,tautomerFingerprints=True) smi = Chem.MolToSmiles(mol) data.append((smi,fp)) t2=time.time() pickle.dump(data,open(&#39;../data/chembl29_sssdata.pkl&#39;,&#39;wb+&#39;)) t1=time.time() mols = rdSubstructLibrary.CachedTrustedSmilesMolHolder() fps = rdSubstructLibrary.TautomerPatternHolder(1024) for smi,fp in data: mols.AddSmiles(smi) fps.AddFingerprint(fp) library = rdSubstructLibrary.SubstructLibrary(mols,fps) t2=time.time() print(f&quot;That took {t2-t1:.2f} seconds. The library has {len(library)} molecules.&quot;) pickle.dump(library,open(&#39;../data/chembl29_ssslib.pkl&#39;,&#39;wb+&#39;)) . import pickle with open(&#39;./results/chembl29_ssslib.pkl&#39;,&#39;rb&#39;) as inf: sslib = pickle.load(inf) print(f&#39;SubstructLibrary loaded with {len(sslib)} molecules&#39;) . SubstructLibrary loaded with 2049078 molecules . Enumeration . Start with a query including a variable attachment point: . qry = Chem.MolFromMolBlock(&#39;&#39;&#39; Mrv2108 08012107372D 0 0 0 0 0 999 V3000 M V30 BEGIN CTAB M V30 COUNTS 11 11 0 0 0 M V30 BEGIN ATOM M V30 1 C -2.4167 7.8734 0 0 M V30 2 C -3.7503 7.1034 0 0 M V30 3 C -3.7503 5.5633 0 0 M V30 4 N -2.4167 4.7933 0 0 M V30 5 C -1.083 5.5633 0 0 M V30 6 C -1.083 7.1034 0 0 M V30 7 N 0.3973 7.5279 0 0 M V30 8 N 0.3104 5.0377 0 0 M V30 9 C 1.2585 6.2511 0 0 M V30 10 * 0.3539 6.2828 0 0 M V30 11 C 1.5089 8.2833 0 0 M V30 END ATOM M V30 BEGIN BOND M V30 1 1 1 2 M V30 2 2 2 3 M V30 3 1 3 4 M V30 4 2 4 5 M V30 5 1 5 6 M V30 6 2 1 6 M V30 7 1 7 6 M V30 8 1 5 8 M V30 9 1 8 9 M V30 10 2 7 9 M V30 11 1 10 11 ENDPTS=(2 8 7) ATTACH=ANY M V30 END BOND M V30 END CTAB M END &#39;&#39;&#39;) qry . bndl = rdMolEnumerator.Enumerate(qry) matches = sslib.GetMatches(bndl) print(f&#39;{len(matches)} matches&#39;) mols = [sslib.GetMol(x) for x in matches] # sort the molecules by number of atoms and preserve the match ID sorted_res = sorted(zip(mols,matches),key=lambda x:x[0].GetNumAtoms()) sorted_mols,sorted_matches = zip(*sorted_res) Draw.MolsToGridImage(sorted_mols[:12],legends=[str(x) for x in sorted_matches],molsPerRow=4) . 1000 matches . Those include some addditional rings attached to the core in molecules like 1476, 10083, and 10853. We can prevent that by calling AdjustQueryProperties(): . bndl = Chem.MolBundle() for m in rdMolEnumerator.Enumerate(qry): bndl.AddMol(Chem.AdjustQueryProperties(m)) matches = sslib.GetMatches(bndl) print(f&#39;{len(matches)} matches&#39;) mols = [sslib.GetMol(x) for x in matches] # sort the molecules by number of atoms and preserve the match ID sorted_res = sorted(zip(mols,matches),key=lambda x:x[0].GetNumAtoms()) sorted_mols,sorted_matches = zip(*sorted_res) Draw.MolsToGridImage(sorted_mols[:12],legends=[str(x) for x in sorted_matches],molsPerRow=4) . 148 matches . An aside: this would be more convenient if AdjustQueryProperties directly supported passing MolBundle objects. That&#39;s something for a future version. . Now let&#39;s make the query more complex by adding a link node in addition to the variable attachment point: . qry = Chem.MolFromMolBlock(&#39;&#39;&#39; Mrv2108 08012108062D 0 0 0 0 0 999 V3000 M V30 BEGIN CTAB M V30 COUNTS 13 13 0 0 0 M V30 BEGIN ATOM M V30 1 C -2.4167 7.8734 0 0 M V30 2 C -3.7503 7.1034 0 0 M V30 3 C -3.7503 5.5633 0 0 M V30 4 N -2.4167 4.7933 0 0 M V30 5 C -1.083 5.5633 0 0 M V30 6 C -1.083 7.1034 0 0 M V30 7 N 0.3973 7.5279 0 0 M V30 8 N 0.3104 5.0377 0 0 M V30 9 C 1.2585 6.2511 0 0 M V30 10 * 0.3539 6.2828 0 0 M V30 11 C 1.5089 8.2833 0 0 M V30 12 C 2.7975 6.1974 0 0 M V30 13 N 3.6136 7.5033 0 0 M V30 END ATOM M V30 BEGIN BOND M V30 1 1 1 2 M V30 2 2 2 3 M V30 3 1 3 4 M V30 4 2 4 5 M V30 5 1 5 6 M V30 6 2 1 6 M V30 7 1 7 6 M V30 8 1 5 8 M V30 9 1 8 9 M V30 10 2 7 9 M V30 11 1 10 11 ENDPTS=(2 8 7) ATTACH=ANY M V30 12 1 9 12 M V30 13 1 12 13 M V30 END BOND M V30 LINKNODE 1 2 2 12 9 12 13 M V30 END CTAB M END &#39;&#39;&#39;) qry . bndl = rdMolEnumerator.Enumerate(qry) matches = sslib.GetMatches(bndl) print(f&#39;{len(matches)} matches&#39;) mols = [sslib.GetMol(x) for x in matches] # sort the molecules by number of atoms and preserve the match ID sorted_res = sorted(zip(mols,matches),key=lambda x:x[0].GetNumAtoms()) sorted_mols,sorted_matches = zip(*sorted_res) Draw.MolsToGridImage(sorted_mols[:12],legends=[str(x) for x in sorted_matches],molsPerRow=4) . 193 matches . Enumeration + tautomer-insensitive queries . Here we will use the RDKit&#39;s TautomerQuery class to do tautomer-insensitive substructure queries. We start by enumerating the molecules, as above, but then convert each of the results into a TautomerQuery . To see what&#39;s going on here it helps to have the result molecules all aligned the same way. In order to do that we also need to generate query molecules with aligned coordinates. . from rdkit.Chem import rdFMCS def getAlignedQueries(qry): # generate a conformer for the query if we don&#39;t have one already if not qry.GetNumConformers(): rdDepictor.Compute2DCoords(qry) bndl = rdMolEnumerator.Enumerate(qry) # find the MCS of the enumerated molecules: mcs = rdFMCS.FindMCS(bndl) qmcs = Chem.MolFromSmarts(mcs.smartsString) # and now adjust the properties, generate coordinates, and create the TautomerQuery queries = [] for q in bndl: q = Chem.AdjustQueryProperties(q) rdDepictor.GenerateDepictionMatching2DStructure(q,qry,refPatt=qmcs) queries.append(rdTautomerQuery.TautomerQuery(q)) return queries def drawAlignedMols(mols,qry,legends=None,molsPerRow=4): queries = getAlignedQueries(qry) for i,m in enumerate(mols): for q in queries: if q.IsSubstructOf(m): rdDepictor.GenerateDepictionMatching2DStructure(m,q.GetTemplateMolecule()) return Draw.MolsToGridImage(mols,legends=legends,molsPerRow=molsPerRow) . qry = Chem.MolFromMolBlock(&#39;&#39;&#39; Mrv2108 08012108222D 0 0 0 0 0 999 V3000 M V30 BEGIN CTAB M V30 COUNTS 12 12 0 0 0 M V30 BEGIN ATOM M V30 1 C -2.4167 7.8734 0 0 M V30 2 C -3.7503 7.1034 0 0 M V30 3 C -3.7503 5.5633 0 0 M V30 4 N -2.4167 4.7933 0 0 M V30 5 C -1.083 5.5633 0 0 M V30 6 C -1.083 7.1034 0 0 M V30 7 N 0.3973 7.5279 0 0 M V30 8 N 0.3104 5.0377 0 0 M V30 9 C 1.2585 6.2511 0 0 M V30 10 * -3.0835 7.4884 0 0 M V30 11 [C,N,O] -3.0835 9.7984 0 0 M V30 12 * 2.7975 6.1974 0 0 M V30 END ATOM M V30 BEGIN BOND M V30 1 1 1 2 M V30 2 2 2 3 M V30 3 1 3 4 M V30 4 2 4 5 M V30 5 1 5 6 M V30 6 2 1 6 M V30 7 1 7 6 M V30 8 1 5 8 M V30 9 1 8 9 M V30 10 2 7 9 M V30 11 1 10 11 ENDPTS=(2 2 1) ATTACH=ANY M V30 12 1 9 12 M V30 END BOND M V30 END CTAB M END &#39;&#39;&#39;) qry . Start by doing a tautomer-sensitive query to see how many results we get: . bndl = rdMolEnumerator.Enumerate(qry) matches = [] for m in bndl: m = Chem.AdjustQueryProperties(m) matches.extend(sslib.GetMatches(m)) print(f&#39;{len(matches)} matches&#39;) mols = [sslib.GetMol(x) for x in matches] # sort the molecules by number of atoms and preserve the match ID sorted_res = sorted(zip(mols,matches),key=lambda x:x[0].GetNumAtoms()) sorted_mols,sorted_matches = zip(*sorted_res) drawAlignedMols(sorted_mols[:12],qry,[str(x) for x in sorted_matches]) . 276 matches . Now do the tautomer-insensitive version of that and show just the new molecules . bndl = rdMolEnumerator.Enumerate(qry) matches2 = [] for m in bndl: m = Chem.AdjustQueryProperties(m) tqry = rdTautomerQuery.TautomerQuery(m) matches2.extend(sslib.GetMatches(tqry)) extras = set(matches2).difference(matches) print(f&#39;{len(matches2)} matches, {len(extras)} are non-overlapping&#39;) mols = [sslib.GetMol(x) for x in extras] # sort the molecules by number of atoms and preserve the match ID sorted_res = sorted(zip(mols,matches),key=lambda x:x[0].GetNumAtoms()) sorted_mols,sorted_matches = zip(*sorted_res) drawAlignedMols(sorted_mols[:12],qry,[str(x) for x in sorted_matches]) . 288 matches, 12 are non-overlapping . Bring it all together . Now let&#39;s put that all together in one function and include the information required to do atom highlighting in the structure drawings . from rdkit.Chem import rdFMCS from rdkit.Chem import rdTautomerQuery # this function does the enumeration of the queries def getAlignedQueries(qry,tautomerInsensitive=True): if not qry.GetNumConformers(): rdDepictor.Compute2DCoords(qry) bndl = rdMolEnumerator.Enumerate(qry) # find the MCS of the enumerated molecules: mcs = rdFMCS.FindMCS(bndl) qmcs = Chem.MolFromSmarts(mcs.smartsString) # and now adjust the properties, generate coordinates, and create the TautomerQuery queries = [] for q in bndl: q = Chem.AdjustQueryProperties(q) rdDepictor.GenerateDepictionMatching2DStructure(q,qry,refPatt=qmcs) if tautomerInsensitive: q = rdTautomerQuery.TautomerQuery(q) queries.append(q) return queries def generalizedSubstructureSearch(query,sslib,tautomerInsensitive=True,alignResults=True, maxResults=1000): queries = getAlignedQueries(query,tautomerInsensitive=tautomerInsensitive) matches = [] for q in queries: matches.extend(sslib.GetMatches(q,maxResults=maxResults)) tmols = [(x,sslib.GetMol(x)) for x in matches] mols = [] for idx,mol in sorted(tmols,key=lambda x:x[1].GetNumAtoms()): match = None if(alignResults): for q in queries: if tautomerInsensitive: match = q.GetSubstructMatch(mol) if match: rdDepictor.GenerateDepictionMatching2DStructure(mol,q.GetTemplateMolecule()) break else: match = mol.GetSubstructMatch(q) if match: rdDepictor.GenerateDepictionMatching2DStructure(mol,q) break mols.append((idx,mol,match)) if len(mols)&gt;=maxResults: break return mols . res = generalizedSubstructureSearch(qry,sslib) ids,mols,matchAtoms = zip(*res) print(f&#39;{len(mols)} results&#39;) Draw.MolsToGridImage(mols[:12],legends=[str(x) for x in ids],highlightAtomLists=matchAtoms, molsPerRow=4) . 288 results . res = generalizedSubstructureSearch(qry,sslib,tautomerInsensitive=False) ids,mols,matchAtoms = zip(*res) print(f&#39;{len(mols)} results&#39;) Draw.MolsToGridImage(mols[:12],legends=[str(x) for x in ids],highlightAtomLists=matchAtoms, molsPerRow=4) . 276 results . Last example, link nodes + variable attachment + tautomer enumeration . qry = Chem.MolFromMolBlock(&#39;&#39;&#39; Mrv2108 08032106392D 0 0 0 0 0 999 V3000 M V30 BEGIN CTAB M V30 COUNTS 13 13 0 0 0 M V30 BEGIN ATOM M V30 1 C -2.4167 7.8734 0 0 M V30 2 C -3.7503 7.1034 0 0 M V30 3 C -3.7503 5.5633 0 0 M V30 4 N -2.4167 4.7933 0 0 M V30 5 C -1.083 5.5633 0 0 M V30 6 C -1.083 7.1034 0 0 M V30 7 N 0.3973 7.5279 0 0 M V30 8 N 0.3104 5.0377 0 0 M V30 9 C 1.2585 6.2511 0 0 M V30 10 * -3.0835 7.4884 0 0 M V30 11 [C,N,O] -3.0835 9.7984 0 0 M V30 12 * 2.7975 6.1974 0 0 M V30 13 N 3.6136 7.5033 0 0 M V30 END ATOM M V30 BEGIN BOND M V30 1 1 1 2 M V30 2 2 2 3 M V30 3 1 3 4 M V30 4 2 4 5 M V30 5 1 5 6 M V30 6 2 1 6 M V30 7 1 7 6 M V30 8 1 5 8 M V30 9 1 8 9 M V30 10 2 7 9 M V30 11 1 10 11 ENDPTS=(3 3 2 1) ATTACH=ANY M V30 12 1 9 12 M V30 13 1 12 13 M V30 END BOND M V30 LINKNODE 1 3 2 12 9 12 13 M V30 END CTAB M END &#39;&#39;&#39;) qry . res = generalizedSubstructureSearch(qry,sslib) ids,mols,matchAtoms = zip(*res) print(f&#39;{len(mols)} results&#39;) Draw.MolsToGridImage(mols[:12],legends=[str(x) for x in ids],highlightAtomLists=matchAtoms, molsPerRow=4) . 24 results . Image for the blog post summary: . keep = [0,1,4,6] ids,mols,matchAtoms = zip(*[res[x] for x in keep]) Draw.MolsToGridImage(mols[:12],legends=[str(x) for x in ids],highlightAtomLists=matchAtoms, molsPerRow=2,subImgSize=(300,250)) .",
            "url": "https://greglandrum.github.io/rdkit-blog/tutorial/substructure/2021/08/03/generalized-substructure-search.html",
            "relUrl": "/tutorial/substructure/2021/08/03/generalized-substructure-search.html",
            "date": " • Aug 3, 2021"
        }
        
    
  
    
        ,"post14": {
            "title": "Using the RDKit in a C++ program",
            "content": "Note: the instructions in this blog post currently only work on linux systems. There’s a configuration problem with the way we use cmake on the Mac and Windows that needs to be cleared up. I will update the post after that’s done. . Last week I (re)discoverered that it’s pretty easy to use the RDKit in other C++ projects. This is obviously somthing that’s possible, but I thought of it as being something of a pain. It turns out that it’s not, as I hope to show you in this post. . I started by setting up a fresh conda environment and grabbing an RDKit build from conda-forge, this is a bit heavyweight since you end up with a bunch of python packages as well as the RDKit itself (I’m going to look into making this more minimal), but it’s much easier than doing your own build. . The first thing is to set up a conda environment: . conda create -n rdkit_dev conda activate rdkit_dev conda install -c conda-forge mamba mamba install -c conda-forge cmake rdkit eigen . Note: I start by installing mamba here because it makes doing conda installs much, much faster. . Here’s a simple demo program which reads in a set of molecules from an input file and generates tautomer hashes for them. It uses the boost::timer library in order to separately time how long it takes to read the molecules and generate the hashes. I called this file tautomer_hash.cpp: . #include &lt;GraphMol/FileParsers/MolSupplier.h&gt; #include &lt;GraphMol/MolHash/MolHash.h&gt; #include &lt;GraphMol/RDKitBase.h&gt; #include &lt;RDGeneral/RDLog.h&gt; #include &lt;algorithm&gt; #include &lt;boost/timer/timer.hpp&gt; #include &lt;iostream&gt; #include &lt;vector&gt; using namespace RDKit; void readmols(std::string pathName, unsigned int maxToDo, std::vector&lt;RWMOL_SPTR&gt; &amp;mols) { boost::timer::auto_cpu_timer t; // using a supplier without sanitizing the molecules... RDKit::SmilesMolSupplier suppl(pathName, &quot; t&quot;, 1, 0, true, false); unsigned int nDone = 0; while (!suppl.atEnd() &amp;&amp; (maxToDo &lt;= 0 || nDone &lt; maxToDo)) { RDKit::ROMol *m = suppl.next(); if (!m) { continue; } m-&gt;updatePropertyCache(); // the tautomer hash code uses conjugation info MolOps::setConjugation(*m); nDone += 1; mols.push_back(RWMOL_SPTR((RWMol *)m)); } std::cerr &lt;&lt; &quot;read: &quot; &lt;&lt; nDone &lt;&lt; &quot; mols.&quot; &lt;&lt; std::endl; } void generatehashes(const std::vector&lt;RWMOL_SPTR&gt; &amp;mols) { boost::timer::auto_cpu_timer t; for (auto &amp;mol : mols) { auto hash = MolHash::MolHash(mol.get(), MolHash::HashFunction::HetAtomTautomer); } } int main(int argc, char *argv[]) { RDLog::InitLogs(); std::vector&lt;RWMOL_SPTR&gt; mols; BOOST_LOG(rdInfoLog) &lt;&lt; &quot;read mols&quot; &lt;&lt; std::endl; readmols(argv[1], 10000, mols); BOOST_LOG(rdInfoLog) &lt;&lt; &quot;generate hashes&quot; &lt;&lt; std::endl; generatehashes(mols); BOOST_LOG(rdInfoLog) &lt;&lt; &quot;done &quot; &lt;&lt; std::endl; } . This is a pretty crappy program since it doesn’t do much error checking, but the purpose here is to demonstrate how to get the environment setup, not to teach how to write nice C++ programs. :-) . The way to make the build easy is to use cmake to set everything up, so I need a CMakeLists.txt file that defines my executable and its RDKit dependencies: . cmake_minimum_required(VERSION 3.18) project(simple_cxx_example) set(CMAKE_CXX_STANDARD 14) set(CMAKE_CXX_STANDARD_REQUIRED True) find_package(RDKit REQUIRED) find_package(Boost COMPONENTS timer system REQUIRED) add_executable(tautomer_hash tautomer_hash.cpp) target_link_libraries(tautomer_hash RDKit::SmilesParse RDKit::MolHash Boost::timer) . This tells cmake to find the RDKit and boost installs (which “just works” since cmake, boost, and the RDKit were all installed from conda), defines the executable I want to create, and then lists the RDKit and boost libraries I use. And that is pretty much that. . Now I create a build dir, run cmake to setup the build, and run make to actually build my program: . (rdkit_dev) glandrum@Badger:~/RDKit_blog/src/simple_cxx_example$ mkdir build (rdkit_dev) glandrum@Badger:~/RDKit_blog/src/simple_cxx_example$ cd build (rdkit_dev) glandrum@Badger:~/RDKit_blog/src/simple_cxx_example/build$ cmake .. -- The C compiler identification is GNU 9.3.0 -- The CXX compiler identification is GNU 9.3.0 -- Detecting C compiler ABI info -- Detecting C compiler ABI info - done -- Check for working C compiler: /usr/bin/cc - skipped -- Detecting C compile features -- Detecting C compile features - done -- Detecting CXX compiler ABI info -- Detecting CXX compiler ABI info - done -- Check for working CXX compiler: /usr/bin/c++ - skipped -- Detecting CXX compile features -- Detecting CXX compile features - done -- Looking for pthread.h -- Looking for pthread.h - found -- Performing Test CMAKE_HAVE_LIBC_PTHREAD -- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Failed -- Looking for pthread_create in pthreads -- Looking for pthread_create in pthreads - not found -- Looking for pthread_create in pthread -- Looking for pthread_create in pthread - found -- Found Threads: TRUE -- Found Boost: /home/glandrum/miniconda3/envs/rdkit_dev/lib/cmake/Boost-1.74.0/BoostConfig.cmake (found suitable version &quot;1.74.0&quot;, minimum required is &quot;1.74.0&quot;) -- Found Boost: /home/glandrum/miniconda3/envs/rdkit_dev/lib/cmake/Boost-1.74.0/BoostConfig.cmake (found version &quot;1.74.0&quot;) found components: timer system -- Configuring done -- Generating done -- Build files have been written to: /home/glandrum/RDKit_blog/src/simple_cxx_example/build (rdkit_dev) glandrum@Badger:~/RDKit_blog/src/simple_cxx_example/build$ make tautomer_hash [ 50%] Building CXX object CMakeFiles/tautomer_hash.dir/tautomer_hash.cpp.o [100%] Linking CXX executable tautomer_hash [100%] Built target tautomer_hash . And now I can run the program: . (rdkit_dev) glandrum@Badger:~/RDKit_blog/src/simple_cxx_example/build$ ./tautomer_hash /scratch/RDKit_git/Code/Profiling/GraphMol/chembl23_very_active.txt [07:51:33] read mols read: 10000 mols. 0.819242s wall, 0.740000s user + 0.070000s system = 0.810000s CPU (98.9%) [07:51:33] generate hashes 0.872662s wall, 0.870000s user + 0.010000s system = 0.880000s CPU (100.8%) [07:51:34] done (rdkit_dev) glandrum@Badger:~/RDKit_blog/src/simple_cxx_example/build$ . If you don’t feel like copy/pasting, the source files for this post are available from github. . This all works so nicely because of the time and effort Riccardo Vianello invested a few years ago to improve the RDKit’s cmake integration. . Next step: add this to the documentation! .",
            "url": "https://greglandrum.github.io/rdkit-blog/tutorial/technical/2021/07/24/setting-up-a-cxx-dev-env.html",
            "relUrl": "/tutorial/technical/2021/07/24/setting-up-a-cxx-dev-env.html",
            "date": " • Jul 24, 2021"
        }
        
    
  
    
        ,"post15": {
            "title": "Simulating count fingerprints",
            "content": "Many of the RDKit&#39;s fingerprints are available as either bit vectors or count vectors. Bit vectors track whether or not features appear in a molecule while count vectors track the number of times each feature appears. It seems intuitive that a count vector is a better representation of similarity than bit vectors, but we often use bit vector representations for computational expediency - bit vectors require less memory and are much faster to operate on. . What impact does this using bit vectors have on computed similarity values and the ordering of similarities? This notebook attempts to provide at least a partial answer to that question and also examines a strategy for simulating counts using bit vectors. I look at the following fingerprints: . Morgan 2 | Topological Torsion | Atom Pair | RDKit | . And I use two sets of compunds: . Random pairs of compounds taken from this blog post | Pairs of &quot;related compounds&quot; taken from this blog post | . Bit vector similarity vs count-based similarity . Let&#39;s start with two molecules where this makes a big difference: The calculated similarity with MFP2 and counts is 0.6 while with bits it&#39;s 0.29. That&#39;s easy to understand since with the bit-based fingerprints the long alkyl chains don&#39;t make the large ontribution to the similarity that they do when using counts. . To demonstrate that this isn&#39;t all about long chains, here&#39;s another pair where there&#39;s a significant difference: In this case the count-based similarity is 0.59 while with bits it&#39;s 0.35. . Those were a couple of anecdotes, but let&#39;s look at the differences across the entire datasets: Here I&#39;ve plotted bit-based similarity vs count-based similarity and included statistics on the correlation in the title. The left plot is for the random compound pairs and the right plot is for the related compound pairs. There are significant differences in similarity here, with the bit vector similarities being consistently lower than the count-based equivalent, but it&#39;s worth pointing out that the rankings of the similarities (as measured by the Spearman rank-order correlation values) are reasonably equivalent, particularly for the related compound pairs. . The equivalent plots for the RDKit fingerprint show the same qualitative behavior with the difference that bit vector similarities tend to be higher than count based similarities: . Simulating counts . The RDKit has a simple mechanism for simulating counts using bit vectors: set multiple bits for each feature where the number of bits set is determined by the count. The approach uses a fixed number of potential bits which each have a threshold value; if the count for the feature exceeds the threshold value then the corresponding bit is set. Here&#39;s a schematic illustration for count simulation with four bits and the thresholds 1, 2, 4, and 8: The example shown, with the first two bits set for feature N, is what we&#39;d get if feature N is set either 2 or 3 times in a molecule. Note that we aren&#39;t just using a binary representation of the count itself. In that case a feature which is present one time in the first molecule, representation 1000, and two times in the second molecule, representation 0100, would contribute zero to the overall similarity. That&#39;s not desirable. . Note that since the count simulation approach uses multiple bits per feature, it decreases the effective length of the fingerprint by a factor equal to the number of bits used. With the default setting of four bits per feature a 2048 bit fingerprint will have the same number of bit collisions as a 512 bit fingerprint without count simulation. This becomes more relevant the more bits a fingerprint tends to set. For example using count simulation to calculate similarity with the RDKit fingerprint, which sets a large number of bits, actually decreases the correlation with the similarity calculated with count vectors (see below for the plot) unless I also increase the overall length of the fingerprint. . Results and discussion . Here&#39;s a summary of the results for the fingerprints I examine here . Random pairs Bits--Count Count simulation--Count . Fingerprint Spearman r MAE RMSE Spearman r MAE RMSE Note . Morgan 2 | 0.84 | 0.097 | 0.10 | 0.90 | 0.024 | 0.036 | | . Topological torsions | 0.92 | 0.026 | 0.051 | 0.98 | 0.018 | 0.029 | | . Topological torsions | 0.92 | 0.026 | 0.051 | 0.99 | 0.010 | 0.021 | 8192 bits for count simulation | . Atom pairs | 0.82 | 0.031 | 0.049 | 0.90 | 0.055 | 0.066 | | . Atom pairs | 0.82 | 0.031 | 0.049 | 0.96 | 0.014 | 0.023 | 8192 bits for count simulation | . RDKit | 0.83 | 0.079 | 0.10 | 0.94 | 0.029 | 0.045 | 8192 bits for count simulation | . Related pairs Bits--Count Count simulation--Count . Fingerprint Spearman r MAE RMSE Spearman r MAE RMSE Note . Morgan 2 | 0.94 | 0.043 | 0.062 | 0.98 | 0.019 | 0.028 | | . Topological torsions | 0.90 | 0.050 | 0.079 | 0.98 | 0.021 | 0.035 | | . Topological torsions | 0.90 | 0.050 | 0.079 | 0.98 | 0.018 | 0.032 | 8192 bits for count simulation | . Atom pairs | 0.91 | 0.043 | 0.067 | 0.97 | 0.052 | 0.063 | | . Atom pairs | 0.91 | 0.043 | 0.067 | 0.98 | 0.020 | 0.032 | 8192 bits for count simulation | . RDKit | 0.91 | 0.077 | 0.11 | 0.98 | 0.034 | 0.053 | 8192 bits for count simulation | . Using the count simulation strategies does improve the match between similarities calculated with bit vectors and those calculated with count vectors. The differences are statistically significant (results not shown here) and large enough to potentially be meaningful. MAE and RMSE values for the various fingerprints typically decrease by at least a factor of two and Spearman rank-order correlation in general increases quite a bit. These conclusions hold for both randomly paired molecules and related pairs with more dramatic differences seen at the lower ends of the similarity scale (the random pairs). . Note that this analysis focuses solely on similarity. The extra information added by doing count simulation will most likely also influence the performance of machine learning models built using these fingerprints. But that&#39;s for a future blog post. . The code to reproduce all of this, along with more plots, is below. . from rdkit import Chem from rdkit.Chem import rdFingerprintGenerator from rdkit.Chem import rdMolDescriptors from rdkit import DataStructs from rdkit.Chem import Draw from rdkit.Chem.Draw import IPythonConsole from rdkit.Chem import rdDepictor rdDepictor.SetPreferCoordGen(True) import numpy as np from scipy.stats import spearmanr from sklearn.metrics import median_absolute_error, mean_squared_error import rdkit print(rdkit.__version__) %pylab inline . 2021.09.1pre Populating the interactive namespace from numpy and matplotlib . Some technical notes: . Note that this notebook uses a couple of features which did not work properly until the v2021.03.4 of the RDKit (which will be released in July). | Count simulation is only generally available when working with the &quot;new&quot; fingerprint generators, so those are used throughout this notebook. | Count simulation is used by default for atom pair and topological torsion fingerprints, both with the &quot;new&quot; fingerprint generators and the older fingerprinting functions. | . Construct the dataset. . Start with our standard similarity comparison set: . import gzip with gzip.open(&#39;../data/chembl21_25K.pairs.txt.gz&#39;,&#39;rt&#39;) as inf: ls = [x.split() for x in inf.readlines()] ms = [(Chem.MolFromSmiles(x[1]),Chem.MolFromSmiles(x[3])) for x in ls] . That&#39;s weighted towards lower similarity values, get some pairs from the related compounds set: . import pickle from collections import namedtuple MCSRes=namedtuple(&#39;MCSRes&#39;,(&#39;smarts&#39;,&#39;numAtoms&#39;,&#39;numMols&#39;,&#39;avgNumMolAtoms&#39;,&#39;mcsTime&#39;)) data = pickle.load(open(&#39;../data/scaffolds_revisited_again.simplified.pkl&#39;,&#39;rb&#39;)) data2 = pickle.load(open(&#39;../data/scaffolds_expanded.simplified.pkl&#39;,&#39;rb&#39;)) data += data2 # keep only sets where the MCS was at least 50% of the average number of atoms: keep = [x for x in data if x[2].numAtoms&gt;=np.mean(x[2].avgNumMolAtoms)/2] len(keep) import random random.seed(0xf00d) related_pairs = [] # keep only molecules matching the MCS: for i,tpl in enumerate(keep): assay,smis,mcs,svg = tpl patt = Chem.MolFromSmarts(mcs.smarts) smis = [(x,y) for x,y in smis if Chem.MolFromSmiles(y).HasSubstructMatch(patt)] ssmis = smis[:] random.shuffle(ssmis) related_pairs.extend([(x[0],x[1],y[0],y[1]) for x,y in zip(smis,ssmis)][:10]) print(f&#39;{len(related_pairs)} related pairs&#39;) related_ms = [(Chem.MolFromSmiles(x[1]),Chem.MolFromSmiles(x[3])) for x in related_pairs] . 10470 related pairs . len(ms) . 25000 . import random random.seed(0xf00d) indices = list(range(len(ms))) random.shuffle(indices) random_pairs = [ms[x] for x in indices[:5000]] indices = list(range(len(related_ms))) random.shuffle(indices) related_pairs = [related_ms[x] for x in indices[:5000]] . Performance of similarity comparisons . fpgen = rdFingerprintGenerator.GetMorganGenerator(radius=2,fpSize=2048,countSimulation=False) bv_pairs = [(fpgen.GetFingerprint(x[0]),fpgen.GetFingerprint(x[1])) for x in random_pairs] cv_pairs = [(fpgen.GetCountFingerprint(x[0]),fpgen.GetCountFingerprint(x[1])) for x in random_pairs] . %timeit _ = [DataStructs.TanimotoSimilarity(x,y) for x,y in bv_pairs] . 5.06 ms ± 75 µs per loop (mean ± std. dev. of 7 runs, 100 loops each) . %timeit _ = [DataStructs.TanimotoSimilarity(x,y) for x,y in cv_pairs] . 8.37 ms ± 160 µs per loop (mean ± std. dev. of 7 runs, 100 loops each) . Not a huge difference there, but what about a fingerprint which sets a much larger number of bits? . fpgen = rdFingerprintGenerator.GetRDKitFPGenerator(fpSize=2048,countSimulation=False) bv_pairs = [(fpgen.GetFingerprint(x[0]),fpgen.GetFingerprint(x[1])) for x in random_pairs] cv_pairs = [(fpgen.GetCountFingerprint(x[0]),fpgen.GetCountFingerprint(x[1])) for x in random_pairs] . %timeit _ = [DataStructs.TanimotoSimilarity(x,y) for x,y in bv_pairs] . 6.22 ms ± 404 µs per loop (mean ± std. dev. of 7 runs, 100 loops each) . %timeit _ = [DataStructs.TanimotoSimilarity(x,y) for x,y in cv_pairs] . 189 ms ± 1.53 ms per loop (mean ± std. dev. of 7 runs, 10 loops each) . Here the performance difference is quite noticeable. . Morgan 2 . fpgen1 = rdFingerprintGenerator.GetMorganGenerator(radius=2,fpSize=2048,countSimulation=False) fpsims = [DataStructs.TanimotoSimilarity(fpgen1.GetFingerprint(x[0]),fpgen1.GetFingerprint(x[1])) for x in ms] countsims = [DataStructs.TanimotoSimilarity(fpgen1.GetCountFingerprint(x[0]),fpgen1.GetCountFingerprint(x[1])) for x in ms] related_fpsims = [DataStructs.TanimotoSimilarity(fpgen1.GetFingerprint(x[0]),fpgen1.GetFingerprint(x[1])) for x in related_ms] related_countsims = [DataStructs.TanimotoSimilarity(fpgen1.GetCountFingerprint(x[0]),fpgen1.GetCountFingerprint(x[1])) for x in related_ms] . fpgen2 = rdFingerprintGenerator.GetMorganGenerator(radius=2,fpSize=2048,countSimulation=True) fpsims_countsim = [DataStructs.TanimotoSimilarity(fpgen2.GetFingerprint(x[0]),fpgen2.GetFingerprint(x[1])) for x in ms] related_fpsims_countsim = [DataStructs.TanimotoSimilarity(fpgen2.GetFingerprint(x[0]),fpgen2.GetFingerprint(x[1])) for x in related_ms] . delts = sorted([(countsims[i]-fpsims[i],i) for i in range(len(fpsims))]) print(delts[:5]) print(delts[-5:]) . [(-0.20329670329670324, 12408), (-0.19358178053830222, 14793), (-0.19191919191919193, 126), (-0.17673378076062635, 1391), (-0.17493796526054584, 13034)] [(0.31300539083557954, 20013), (0.3151412702245835, 12445), (0.3157622739018088, 13430), (0.3207792207792208, 4381), (0.37206896551724133, 11692)] . idx = 13430 print(f&#39;Count: {countsims[idx]:.2f}, Bits: {fpsims[idx]:.2f}, Simulated counts: {fpsims_countsim[idx]:.2f}&#39;) Draw.MolsToGridImage(ms[idx],subImgSize=(350,250),molsPerRow=2) . Count: 0.60, Bits: 0.29, Simulated counts: 0.42 . delts = sorted([(related_countsims[i]-related_fpsims[i],i) for i in range(len(related_fpsims))]) print(delts[:5]) print(delts[-5:]) . [(-0.26508684133058585, 4359), (-0.24506749740394607, 1322), (-0.2321428571428572, 7602), (-0.21353383458646613, 10080), (-0.20879676440849337, 3804)] [(0.24318181818181822, 1962), (0.24456938410426782, 1961), (0.24456938410426782, 1969), (0.2455492835432045, 1963), (0.273972602739726, 7774)] . idx = 1969 print(f&#39;Count: {related_countsims[idx]:.2f}, Bits: {related_fpsims[idx]:.2f}, Simulated counts: {related_fpsims_countsim[idx]:.2f}&#39;) Draw.MolsToGridImage(related_ms[idx],subImgSize=(350,250),molsPerRow=2) . Count: 0.59, Bits: 0.35, Simulated counts: 0.52 . idx = 4359 print(f&#39;Count: {related_countsims[idx]:.2f}, Bits: {related_fpsims[idx]:.2f}, Simulated counts: {related_fpsims_countsim[idx]:.2f}&#39;) Draw.MolsToGridImage(related_ms[idx],subImgSize=(350,250),molsPerRow=2) . Count: 0.39, Bits: 0.65, Simulated counts: 0.51 . figsize(18,9) subplot(1,2,1) y,x = fpsims,countsims hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); xlabel(&#39;count&#39;) ylabel(&#39;bits&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Random pairs, Morgan2 spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); subplot(1,2,2) y,x = related_fpsims,related_countsims hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); xlabel(&#39;count&#39;) ylabel(&#39;bits&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Related pairs, Morgan2 spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); . figsize(18,9) subplot(1,2,1) x,y = countsims,fpsims_countsim hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); ylabel(&#39;count simulation&#39;) xlabel(&#39;count&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Random pairs, Morgan2 spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); subplot(1,2,2) x,y = related_countsims,related_fpsims_countsim hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); ylabel(&#39;count simulation&#39;) xlabel(&#39;count&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Related pairs, Morgan2 spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); . fpgen3 = rdFingerprintGenerator.GetMorganGenerator(radius=2,fpSize=8192,countSimulation=True) fpsims_countsim2 = [DataStructs.TanimotoSimilarity(fpgen3.GetFingerprint(x[0]),fpgen3.GetFingerprint(x[1])) for x in ms] related_fpsims_countsim2 = [DataStructs.TanimotoSimilarity(fpgen3.GetFingerprint(x[0]),fpgen3.GetFingerprint(x[1])) for x in related_ms] figsize(18,9) subplot(1,2,1) x,y = countsims,fpsims_countsim2 hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); ylabel(&#39;count simulation 8192&#39;) xlabel(&#39;count&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Random pairs, Morgan2 spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); subplot(1,2,2) x,y = related_countsims,related_fpsims_countsim2 hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); ylabel(&#39;count simulation 8192&#39;) xlabel(&#39;count&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Related pairs, Morgan2 spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); . Topological Torsions . fpgen1 = rdFingerprintGenerator.GetTopologicalTorsionGenerator(fpSize=2048,countSimulation=False) fpsims = [DataStructs.TanimotoSimilarity(fpgen1.GetFingerprint(x[0]),fpgen1.GetFingerprint(x[1])) for x in ms] countsims = [DataStructs.TanimotoSimilarity(fpgen1.GetCountFingerprint(x[0]),fpgen1.GetCountFingerprint(x[1])) for x in ms] related_fpsims = [DataStructs.TanimotoSimilarity(fpgen1.GetFingerprint(x[0]),fpgen1.GetFingerprint(x[1])) for x in related_ms] related_countsims = [DataStructs.TanimotoSimilarity(fpgen1.GetCountFingerprint(x[0]),fpgen1.GetCountFingerprint(x[1])) for x in related_ms] fpgen2 = rdFingerprintGenerator.GetTopologicalTorsionGenerator(fpSize=2048,countSimulation=True) fpsims_countsim = [DataStructs.TanimotoSimilarity(fpgen2.GetFingerprint(x[0]),fpgen2.GetFingerprint(x[1])) for x in ms] related_fpsims_countsim = [DataStructs.TanimotoSimilarity(fpgen2.GetFingerprint(x[0]),fpgen2.GetFingerprint(x[1])) for x in related_ms] . figsize(18,9) subplot(1,2,1) y,x = fpsims,countsims hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); xlabel(&#39;count&#39;) ylabel(&#39;bits&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Random pairs, TT spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); subplot(1,2,2) y,x = related_fpsims,related_countsims hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); xlabel(&#39;count&#39;) ylabel(&#39;bits&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Related pairs, TT spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); . figsize(18,9) subplot(1,2,1) x,y = countsims,fpsims_countsim hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); ylabel(&#39;count simulation&#39;) xlabel(&#39;count&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Random pairs, TT spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); subplot(1,2,2) x,y = related_countsims,related_fpsims_countsim hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); ylabel(&#39;count simulation&#39;) xlabel(&#39;count&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Related pairs, TT spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); . fpgen3 = rdFingerprintGenerator.GetTopologicalTorsionGenerator(fpSize=8192,countSimulation=True) fpsims_countsim2 = [DataStructs.TanimotoSimilarity(fpgen3.GetFingerprint(x[0]),fpgen3.GetFingerprint(x[1])) for x in ms] related_fpsims_countsim2 = [DataStructs.TanimotoSimilarity(fpgen3.GetFingerprint(x[0]),fpgen3.GetFingerprint(x[1])) for x in related_ms] figsize(18,9) subplot(1,2,1) x,y = countsims,fpsims_countsim2 hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); ylabel(&#39;count simulation 8192&#39;) xlabel(&#39;count&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Random pairs, TT spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); subplot(1,2,2) x,y = related_countsims,related_fpsims_countsim2 hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); ylabel(&#39;count simulation 8192&#39;) xlabel(&#39;count&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Related pairs, TT spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); . Atom pairs . fpgen1 = rdFingerprintGenerator.GetAtomPairGenerator(fpSize=2048,countSimulation=False) fpsims = [DataStructs.TanimotoSimilarity(fpgen1.GetFingerprint(x[0]),fpgen1.GetFingerprint(x[1])) for x in ms] countsims = [DataStructs.TanimotoSimilarity(fpgen1.GetCountFingerprint(x[0]),fpgen1.GetCountFingerprint(x[1])) for x in ms] related_fpsims = [DataStructs.TanimotoSimilarity(fpgen1.GetFingerprint(x[0]),fpgen1.GetFingerprint(x[1])) for x in related_ms] related_countsims = [DataStructs.TanimotoSimilarity(fpgen1.GetCountFingerprint(x[0]),fpgen1.GetCountFingerprint(x[1])) for x in related_ms] fpgen2 = rdFingerprintGenerator.GetAtomPairGenerator(fpSize=2048,countSimulation=True) fpsims_countsim = [DataStructs.TanimotoSimilarity(fpgen2.GetFingerprint(x[0]),fpgen2.GetFingerprint(x[1])) for x in ms] related_fpsims_countsim = [DataStructs.TanimotoSimilarity(fpgen2.GetFingerprint(x[0]),fpgen2.GetFingerprint(x[1])) for x in related_ms] . figsize(18,9) subplot(1,2,1) y,x = fpsims,countsims hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); xlabel(&#39;count&#39;) ylabel(&#39;bits&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Random pairs, AP spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); subplot(1,2,2) y,x = related_fpsims,related_countsims hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); xlabel(&#39;count&#39;) ylabel(&#39;bits&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Related pairs, AP spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); . figsize(18,9) subplot(1,2,1) x,y = countsims,fpsims_countsim hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); ylabel(&#39;count simulation&#39;) xlabel(&#39;count&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Random pairs, AP spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); subplot(1,2,2) x,y = related_countsims,related_fpsims_countsim hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); ylabel(&#39;count simulation&#39;) xlabel(&#39;count&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Related pairs, AP spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); . fpgen3 = rdFingerprintGenerator.GetAtomPairGenerator(fpSize=8192,countSimulation=True) fpsims_countsim2 = [DataStructs.TanimotoSimilarity(fpgen3.GetFingerprint(x[0]),fpgen3.GetFingerprint(x[1])) for x in ms] related_fpsims_countsim2 = [DataStructs.TanimotoSimilarity(fpgen3.GetFingerprint(x[0]),fpgen3.GetFingerprint(x[1])) for x in related_ms] figsize(18,9) subplot(1,2,1) x,y = countsims,fpsims_countsim2 hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); ylabel(&#39;count simulation 8192&#39;) xlabel(&#39;count&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Random pairs, AP spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); subplot(1,2,2) x,y = related_countsims,related_fpsims_countsim2 hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); ylabel(&#39;count simulation 8192&#39;) xlabel(&#39;count&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Related pairs, AP spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); . RDKit Fingerprint . fpgen1 = rdFingerprintGenerator.GetRDKitFPGenerator(fpSize=2048,countSimulation=False) fpsims = [DataStructs.TanimotoSimilarity(fpgen1.GetFingerprint(x[0]),fpgen1.GetFingerprint(x[1])) for x in ms] countsims = [DataStructs.TanimotoSimilarity(fpgen1.GetCountFingerprint(x[0]),fpgen1.GetCountFingerprint(x[1])) for x in ms] related_fpsims = [DataStructs.TanimotoSimilarity(fpgen1.GetFingerprint(x[0]),fpgen1.GetFingerprint(x[1])) for x in related_ms] related_countsims = [DataStructs.TanimotoSimilarity(fpgen1.GetCountFingerprint(x[0]),fpgen1.GetCountFingerprint(x[1])) for x in related_ms] fpgen2 = rdFingerprintGenerator.GetRDKitFPGenerator(fpSize=2048,countSimulation=True) fpsims_countsim = [DataStructs.TanimotoSimilarity(fpgen2.GetFingerprint(x[0]),fpgen2.GetFingerprint(x[1])) for x in ms] related_fpsims_countsim = [DataStructs.TanimotoSimilarity(fpgen2.GetFingerprint(x[0]),fpgen2.GetFingerprint(x[1])) for x in related_ms] . figsize(18,9) subplot(1,2,1) y,x = fpsims,countsims hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); xlabel(&#39;count&#39;) ylabel(&#39;bits&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Random pairs, RDKit spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); subplot(1,2,2) y,x = related_fpsims,related_countsims hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); xlabel(&#39;count&#39;) ylabel(&#39;bits&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Related pairs, RDKit spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); . figsize(18,9) subplot(1,2,1) x,y = countsims,fpsims_countsim hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); ylabel(&#39;count simulation&#39;) xlabel(&#39;count&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Random pairs, RDKit spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); subplot(1,2,2) x,y = related_countsims,related_fpsims_countsim hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); ylabel(&#39;count simulation&#39;) xlabel(&#39;count&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Related pairs, RDKit spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); . This is terrible, but I suspect that has to do with the number of bits set by RDKit fingerprints just totally overloading things. . fpgen3 = rdFingerprintGenerator.GetRDKitFPGenerator(fpSize=8192,countSimulation=True) fpsims_countsim2 = [DataStructs.TanimotoSimilarity(fpgen3.GetFingerprint(x[0]),fpgen3.GetFingerprint(x[1])) for x in ms] related_fpsims_countsim2 = [DataStructs.TanimotoSimilarity(fpgen3.GetFingerprint(x[0]),fpgen3.GetFingerprint(x[1])) for x in related_ms] figsize(18,9) subplot(1,2,1) x,y = countsims,fpsims_countsim2 hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); ylabel(&#39;count simulation 8192&#39;) xlabel(&#39;count&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Random pairs, RDKit spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); subplot(1,2,2) x,y = related_countsims,related_fpsims_countsim2 hexbin(x,y,cmap=&#39;Blues&#39;,bins=&#39;log&#39;); plot((0,1),(0,1),&#39;k&#39;); ylabel(&#39;count simulation 8192&#39;) xlabel(&#39;count&#39;); sr,p = spearmanr(x,y) mae = median_absolute_error(x,y) rmse = sqrt(mean_squared_error(x,y)) title(f&#39;Related pairs, RDKit spearman r={sr:.3f} MAE={mae:.3f} RMSE={rmse:.3f}&#39;); . That&#39;s way better .",
            "url": "https://greglandrum.github.io/rdkit-blog/fingerprints/technical/reference/2021/07/06/simulating-counts.html",
            "relUrl": "/fingerprints/technical/reference/2021/07/06/simulating-counts.html",
            "date": " • Jul 6, 2021"
        }
        
    
  
    
        ,"post16": {
            "title": "Looking at the number of bits set by different fingerprints",
            "content": "This is an updated version of a post. The original version of the notebook can be found in github. . I&#39;ve done a number of posts looking at Morgan fingerprint statistics before, including: . The number of collisions in Morgan fingerprints. | Morgan fingerprint stats | Collisions in Morgan fingerprints revisited | . I have done similar analysis for other fingerprint types, but it looks like I didn&#39;t post that (at least I can&#39;t find it if I did). It&#39;s useful to do this because, as we&#39;ll see, the different fingerprint types have very different numbers of bits set for typical molecules. . Here&#39;s the summary of the mean and standard deviation of the number of bits set, from an analysis of 5 million molecules with less than 50 heavy atoms extracted from ZINC: . Fingerprint Type Mean num_bits SD num_bits . Morgan1 | sparse | 29.4 | 5.6 | . Morgan2 | sparse | 48.7 | 9.6 | . Morgan3 | sparse | 66.8 | 13.8 | . FeatMorgan1 | sparse | 20.1 | 3.9 | . FeatMorgan2 | sparse | 38.1 | 7.7 | . FeatMorgan3 | sparse | 56.0 | 11.8 | . RDKit5 | bitvect | 363 | 122 | . RDKit6 | bitvect | 621 | 233 | . RDKit7 | bitvect | 993 | 406 | . pattern | bitvect | 446 | 122 | . avalon | bitvect | 280 | 130 | . atom pairs | sparse | 167 | 56 | . TT | sparse | 33.4 | 9.8 | . atom pairs | bitvect | 267 | 90 | . TT | bitvect | 47.2 | 12.0 | . The bit vector fingerprints were all 4096 bits long. . from rdkit import Chem,DataStructs import time,random,gzip,pickle,copy import numpy as np from collections import Counter,defaultdict from rdkit.Chem import Draw from rdkit.Chem import rdMolDescriptors from rdkit.Avalon import pyAvalonTools from rdkit.Chem.Draw import IPythonConsole from rdkit import DataStructs from rdkit import rdBase %pylab inline print(rdBase.rdkitVersion) import time print(time.asctime()) . Populating the interactive namespace from numpy and matplotlib 2021.09.1pre Tue Jul 6 04:58:28 2021 . /home/glandrum/miniconda3/lib/python3.7/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: [&#39;copy&#39;, &#39;random&#39;] `%matplotlib` prevents importing * from pylab and numpy &#34; n`%matplotlib` prevents importing * from pylab and numpy&#34; . try: import ipyparallel as ipp rc = ipp.Client() dview = rc[:] dview.execute(&#39;from rdkit import Chem&#39;) dview.execute(&#39;from rdkit import Descriptors&#39;) dview.execute(&#39;from rdkit.Chem import rdMolDescriptors&#39;) dview.execute(&#39;from rdkit.Avalon import pyAvalonTools&#39;) except: print(&quot;could not use ipyparallel&quot;) dview = None . For test data I&#39;ll use the same 16 million ZINC compounds I used in the bit statistics post. . filen=&#39;/scratch/RDKit_git/LocalData/Zinc/zinc_all_clean.pkl.gz&#39; . Loop over the molecules, skip anything with more than 50 atoms, and build fingerprints for all the others. . The fingerprints I generate for this analysis are: . Sparse Morgan with radii 1, 2, and 3 | Sparse FeatureMorgan with radii 1, 2, and 3 | RDKit BitVect with maxPath 5, 6, and 7 | Pattern BitVect | Avalon BitVect | Sparse Atom Pairs | Sparse Topological Torsions | Atom Pair BitVect | Topological Torsion BitVect | . All of the BitVect fingerprints are 4096 bits long . import copy historyf = gzip.open(&#39;../data/fp_bit_counts.history.pkl.gz&#39;,&#39;wb+&#39;) counts=defaultdict(Counter) t1 = time.time() with gzip.open(filen,&#39;rb&#39;) as inf: i = 0 ms = [] while 1: try: m,nm = pickle.load(inf) except EOFError: break if not m or m.GetNumHeavyAtoms()&gt;50: continue ms.append(m) i+=1 if len(ms)&gt;=10000: for v in 1,2,3: cnts = dview.map_sync(lambda x,v=v:len(rdMolDescriptors.GetMorganFingerprint(x,v).GetNonzeroElements()), ms) for obc in cnts: counts[(&#39;Morgan&#39;,v)][obc]+=1 for v in 1,2,3: cnts = dview.map_sync(lambda x,v=v:len(rdMolDescriptors.GetMorganFingerprint(x,v,useFeatures=True).GetNonzeroElements()), ms) for obc in cnts: counts[(&#39;FeatMorgan&#39;,v)][obc]+=1 for v in 5,6,7: cnts = dview.map_sync(lambda x,v=v:Chem.RDKFingerprint(x,maxPath=v,fpSize=4096).GetNumOnBits(), ms) for obc in cnts: counts[(&#39;RDKit&#39;,v)][obc]+=1 cnts = dview.map_sync(lambda x:Chem.PatternFingerprint(x,fpSize=4096).GetNumOnBits(), ms) for obc in cnts: counts[(&#39;pattern&#39;,-1)][obc]+=1 cnts = dview.map_sync(lambda x:pyAvalonTools.GetAvalonFP(x,nBits=4096).GetNumOnBits(), ms) for obc in cnts: counts[(&#39;avalon&#39;,-1)][obc]+=1 cnts = dview.map_sync(lambda x:len(rdMolDescriptors.GetAtomPairFingerprint(x).GetNonzeroElements()), ms) for obc in cnts: counts[(&#39;ap-counts&#39;,-1)][obc]+=1 cnts = dview.map_sync(lambda x:len(rdMolDescriptors.GetTopologicalTorsionFingerprint(x).GetNonzeroElements()), ms) for obc in cnts: counts[(&#39;tt-counts&#39;,-1)][obc]+=1 cnts = dview.map_sync(lambda x:rdMolDescriptors.GetHashedAtomPairFingerprintAsBitVect(x,nBits=4096).GetNumOnBits(), ms) for obc in cnts: counts[(&#39;ap-bv&#39;,-1)][obc]+=1 cnts = dview.map_sync(lambda x:rdMolDescriptors.GetHashedTopologicalTorsionFingerprintAsBitVect(x,nBits=4096).GetNumOnBits(), ms) for obc in cnts: counts[(&#39;tt-bv&#39;,-1)][obc]+=1 ms = [] if not i%50000: t2 = time.time() print(&quot;Done %d in %.2f sec&quot;%(i,t2-t1)) if not i%500000: pickle.dump(dict(counts),historyf) if i&gt;=5000000: break . Done 50000 in 38.63 sec Done 100000 in 77.02 sec Done 150000 in 115.17 sec Done 200000 in 163.61 sec Done 250000 in 215.39 sec Done 300000 in 267.96 sec Done 350000 in 319.74 sec Done 400000 in 373.11 sec Done 450000 in 415.37 sec Done 500000 in 468.50 sec Done 550000 in 526.23 sec Done 600000 in 570.65 sec Done 650000 in 622.83 sec Done 700000 in 674.11 sec Done 750000 in 724.71 sec Done 800000 in 775.76 sec Done 850000 in 823.44 sec Done 900000 in 873.37 sec Done 950000 in 922.91 sec Done 1000000 in 971.03 sec Done 1050000 in 1019.84 sec Done 1100000 in 1068.24 sec Done 1150000 in 1116.11 sec Done 1200000 in 1164.39 sec Done 1250000 in 1211.31 sec Done 1300000 in 1255.67 sec Done 1350000 in 1306.25 sec Done 1400000 in 1356.04 sec Done 1450000 in 1402.95 sec Done 1500000 in 1453.38 sec Done 1550000 in 1500.31 sec Done 1600000 in 1546.90 sec Done 1650000 in 1593.48 sec Done 1700000 in 1640.38 sec Done 1750000 in 1696.32 sec Done 1800000 in 1750.83 sec Done 1850000 in 1810.42 sec Done 1900000 in 1868.12 sec Done 1950000 in 1926.07 sec Done 2000000 in 1983.37 sec Done 2050000 in 2043.56 sec Done 2100000 in 2102.81 sec Done 2150000 in 2160.67 sec Done 2200000 in 2218.30 sec Done 2250000 in 2272.73 sec Done 2300000 in 2323.77 sec Done 2350000 in 2375.39 sec Done 2400000 in 2427.04 sec Done 2450000 in 2481.36 sec Done 2500000 in 2536.57 sec Done 2550000 in 2591.71 sec Done 2600000 in 2644.06 sec Done 2650000 in 2698.32 sec Done 2700000 in 2752.86 sec Done 2750000 in 2805.41 sec Done 2800000 in 2856.95 sec Done 2850000 in 2909.60 sec Done 2900000 in 2965.05 sec Done 2950000 in 3021.72 sec Done 3000000 in 3073.35 sec Done 3050000 in 3127.90 sec Done 3100000 in 3177.67 sec Done 3150000 in 3234.92 sec Done 3200000 in 3288.20 sec Done 3250000 in 3341.28 sec Done 3300000 in 3393.97 sec Done 3350000 in 3446.92 sec Done 3400000 in 3499.45 sec Done 3450000 in 3549.88 sec Done 3500000 in 3601.67 sec Done 3550000 in 3653.41 sec Done 3600000 in 3705.95 sec Done 3650000 in 3759.37 sec Done 3700000 in 3810.11 sec Done 3750000 in 3861.68 sec Done 3800000 in 3912.28 sec Done 3850000 in 3965.28 sec Done 3900000 in 4022.67 sec Done 3950000 in 4077.32 sec Done 4000000 in 4129.91 sec Done 4050000 in 4185.33 sec Done 4100000 in 4240.67 sec Done 4150000 in 4287.86 sec Done 4200000 in 4340.04 sec Done 4250000 in 4391.57 sec Done 4300000 in 4443.67 sec Done 4350000 in 4493.96 sec Done 4400000 in 4545.53 sec Done 4450000 in 4592.16 sec Done 4500000 in 4640.05 sec Done 4550000 in 4687.30 sec Done 4600000 in 4733.79 sec Done 4650000 in 4780.85 sec Done 4700000 in 4828.29 sec Done 4750000 in 4878.40 sec Done 4800000 in 4927.55 sec Done 4850000 in 4984.36 sec Done 4900000 in 5042.20 sec Done 4950000 in 5101.82 sec Done 5000000 in 5154.32 sec . pickle.dump(dict(counts),gzip.open(&#39;../data/fp_bit_counts.pkl.gz&#39;,&#39;wb+&#39;)) . Now plot the distributions of the number of bits set . morgan_ks = [x for x in counts.keys() if x[0] ==&#39;Morgan&#39;] featmorgan_ks = [x for x in counts.keys() if x[0] ==&#39;FeatMorgan&#39;] rdkit_ks = [x for x in counts.keys() if x[0] == &#39;RDKit&#39;] figure(figsize=(15,15)) pidx=1 subplot(3,3,pidx) for n,r in morgan_ks: cnts = sorted(counts[(n,r)].items()) plot([x for x,y in cnts],[y for x,y in cnts],label= f&quot;r={r}&quot;) _=title(&quot;Morgan&quot;) _=xlabel(&quot;num bits set&quot;) _=ylabel(&quot;count&quot;) _=legend() pidx=2 subplot(3,3,pidx) for n,r in featmorgan_ks: cnts = sorted(counts[(n,r)].items()) plot([x for x,y in cnts],[y for x,y in cnts],label= f&quot;r={r}&quot;) _=title(&quot;FeatMorgan&quot;) _=xlabel(&quot;num bits set&quot;) _=ylabel(&quot;count&quot;) _=legend() pidx=3 subplot(3,3,pidx) for n,r in rdkit_ks: cnts = sorted(counts[(n,r)].items()) plot([x for x,y in cnts],[y for x,y in cnts],label= f&quot;r={r}&quot;) _=title(&quot;RDKit&quot;) _=xlabel(&quot;num bits set&quot;) _=ylabel(&quot;count&quot;) _=legend() for k in counts.keys(): if k[0] in (&#39;Morgan&#39;,&#39;FeatMorgan&#39;,&#39;RDKit&#39;): continue pidx+=1 subplot(3,3,pidx) cnts = sorted(counts[k].items()) plot([x for x,y in cnts],[y for x,y in cnts]) _=title(k[0]) _=xlabel(&quot;num bits set&quot;) _=ylabel(&quot;count&quot;) . The avalon FP curve has an interesting shape . for k,cnts in counts.items(): accum = 0 denom = 0 for cnt,num in cnts.items(): accum += cnt*num denom += num mean = accum/denom dev = 0 for cnt,num in cnts.items(): dev += num*(cnt-mean)**2 dev /= (denom-1) dev = dev**0.5 label = k[0] if k[1]!=-1: label += str(k[1]) print(label,&#39; t%.1f&#39;%mean,&#39;%.1f&#39;%dev) . Morgan1 29.4 5.6 Morgan2 48.7 9.6 Morgan3 66.8 13.8 FeatMorgan1 20.1 3.9 FeatMorgan2 38.1 7.7 FeatMorgan3 56.0 11.8 RDKit5 363.3 122.5 RDKit6 621.7 233.2 RDKit7 993.6 406.3 pattern 445.5 122.5 avalon 279.8 129.9 ap-counts 166.6 56.3 tt-counts 33.4 9.8 ap-bv 267.3 90.0 tt-bv 47.2 12.0 . Convergence . I did 5 million examples, which took a while (about 1.5 hours with 6 worker processes on my PC). Could I have analyzed less and gotten to the same results? Did the means converge? If so, how quickly? . historyf = gzip.open(&#39;../data/fp_bit_counts.history.pkl.gz&#39;,&#39;rb&#39;) means = defaultdict(list) devs = defaultdict(list) nmols = [] while 1: try: lcounts = pickle.load(historyf) except EOFError: break for k,cnts in lcounts.items(): accum = 0 denom = 0 for cnt,num in cnts.items(): accum += cnt*num denom += num mean = accum/denom dev = 0 for cnt,num in cnts.items(): dev += num*(cnt-mean)**2 dev /= (denom-1) dev = dev**0.5 if denom not in nmols: nmols.append(denom) means[k].append(mean) devs[k].append(dev) label = k[0] if k[1]!=-1: label += str(k[1]) print(denom,label,&#39; t%.1f&#39;%mean,&#39;%.1f&#39;%dev) . 500000 Morgan1 26.0 6.2 500000 Morgan2 42.8 10.7 500000 Morgan3 58.7 15.5 500000 FeatMorgan1 18.2 4.3 500000 FeatMorgan2 33.8 8.5 500000 FeatMorgan3 49.5 13.2 500000 RDKit5 324.6 133.9 500000 RDKit6 560.8 256.2 500000 RDKit7 902.9 445.7 500000 pattern 408.8 133.9 500000 avalon 241.8 133.8 500000 ap-counts 133.3 57.6 500000 tt-counts 28.6 10.2 500000 ap-bv 219.5 93.6 500000 tt-bv 41.9 12.9 1000000 Morgan1 27.1 6.1 1000000 Morgan2 44.6 10.5 1000000 Morgan3 61.2 15.2 1000000 FeatMorgan1 18.9 4.2 1000000 FeatMorgan2 35.2 8.4 1000000 FeatMorgan3 51.6 13.0 1000000 RDKit5 340.7 133.9 1000000 RDKit6 588.9 257.4 1000000 RDKit7 948.5 449.9 1000000 pattern 425.2 136.0 1000000 avalon 257.7 136.7 1000000 ap-counts 143.7 57.7 1000000 tt-counts 30.1 10.1 1000000 ap-bv 234.4 92.8 1000000 tt-bv 43.6 12.9 1500000 Morgan1 27.3 5.8 1500000 Morgan2 45.0 9.9 1500000 Morgan3 61.7 14.3 1500000 FeatMorgan1 19.0 4.1 1500000 FeatMorgan2 35.5 8.0 1500000 FeatMorgan3 52.0 12.3 1500000 RDKit5 340.3 127.8 1500000 RDKit6 587.1 246.2 1500000 RDKit7 944.8 432.0 1500000 pattern 424.0 129.4 1500000 avalon 260.5 133.7 1500000 ap-counts 145.1 54.8 1500000 tt-counts 30.5 9.8 1500000 ap-bv 234.9 87.3 1500000 tt-bv 43.7 12.3 2000000 Morgan1 28.0 5.7 2000000 Morgan2 46.2 9.8 2000000 Morgan3 63.4 14.1 2000000 FeatMorgan1 19.4 4.0 2000000 FeatMorgan2 36.3 7.9 2000000 FeatMorgan3 53.3 12.1 2000000 RDKit5 350.7 126.6 2000000 RDKit6 603.5 243.1 2000000 RDKit7 969.0 425.8 2000000 pattern 433.3 128.0 2000000 avalon 269.5 133.1 2000000 ap-counts 152.4 55.5 2000000 tt-counts 31.5 9.8 2000000 ap-bv 245.8 88.2 2000000 tt-bv 45.0 12.2 2500000 Morgan1 28.7 5.8 2500000 Morgan2 47.5 9.8 2500000 Morgan3 65.3 14.2 2500000 FeatMorgan1 19.7 4.0 2500000 FeatMorgan2 37.2 7.9 2500000 FeatMorgan3 54.7 12.1 2500000 RDKit5 361.5 126.3 2500000 RDKit6 621.2 241.1 2500000 RDKit7 996.0 420.5 2500000 pattern 443.2 126.4 2500000 avalon 278.4 132.6 2500000 ap-counts 160.1 56.9 2500000 tt-counts 32.6 9.9 2500000 ap-bv 257.9 90.2 2500000 tt-bv 46.3 12.2 3000000 Morgan1 29.1 5.7 3000000 Morgan2 48.1 9.8 3000000 Morgan3 66.1 14.1 3000000 FeatMorgan1 19.9 3.9 3000000 FeatMorgan2 37.6 7.8 3000000 FeatMorgan3 55.3 12.0 3000000 RDKit5 364.5 124.5 3000000 RDKit6 625.3 237.2 3000000 RDKit7 1001.4 413.2 3000000 pattern 446.5 124.1 3000000 avalon 280.5 131.5 3000000 ap-counts 163.7 57.0 3000000 tt-counts 33.1 9.8 3000000 ap-bv 263.5 90.5 3000000 tt-bv 46.9 12.1 3500000 Morgan1 29.2 5.7 3500000 Morgan2 48.3 9.7 3500000 Morgan3 66.4 14.0 3500000 FeatMorgan1 19.9 3.9 3500000 FeatMorgan2 37.7 7.8 3500000 FeatMorgan3 55.6 11.9 3500000 RDKit5 365.3 123.8 3500000 RDKit6 626.7 236.0 3500000 RDKit7 1003.7 411.3 3500000 pattern 448.4 123.3 3500000 avalon 280.3 131.1 3500000 ap-counts 165.1 56.7 3500000 tt-counts 33.3 9.8 3500000 ap-bv 265.9 90.1 3500000 tt-bv 47.2 12.1 4000000 Morgan1 29.4 5.7 4000000 Morgan2 48.6 9.8 4000000 Morgan3 66.7 14.1 4000000 FeatMorgan1 20.0 3.9 4000000 FeatMorgan2 38.0 7.8 4000000 FeatMorgan3 55.9 12.0 4000000 RDKit5 365.2 124.1 4000000 RDKit6 627.1 236.6 4000000 RDKit7 1005.0 412.4 4000000 pattern 448.6 124.0 4000000 avalon 281.4 131.3 4000000 ap-counts 165.7 56.9 4000000 tt-counts 33.4 9.9 4000000 ap-bv 266.8 90.6 4000000 tt-bv 47.3 12.2 4500000 Morgan1 29.4 5.6 4500000 Morgan2 48.7 9.6 4500000 Morgan3 66.8 13.9 4500000 FeatMorgan1 20.1 3.9 4500000 FeatMorgan2 38.0 7.7 4500000 FeatMorgan3 55.9 11.8 4500000 RDKit5 364.3 123.1 4500000 RDKit6 624.4 234.6 4500000 RDKit7 999.1 408.8 4500000 pattern 447.0 122.7 4500000 avalon 280.7 130.6 4500000 ap-counts 166.3 56.4 4500000 tt-counts 33.4 9.8 4500000 ap-bv 267.3 89.9 4500000 tt-bv 47.3 12.1 5000000 Morgan1 29.4 5.6 5000000 Morgan2 48.7 9.6 5000000 Morgan3 66.8 13.8 5000000 FeatMorgan1 20.1 3.9 5000000 FeatMorgan2 38.1 7.7 5000000 FeatMorgan3 56.0 11.8 5000000 RDKit5 363.3 122.5 5000000 RDKit6 621.7 233.2 5000000 RDKit7 993.6 406.3 5000000 pattern 445.5 122.5 5000000 avalon 279.8 129.9 5000000 ap-counts 166.6 56.3 5000000 tt-counts 33.4 9.8 5000000 ap-bv 267.3 90.0 5000000 tt-bv 47.2 12.0 . Let&#39;s look at those graphically: . morgan_ks = [x for x in counts.keys() if x[0] ==&#39;Morgan&#39;] featmorgan_ks = [x for x in counts.keys() if x[0] ==&#39;FeatMorgan&#39;] rdkit_ks = [x for x in counts.keys() if x[0] == &#39;RDKit&#39;] figure(figsize=(15,15)) nmols2 = [x/1000000 for x in nmols] pidx=1 subplot(3,3,pidx) for n,r in morgan_ks: lmeans = means[(n,r)] ldevs = devs[(n,r)] errorbar(nmols2,lmeans,yerr=ldevs,capsize=3) _=title(&quot;Morgan&quot;) _=xlabel(&quot;num mols (millions)&quot;) _=ylabel(&quot;count&quot;) #_=legend() pidx=2 subplot(3,3,pidx) for n,r in featmorgan_ks: lmeans = means[(n,r)] ldevs = devs[(n,r)] errorbar(nmols2,lmeans,yerr=ldevs,capsize=3) _=title(&quot;FeatMorgan&quot;) _=xlabel(&quot;num mols (millions)&quot;) _=ylabel(&quot;count&quot;) #_=legend() pidx=3 subplot(3,3,pidx) for n,r in rdkit_ks: lmeans = means[(n,r)] ldevs = devs[(n,r)] errorbar(nmols2,lmeans,yerr=ldevs,capsize=3) _=title(&quot;RDKit&quot;) _=xlabel(&quot;num mols (millions)&quot;) _=ylabel(&quot;count&quot;) #_=legend() for k in counts.keys(): if k[0] in (&#39;Morgan&#39;,&#39;FeatMorgan&#39;,&#39;RDKit&#39;): continue pidx+=1 subplot(3,3,pidx) lmeans = means[k] ldevs = devs[k] errorbar(nmols2,lmeans,yerr=ldevs,capsize=3) _=title(k[0]) _=xlabel(&quot;num mols (millions)&quot;) _=ylabel(&quot;count&quot;) . Looks like we would have been fine with 3 million molecules. .",
            "url": "https://greglandrum.github.io/rdkit-blog/fingerprints/reference/2021/07/06/number-of-fp-bits-set.html",
            "relUrl": "/fingerprints/reference/2021/07/06/number-of-fp-bits-set.html",
            "date": " • Jul 6, 2021"
        }
        
    
  
    
        ,"post17": {
            "title": "Some observations about similarity search thresholds",
            "content": "Updated 08.06.2021 after I expanded the set of “related compounds”. The source of the previous version of the post is available in github. The updates didn’t change the discussion that much. . TL;DR . Based on the analysis here it looks like the fingerprint the RDKit provides which does the best job of efficiently retrieving chemically similar structures is the RDKit fingerprint with maxPath set to 6. . Intro / Results . I recently did a post presenting an approach for finding reasonable thresholds for similarity searches using the fingerprints the RDKit provides. This is a followup to that one written after I’ve done some more looking at the data. I want to come up with a suggestion for which fingerprint to use for similarity searches when the goal is retrieving as many chemically related compounds as possible. I’ll do that by looking at search efficiency as measured by the fraction of the total database retrieved when using similarity thresholds sufficient to return 90-95% of the related compounds. See the earlier post for an explanation of what “related compounds” means here and how the searches were done. . As a reminder, this is how I presented the results in that post and how to interpret the data: . 0.95 of related compounds 0.9 of related compounds 0.8 of related compounds 0.5 of related compounds . Fingerprint 0.95 noise level threshold db fraction / count per million threshold db fraction / count per million threshold db fraction / count per million threshold db fraction / count per million . Morgan2 (bits) | 0.27 | 0.4 | 0.00019 / 190 | 0.4 | 0.00019 / 190 | 0.45 | 0.00012 / 115 | 0.55 | 2.5e-05 / 25 | . The 0.95 noise level (from the previous analysis) for the MFP2 fingerprint is 0.27. If I want to retrieve 95% of the related compounds I need to set the similarity threshold to 0.4. With this threshold I would retrieve ~190 compounds per million compounds in the database (0.4% of the database). Similarly, if I were willing to live with finding 50% of the related actives I could set the search threshold to 0.55, in which case I’d only retrieve ~25 rows per million compounds in the database. . I won’t reproduce the full results table from the post here, but here are the rows with the highest search efficiencies (lowest number of compounds returned from the “background database”) at 90% and 95% of related compounds found. I sorted the table by the efficiency at 90% of related compounds retrieved: . 0.95 of related compounds 0.9 of related compounds 0.8 of related compounds 0.5 of related compounds . Fingerprint 0.95 noise level threshold db fraction / count per million threshold db fraction / count per million threshold db fraction / count per million threshold db fraction / count per million . RDKit 7 (bits) | 0.43 | 0.55 | 0.00051 / 510 | 0.6 | 8e-05 / 80 | 0.6 | 8e-05 / 80 | 0.7 | 3e-05 / 30 | . Topological Torsions (counts) | 0.19 | 0.35 | 0.00049 / 489 | 0.4 | 0.00011 / 110 | 0.45 | 7.5e-05 / 75 | 0.55 | 2.5e-05 / 25 | . linear RDKit 7 (bits) | 0.26 | 0.45 | 0.00053 / 535 | 0.5 | 0.00013 / 130 | 0.55 | 9e-05 / 90 | 0.65 | 3.5e-05 / 35 | . RDKit 6 (bits) | 0.31 | 0.5 | 0.00021 / 210 | 0.55 | 0.00014 / 135 | 0.6 | 6e-05 / 60 | 0.7 | 3e-05 / 30 | . Morgan2 (counts) | 0.25 | 0.4 | 0.00014 / 140 | 0.4 | 0.00014 / 140 | 0.45 | 8.5e-05 / 84 | 0.55 | 2e-05 / 20 | . Avalon 1024 (bits) | 0.37 | 0.55 | 0.00075 / 750 | 0.6 | 0.00014 / 140 | 0.65 | 9e-05 / 90 | 0.75 | 2.5e-05 / 25 | . Morgan3 (counts) | 0.20 | 0.3 | 0.00026 / 260 | 0.35 | 0.00015 / 154 | 0.35 | 0.00015 / 154 | 0.45 | 3.5e-05 / 35 | . RDKit 5 (bits) | 0.29 | 0.5 | 0.00025 / 250 | 0.55 | 0.00016 / 155 | 0.6 | 6e-05 / 60 | 0.7 | 3e-05 / 30 | . Topological Torsions (bits) | 0.22 | 0.4 | 0.00016 / 160 | 0.4 | 0.00016 / 160 | 0.45 | 0.00011 / 105 | 0.55 | 3.5e-05 / 35 | . Morgan2 (bits) | 0.27 | 0.4 | 0.00019 / 190 | 0.4 | 0.00019 / 190 | 0.45 | 0.00012 / 115 | 0.55 | 2.5e-05 / 25 | . FeatMorgan3 (counts) | 0.28 | 0.4 | 0.00022 / 220 | 0.4 | 0.00022 / 220 | 0.45 | 0.00013 / 130 | 0.55 | 3e-05 / 30 | . linear RDKit 6 (bits) | 0.28 | 0.5 | 0.00022 / 220 | 0.5 | 0.00022 / 220 | 0.55 | 0.00014 / 140 | 0.7 | 3e-05 / 30 | . The threshold values are rounded to the nearest 0.05. . I’ve included count-based fingerprints in the above table, but they wouldn’t be my first choice for use in a real-world similarity search application. Calculating similarity for count-based fingerprints is significantly slower than bit vector fingerprints, so they really aren’t practical for large datasets. Note that the RDKit has a method for approximating counts using bit vector fingerprints which is used by the Atom Pair and Topological Torsion fingeprints and could also be an option for the other fingerprint types, but that’s a topic for another post. . Based on these numbers (and, of course, the dataset I used) it looks like the RDKit fingerprint is the optimal choice for chemical similarity search. Taking the efficiency at both 90% and 95% into account, the version of the fingerprint with maxPath=6 is arguably better than the version with maxPath=7 (which is the default). There’s not a publication for the RDKit fingerprint but it is described in detail in the RDKit documentation. . The Morgan3 fingerprint, which is what I kind of expected to be the best at this task, doesn’t do that well - the bit-vector based form didn’t even make this list of top performaers. The Morgan2 fingerprint, on the other hand, seems like another good choice. The Morgan fingerprints are the RDKit’s implementation of the circular fingerprints described in this publication. . A real surprise to me was how well the topological torsions fingerprint does at this chemical search. I had (I guess without much evidence) thought of it as more of a fuzzy (or “scaffold-hopping”) fingerprint, but the high efficiency on this chemical search problem makes me reconsider that. Topological torsions were introduced in this publication. . The Avalon fingerprint seems to be another decent choice, at least at 90%. This isn’t surprising to me, but I’ll probably remain resistant to making heavy of it due to the complexity of the fingerprint itself. The only non-code description I’m aware of for the Avalon FP is in the supplementary material for this paper; it’s likely that the current version of the fingerprint, which was under active development for at least 10 years after that paper appeared, deviates from that. . Before getting any deeper into details with this kind of analysis, I think I would like to look into using more than 10K of the “related” molecules and increasing the size of the background database just to make sure the statistics are solid. I’ll do that in a separate post and leave the count-based fingerprints out. .",
            "url": "https://greglandrum.github.io/rdkit-blog/similarity/reference/2021/05/26/similarity-threshold-observations1.html",
            "relUrl": "/similarity/reference/2021/05/26/similarity-threshold-observations1.html",
            "date": " • May 26, 2021"
        }
        
    
  
    
        ,"post18": {
            "title": "Fingerprint similarity thresholds for database searches",
            "content": "Updated 08.06.2021 after I expanded the set of “related compounds”. The source of the previous version of the post is available in github . Prologue . If you’re interested in this topic and have questions, notice mistakes in my analysis, or have suggestions or ideas for improving this (particularly when it comes to the sets of “related compounds” I use), please either send me email or leave a comment. . Intro / Results . One of the RDKit blog posts I refer back to the most is the one where I tried to establish the Tanimoto similarity value which constitutes a “noise level” for each of the fingerprints the RDKit supports by looking at the distributions of similarities between randomly chosen molecules. I periodically update the post just in case the threshold values change with RDKit versions. Here’s the most recent version of the post and the associated jupyter notebook. I find it really useful to be able to say things like “The 95% noise level for Tanimoto similarity calculated with the the bit-based version of the RDKit’s MFP2 is 0.27.” Based on this I know that when doing similarity searches the threshold for MFP2 shouldn’t be set below 0.27 (I normally say 0.3) in most cases. But that analysis doesn’t tell me what I should set the threshold to. . Of course the answer to that question is “it depends”. Let’s assume that the database you’re searching contains a certain number of compounds which would actually be interesting for you and a much larger number of compounds which are not interesting (at least not for the search you’re currently running). And let’s further assume that the similarities between those interesting compounds and your query is generally above the noise level for the fingerprint you’re using. Any similarity search is going to return a mix of both interesting and non-interesting compounds and the proportions in that mix are generally going to be determined by the similarity threshould you use. Setting the similarity threshold high tends to give a larger proportion of interesting compounds at the cost of missing interesting compounds while a lower threshold will return more of the interesting compounds but a higher fraction of uninteresting compounds. . Basically how bad your FOMO is will determine how many results you need to look through. . This isn’t a big deal if you’re searching a small database and or if you’re going to be post-processing the results using some other computational tool, but if the idea is that you’re going to actually be looking at the results of the similarity search, then result sets with 10K or more rows are going to require a lot of patience. . This post is an attempt to come up with recommendations for reasonable threshold values for the common RDKit fingerprints so that you can make a more informed decision about what to use for a given search. . There’s a more complete description below along with links to the jupyter notebooks with the actual code, but here’s a quick summary of what I did: . I started with 1047 groups of related compounds (~66K compounds in all). Each group is a set of 50-100 compounds from a single ChEMBL document. | I calculated intra-group similarities within each of those 1047 groups using each of the fingerprint types to determine thresholds for retrieving various fractions of each group. | I used a randomly selected subset of 10K of those compounds to do similarity searches on 100K molecules randomly selected from ChEMBL in order to determine what fraction of the database would be retrieved for various similarity thresholds. | Here are what the results look like for bit-based MFP2: . 0.95 of related compounds 0.9 of related compounds 0.8 of related compounds 0.5 of related compounds . Fingerprint 0.95 noise level threshold db fraction / count per million threshold db fraction / count per million threshold db fraction / count per million threshold db fraction / count per million . Morgan2 (bits) | 0.27 | 0.4 | 0.00019 / 190 | 0.4 | 0.00019 / 190 | 0.45 | 0.00012 / 115 | 0.55 | 2.5e-05 / 25 | . The 0.95 noise level (from the previous analysis) for this FP is 0.27. If I want to retrieve 95% of the related compounds I need to set the similarity threshold to 0.4. With this threshold I would retrieve ~190 compounds per million compounds in the database (0.4% of the database). Similarly, if I were willing to live with finding 50% of the related actives I could set the search threshold to 0.55, in which case I’d only retrieve ~25 rows per million compounds in the database. . I find this is a useful way of thinking about the thresholds: it makes the balance between recall (number of interesting compounds retrieved) and the overall result set size visible. For example, for the MFP2 results shown above, if I’m willing to live with retrieving about 90% of the interesting compounds instead of 95% I would only have to look through about 1/8th of the results from the database. . With that explained, here’s the full results table: . 0.95 of related compounds 0.9 of related compounds 0.8 of related compounds 0.5 of related compounds . Fingerprint 0.95 noise level threshold db fraction / count per million threshold db fraction / count per million threshold db fraction / count per million threshold db fraction / count per million . MACCS | 0.57 | 0.65 | 0.016 / 15820 | 0.65 | 0.016 / 15820 | 0.7 | 0.0019 / 1880 | 0.8 | 8e-05 / 80 | . Morgan0 (counts) | 0.57 | 0.6 | 0.017 / 16990 | 0.6 | 0.017 / 16990 | 0.65 | 0.009 / 9040 | 0.75 | 0.00057 / 565 | . Morgan1 (counts) | 0.36 | 0.5 | 0.0003 / 300 | 0.5 | 0.0003 / 300 | 0.55 | 0.00017 / 170 | 0.65 | 2.5e-05 / 25 | . Morgan2 (counts) | 0.25 | 0.4 | 0.00014 / 140 | 0.4 | 0.00014 / 140 | 0.45 | 8.5e-05 / 84 | 0.55 | 2e-05 / 20 | . Morgan3 (counts) | 0.20 | 0.3 | 0.00026 / 260 | 0.35 | 0.00015 / 154 | 0.35 | 0.00015 / 154 | 0.45 | 3.5e-05 / 35 | . Morgan0 (bits) | 0.57 | 0.6 | 0.019 / 18550 | 0.6 | 0.019 / 18550 | 0.65 | 0.0099 / 9880 | 0.75 | 0.00063 / 629 | . Morgan1 (bits) | 0.37 | 0.5 | 0.00036 / 360 | 0.5 | 0.00036 / 360 | 0.55 | 0.0002 / 200 | 0.65 | 2.5e-05 / 25 | . Morgan2 (bits) | 0.27 | 0.4 | 0.00019 / 190 | 0.4 | 0.00019 / 190 | 0.45 | 0.00012 / 115 | 0.55 | 2.5e-05 / 25 | . Morgan3 (bits) | 0.22 | 0.3 | 0.00057 / 570 | 0.35 | 0.00031 / 309 | 0.4 | 5e-05 / 50 | 0.5 | 2e-05 / 20 | . FeatMorgan0 (counts) | 0.74 | 0.65 | 0.17 / 165672 | 0.7 | 0.073 / 72975 | 0.7 | 0.073 / 72975 | 0.8 | 0.0086 / 8620 | . FeatMorgan1 (counts) | 0.51 | 0.55 | 0.021 / 21000 | 0.6 | 0.0024 / 2360 | 0.65 | 0.0012 / 1235 | 0.7 | 0.00011 / 110 | . FeatMorgan2 (counts) | 0.36 | 0.45 | 0.0038 / 3782 | 0.5 | 0.00023 / 230 | 0.55 | 0.00014 / 135 | 0.65 | 2.5e-05 / 25 | . FeatMorgan3 (counts) | 0.28 | 0.4 | 0.00022 / 220 | 0.4 | 0.00022 / 220 | 0.45 | 0.00013 / 130 | 0.55 | 3e-05 / 30 | . FeatMorgan0 (bits) | 0.74 | 0.65 | 0.17 / 165672 | 0.7 | 0.073 / 72975 | 0.7 | 0.073 / 72975 | 0.8 | 0.0086 / 8620 | . FeatMorgan1 (bits) | 0.51 | 0.55 | 0.023 / 22962 | 0.6 | 0.0027 / 2660 | 0.65 | 0.0014 / 1390 | 0.7 | 0.00012 / 120 | . FeatMorgan2 (bits) | 0.38 | 0.45 | 0.006 / 6007 | 0.5 | 0.00031 / 310 | 0.55 | 0.00018 / 175 | 0.65 | 2.5e-05 / 25 | . FeatMorgan3 (bits) | 0.30 | 0.4 | 0.00037 / 370 | 0.45 | 0.00021 / 210 | 0.45 | 0.00021 / 210 | 0.55 | 3.5e-05 / 35 | . RDKit 4 (bits) | 0.33 | 0.5 | 0.00069 / 690 | 0.55 | 0.0004 / 400 | 0.6 | 0.00011 / 110 | 0.7 | 4e-05 / 40 | . RDKit 5 (bits) | 0.29 | 0.5 | 0.00025 / 250 | 0.55 | 0.00016 / 155 | 0.6 | 6e-05 / 60 | 0.7 | 3e-05 / 30 | . RDKit 6 (bits) | 0.31 | 0.5 | 0.00021 / 210 | 0.55 | 0.00014 / 135 | 0.6 | 6e-05 / 60 | 0.7 | 3e-05 / 30 | . RDKit 7 (bits) | 0.43 | 0.55 | 0.00051 / 510 | 0.6 | 8e-05 / 80 | 0.6 | 8e-05 / 80 | 0.7 | 3e-05 / 30 | . linear RDKit 4 (bits) | 0.35 | 0.5 | 0.0015 / 1470 | 0.55 | 0.00083 / 830 | 0.6 | 0.00019 / 190 | 0.7 | 5e-05 / 50 | . linear RDKit 5 (bits) | 0.31 | 0.5 | 0.00046 / 455 | 0.55 | 0.00027 / 272 | 0.6 | 9e-05 / 90 | 0.7 | 3e-05 / 30 | . linear RDKit 6 (bits) | 0.28 | 0.5 | 0.00022 / 220 | 0.5 | 0.00022 / 220 | 0.55 | 0.00014 / 140 | 0.7 | 3e-05 / 30 | . linear RDKit 7 (bits) | 0.26 | 0.45 | 0.00053 / 535 | 0.5 | 0.00013 / 130 | 0.55 | 9e-05 / 90 | 0.65 | 3.5e-05 / 35 | . Atom Pairs (counts) | 0.27 | 0.35 | 0.0037 / 3724 | 0.35 | 0.0037 / 3724 | 0.4 | 0.00016 / 160 | 0.5 | 3e-05 / 30 | . Topological Torsions (counts) | 0.19 | 0.35 | 0.00049 / 489 | 0.4 | 0.00011 / 110 | 0.45 | 7.5e-05 / 75 | 0.55 | 2.5e-05 / 25 | . Atom Pairs (bits) | 0.36 | 0.4 | 0.01 / 10380 | 0.45 | 0.0053 / 5250 | 0.5 | 0.00012 / 120 | 0.55 | 7e-05 / 70 | . Topological Torsions (bits) | 0.22 | 0.4 | 0.00016 / 160 | 0.4 | 0.00016 / 160 | 0.45 | 0.00011 / 105 | 0.55 | 3.5e-05 / 35 | . Avalon 512 (bits) | 0.51 | 0.65 | 0.0004 / 400 | 0.65 | 0.0004 / 400 | 0.7 | 8e-05 / 80 | 0.8 | 2e-05 / 20 | . Avalon 1024 (bits) | 0.37 | 0.55 | 0.00075 / 750 | 0.6 | 0.00014 / 140 | 0.65 | 9e-05 / 90 | 0.75 | 2.5e-05 / 25 | . Avalon 512 (counts) | 0.42 | 0.55 | 0.0028 / 2785 | 0.6 | 0.00028 / 280 | 0.65 | 0.00016 / 160 | 0.75 | 2.5e-05 / 25 | . Avalon 1024 (counts) | 0.38 | 0.55 | 0.0012 / 1192 | 0.6 | 0.00017 / 170 | 0.6 | 0.00017 / 170 | 0.7 | 4e-05 / 40 | . The threshold values are rounded to the nearest 0.05. . Method . I won’t get into heavy detail here, the actual notebooks are linked below. . Similarity between random molecules . The workflow and dataset for this is described in a blog post. The very quick summary is that I generated statistics for the similarity distribution of 25K random pairs of reasonable sized (MW&lt;600) molecules exported from ChEMBL. . Groups of related compounds . This is really the central pillar of the post: how do we pick sets of compounds we can use to quantify similarity search performance? . One obvious possibility is to just take groups of molecules which are known to be active against the same targets. This is the classic similarity-based virtual screening use case and it’s one which has been done a lot in the literature. That’s an interesting (and important) use case and it’s something which I may come back to in a future post, but it requires a connection between chemical similarity and biological activity. That connection (or lack thereof) makes analysis of the threshold results more complex and introduces a significant amount of variability. . Here I want to look at a different use case: searching a database and retrieving compounds which are chemically similar to each other. For this I need to pick groups of chemically similar compounds without actually using a traditional approach to chemical similarity. The approach I used is to assume that the typical medicinal chemistry SAR paper includes a bunch of compounds which come from a small number of chemical series (typically one). These compounds are definitely related to each other and it’s not unreasonable to expect that a similarity search for one should return the others as results. . This led me back to an earlier blog post looking at identifying scaffolds from ChEMBL compounds tested in the same assay (given the structure of ChEMBL, this implies that the compounds are from the same paper). That post includes some pre-filtering of the results to try and get only SAR papers by only keeping assays (papers) where 50-100 compounds were measured. For this post I re-ran that analysis against ChEMBL28 and expanded my search criteria to include IC50 data as well as the Ki data used in the original set. The analysis produced results for 1396 groups (a group is the compounds tested in one assay); for this analysis I further filtered these down to the 1047 groups (70026 compounds in total) where the number of atoms in the scaffold is at least 50% of the average number of atoms for compounds in the group. I further filtered each group to only include compounds which have a substructure match to the fuzzy MCS which was found for the full set. The hope here is that this will limit us to only consider the compounds which are part of the chemical series being reported. This lowers the total number of compounds to 66577 across the 1047 groups. . So given these 1047 groups of chemically related compounds I was ready to start doing some searches. . Determining background retrieval rates . In order to get a sense of how many compounds would be retrieved from a database when using the related compounds, I randomly picked 100K molecules from ChEMBL28 to use as a background. I wanted a representative sample, so I didn’t apply MW filters when doing this selection. . I then queried the background compounds with each molecule in a random subset of the 66K members of the “related compounds” set, counted the number of results each returned for each fingerprint/similarity threshold combination, and did statistics based on those results. . Summarizing the data . Here’s an example of a graphical summary of the results presented in the final notebook listed below: . . The violin plots show the distribution of similarity values required to match 50% of the related compound pairs for each of the fingerprints. The dark gray boxes show the noise level for the fingerprints. The red line shows the median fraction of the 100K ChEMBL compounds retrieved when using the median value from the violin plots as a similarity threshold. . The notebooks . Here are the github links for the notebooks I used: . Similarity between random molecules (this is the previous analysis): https://github.com/greglandrum/rdkit_blog/blob/master/notebooks/Fingerprint%20Thresholds.ipynb | Finding scaffolds for ChEMBL documents with Ki values (also a previous analysis): https://github.com/greglandrum/rdkit_blog/blob/master/notebooks/Finding%20Scaffolds%20Revisited%20again.ipynb | Similarity distributions for related compounds: https://github.com/greglandrum/rdkit_blog/blob/master/notebooks/Fingerprint%20Thresholds%20Scaffolds.ipynb Note that this is a new one and I’m still working on cleaning it up and adding more text/explanation | Fraction of the database retrieved when searching (this one also has the calculation of the summary results presented here): https://github.com/greglandrum/rdkit_blog/blob/master/notebooks/Fingerprint%20Thresholds%20Database%20Fraction.ipynb Note that this is a new one and I’m still working on cleaning it up and adding more text/explanation | .",
            "url": "https://greglandrum.github.io/rdkit-blog/similarity/reference/2021/05/21/similarity-search-thresholds.html",
            "relUrl": "/similarity/reference/2021/05/21/similarity-search-thresholds.html",
            "date": " • May 21, 2021"
        }
        
    
  
    
        ,"post19": {
            "title": "Thresholds for "random" in fingerprints the RDKit supports",
            "content": "This is an updated version of a post. The original version of the notebook can be found in github. . A frequent question that comes up when considering fingerprint similarity is: &quot;What threshold should I use to determine what a neighbor is?&quot; The answer is poorly defined. Of course it depends heavily on the details of the fingerprint, but there&#39;s also a very subjective component: you want to pick a low enough threshold that you&#39;re sure you won&#39;t miss anything, but you don&#39;t want to pick up too much noise. . The goal here is to systematically come up with some guidelines that can be used for fingerprints supported within the RDKit. We will do that by looking a similarities between random &quot;drug-like&quot; (MW&lt;600) molecules picked from ChEMBL. . For the analysis, the 25K similarity values are sorted and the values at particular threshold are examined. . There&#39;s a fair amount of code and results below, so here&#39;s the summary table. To help interpret this: 22500 of the 25000 pairs (90%) have a MACCS keys similarity value less than 0.528. . FingerprintMetric70% level80% level90% level95% level99% level . MACCS | Tanimoto | 0.431 | 0.471 | 0.528 | 0.575 | 0.655 | . Morgan0 (counts) | Tanimoto | 0.429 | 0.471 | 0.525 | 0.568 | 0.651 | . Morgan1 (counts) | Tanimoto | 0.265 | 0.293 | 0.333 | 0.364 | 0.429 | . Morgan2 (counts) | Tanimoto | 0.181 | 0.201 | 0.229 | 0.252 | 0.305 | . Morgan3 (counts) | Tanimoto | 0.141 | 0.156 | 0.178 | 0.196 | 0.238 | . Morgan0 (bits) | Tanimoto | 0.435 | 0.475 | 0.529 | 0.571 | 0.656 | . Morgan1 (bits) | Tanimoto | 0.273 | 0.301 | 0.341 | 0.371 | 0.434 | . Morgan2 (bits) | Tanimoto | 0.197 | 0.217 | 0.246 | 0.269 | 0.322 | . Morgan3 (bits) | Tanimoto | 0.165 | 0.181 | 0.203 | 0.222 | 0.264 | . FeatMorgan0 (counts) | Tanimoto | 0.583 | 0.630 | 0.690 | 0.737 | 0.818 | . FeatMorgan1 (counts) | Tanimoto | 0.390 | 0.425 | 0.474 | 0.511 | 0.581 | . FeatMorgan2 (counts) | Tanimoto | 0.272 | 0.298 | 0.333 | 0.364 | 0.424 | . FeatMorgan3 (counts) | Tanimoto | 0.209 | 0.228 | 0.256 | 0.279 | 0.328 | . FeatMorgan0 (bits) | Tanimoto | 0.583 | 0.630 | 0.690 | 0.737 | 0.818 | . FeatMorgan1 (bits) | Tanimoto | 0.395 | 0.429 | 0.477 | 0.514 | 0.585 | . FeatMorgan2 (bits) | Tanimoto | 0.284 | 0.310 | 0.347 | 0.376 | 0.434 | . FeatMorgan3 (bits) | Tanimoto | 0.228 | 0.248 | 0.276 | 0.299 | 0.349 | . RDKit 4 (bits) | Tanimoto | 0.209 | 0.239 | 0.285 | 0.325 | 0.426 | . RDKit 5 (bits) | Tanimoto | 0.197 | 0.219 | 0.253 | 0.287 | 0.368 | . RDKit 6 (bits) | Tanimoto | 0.230 | 0.250 | 0.280 | 0.308 | 0.369 | . RDKit 7 (bits) | Tanimoto | 0.313 | 0.346 | 0.389 | 0.429 | 0.507 | . linear RDKit 4 (bits) | Tanimoto | 0.225 | 0.258 | 0.309 | 0.354 | 0.462 | . linear RDKit 5 (bits) | Tanimoto | 0.198 | 0.225 | 0.269 | 0.309 | 0.404 | . linear RDKit 6 (bits) | Tanimoto | 0.187 | 0.210 | 0.246 | 0.282 | 0.365 | . linear RDKit 7 (bits) | Tanimoto | 0.182 | 0.203 | 0.234 | 0.264 | 0.337 | . Atom Pairs (counts) | Tanimoto | 0.180 | 0.204 | 0.237 | 0.265 | 0.325 | . Torsions (counts) | Tanimoto | 0.107 | 0.130 | 0.165 | 0.194 | 0.266 | . Atom Pairs (bits) | Tanimoto | 0.275 | 0.301 | 0.335 | 0.363 | 0.415 | . Torsions (bits) | Tanimoto | 0.133 | 0.155 | 0.188 | 0.219 | 0.288 | . Avalon 512 (bits) | Tanimoto | 0.369 | 0.407 | 0.461 | 0.505 | 0.575 | . Avalon 1024 (bits) | Tanimoto | 0.269 | 0.297 | 0.340 | 0.375 | 0.449 | . Avalon 512 (counts) | Tanimoto | 0.300 | 0.333 | 0.379 | 0.418 | 0.491 | . Avalon 1024 (counts) | Tanimoto | 0.267 | 0.299 | 0.344 | 0.384 | 0.462 | . from rdkit import Chem from rdkit.Chem import rdMolDescriptors from rdkit.Avalon import pyAvalonTools from rdkit.Chem import Draw from rdkit.Chem.Draw import IPythonConsole from rdkit import rdBase from rdkit import DataStructs from collections import defaultdict import pickle,random,gzip print(rdBase.rdkitVersion) import time print(time.asctime()) %pylab inline . 2021.03.1 Tue May 18 06:44:23 2021 Populating the interactive namespace from numpy and matplotlib . /home/glandrum/miniconda3/envs/rdkit_blog/lib/python3.9/site-packages/IPython/core/magics/pylab.py:159: UserWarning: pylab import has clobbered these variables: [&#39;random&#39;] `%matplotlib` prevents importing * from pylab and numpy warn(&#34;pylab import has clobbered these variables: %s&#34; % clobbered + . Read in the data . We&#39;re using the set of 25K reference pairs generated in an earlier post: http://rdkit.blogspot.ch/2013/10/building-similarity-comparison-set-goal.html . As a quick reminder: these are pairs of molecules taken from ChEMBL with MW&lt;600 and a count-based MFP0 similarity of at least 0.7 to each other. . ind = [x.split() for x in gzip.open(&#39;../data/chembl16_25K.pairs.txt.gz&#39;)] ms1 = [] ms2 = [] for i,row in enumerate(ind): m1 = Chem.MolFromSmiles(row[1]) ms1.append((row[0],m1)) m2 = Chem.MolFromSmiles(row[3]) ms2.append((row[2],m2)) . Those pairs are related to each other, but we want random pairs, so shuffle the second list: . random.seed(23) random.shuffle(ms2) . try: import ipyparallel as ipp rc = ipp.Client() dview = rc[:] dview.execute(&#39;from rdkit import Chem&#39;) dview.execute(&#39;from rdkit import Descriptors&#39;) dview.execute(&#39;from rdkit.Chem import rdMolDescriptors&#39;) dview.execute(&#39;from rdkit.Avalon import pyAvalonTools&#39;) except: print(&quot;could not use ipyparallel&quot;) dview = None def compareFPs(ms1,ms2,fpfn,fpName): if dview is not None: fps = dview.map_sync(lambda x:fpfn(x[1]),ms1) fp2s = dview.map_sync(lambda x:fpfn(x[1]),ms2) else: fps = [fpfn(x[1]) for x in ms1] fp2s = [fpfn(x[1]) for x in ms2] sims = [DataStructs.TanimotoSimilarity(x,y) for x,y in zip(fps,fp2s)] sl = sorted(sims) np = len(sl) with open(&#39;fp_results.txt&#39;,&#39;a+&#39;) as outf: outf.write(f&#39;&lt;tr&gt;&lt;td&gt;{fpName}&lt;/td&gt;&lt;td&gt;Tanimoto&lt;/td&gt; n&#39;) for bin in (.7,.8,.9,.95,.99): simv = sl[int(bin*np)] print( bin,simv) outf.write(f&#39; &lt;td&gt;{simv:.3f}&lt;/td&gt; n&#39;) outf.write(&#39;&lt;/tr&gt;&#39;) hist(sims,bins=20) xlabel(fpName) . MACCS . compareFPs(ms1,ms2,lambda x:rdMolDescriptors.GetMACCSKeysFingerprint(x),&quot;MACCS&quot;) . 0.7 0.4305555555555556 0.8 0.47058823529411764 0.9 0.5283018867924528 0.95 0.575 0.99 0.6551724137931034 . Morgan FPs . count based . compareFPs(ms1,ms2,lambda x:rdMolDescriptors.GetMorganFingerprint(x,0),&quot;Morgan0 (counts)&quot;) . 0.7 0.42857142857142855 0.8 0.47058823529411764 0.9 0.525 0.95 0.5675675675675675 0.99 0.6511627906976745 . compareFPs(ms1,ms2,lambda x:rdMolDescriptors.GetMorganFingerprint(x,1),&quot;Morgan1 (counts)&quot;) . 0.7 0.2653061224489796 0.8 0.2926829268292683 0.9 0.3333333333333333 0.95 0.36363636363636365 0.99 0.42857142857142855 . compareFPs(ms1,ms2,lambda x:rdMolDescriptors.GetMorganFingerprint(x,2),&quot;Morgan2 (counts)&quot;) . 0.7 0.18110236220472442 0.8 0.20125786163522014 0.9 0.22916666666666666 0.95 0.2523364485981308 0.99 0.304635761589404 . compareFPs(ms1,ms2,lambda x:rdMolDescriptors.GetMorganFingerprint(x,3),&quot;Morgan3 (counts)&quot;) . 0.7 0.140625 0.8 0.1557377049180328 0.9 0.17751479289940827 0.95 0.19607843137254902 0.99 0.23841059602649006 . bit-vector based . compareFPs(ms1,ms2,lambda x:rdMolDescriptors.GetHashedMorganFingerprint(x,0,1024),&quot;Morgan0 (bits)&quot;) . 0.7 0.43478260869565216 0.8 0.475 0.9 0.5294117647058824 0.95 0.5714285714285714 0.99 0.65625 . compareFPs(ms1,ms2,lambda x:rdMolDescriptors.GetHashedMorganFingerprint(x,1,1024),&quot;Morgan1 (bits)&quot;) . 0.7 0.2727272727272727 0.8 0.30120481927710846 0.9 0.34065934065934067 0.95 0.37142857142857144 0.99 0.4342105263157895 . compareFPs(ms1,ms2,lambda x:rdMolDescriptors.GetHashedMorganFingerprint(x,2,1024),&quot;Morgan2 (bits)&quot;) . 0.7 0.19708029197080293 0.8 0.2169811320754717 0.9 0.24603174603174602 0.95 0.2689655172413793 0.99 0.3217391304347826 . compareFPs(ms1,ms2,lambda x:rdMolDescriptors.GetHashedMorganFingerprint(x,3,1024),&quot;Morgan3 (bits)&quot;) . 0.7 0.16477272727272727 0.8 0.18072289156626506 0.9 0.20261437908496732 0.95 0.2222222222222222 0.99 0.26356589147286824 . FeatMorgan . count based . compareFPs(ms1,ms2,lambda x:rdMolDescriptors.GetMorganFingerprint(x,0,useFeatures=True),&quot;FeatMorgan0 (counts)&quot;) . 0.7 0.5833333333333334 0.8 0.6296296296296297 0.9 0.6896551724137931 0.95 0.7368421052631579 0.99 0.8181818181818182 . compareFPs(ms1,ms2,lambda x:rdMolDescriptors.GetMorganFingerprint(x,1,useFeatures=True),&quot;FeatMorgan1 (counts)&quot;) . 0.7 0.3902439024390244 0.8 0.42528735632183906 0.9 0.47368421052631576 0.95 0.5106382978723404 0.99 0.5813953488372093 . compareFPs(ms1,ms2,lambda x:rdMolDescriptors.GetMorganFingerprint(x,2,useFeatures=True),&quot;FeatMorgan2 (counts)&quot;) . 0.7 0.272 0.8 0.29770992366412213 0.9 0.3333333333333333 0.95 0.36363636363636365 0.99 0.424 . compareFPs(ms1,ms2,lambda x:rdMolDescriptors.GetMorganFingerprint(x,3,useFeatures=True),&quot;FeatMorgan3 (counts)&quot;) . 0.7 0.2087378640776699 0.8 0.22818791946308725 0.9 0.2558139534883721 0.95 0.2785714285714286 0.99 0.3275862068965517 . bit vectors . compareFPs(ms1,ms2,lambda x:rdMolDescriptors.GetHashedMorganFingerprint(x,0,1024,useFeatures=True),&quot;FeatMorgan0 (bits)&quot;) . 0.7 0.5833333333333334 0.8 0.6296296296296297 0.9 0.6896551724137931 0.95 0.7368421052631579 0.99 0.8181818181818182 . compareFPs(ms1,ms2,lambda x:rdMolDescriptors.GetHashedMorganFingerprint(x,1,1024,useFeatures=True),&quot;FeatMorgan1 (bits)&quot;) . 0.7 0.39473684210526316 0.8 0.42857142857142855 0.9 0.4772727272727273 0.95 0.5142857142857142 0.99 0.5849056603773585 . compareFPs(ms1,ms2,lambda x:rdMolDescriptors.GetHashedMorganFingerprint(x,2,1024,useFeatures=True),&quot;FeatMorgan2 (bits)&quot;) . 0.7 0.28368794326241137 0.8 0.30973451327433627 0.9 0.3469387755102041 0.95 0.37606837606837606 0.99 0.43434343434343436 . compareFPs(ms1,ms2,lambda x:rdMolDescriptors.GetHashedMorganFingerprint(x,3,1024,useFeatures=True),&quot;FeatMorgan3 (bits)&quot;) . 0.7 0.22807017543859648 0.8 0.24770642201834864 0.9 0.27564102564102566 0.95 0.29901960784313725 0.99 0.3488372093023256 . RDKit . Branched (default) . compareFPs(ms1,ms2,lambda x:Chem.RDKFingerprint(x,maxPath=4),&quot;RDKit 4 (bits)&quot;) . 0.7 0.2094017094017094 0.8 0.23863636363636365 0.9 0.2849462365591398 0.95 0.3254237288135593 0.99 0.4258373205741627 . compareFPs(ms1,ms2,lambda x:Chem.RDKFingerprint(x,maxPath=5),&quot;RDKit 5 (bits)&quot;) . 0.7 0.19672131147540983 0.8 0.21875 0.9 0.2534562211981567 0.95 0.28735632183908044 0.99 0.3682170542635659 . compareFPs(ms1,ms2,lambda x:Chem.RDKFingerprint(x,maxPath=6),&quot;RDKit 6 (bits)&quot;) . 0.7 0.22965641952983726 0.8 0.2502120441051739 0.9 0.28023598820059 0.95 0.30818767249310025 0.99 0.3686382393397524 . compareFPs(ms1,ms2,lambda x:Chem.RDKFingerprint(x,maxPath=7),&quot;RDKit 7 (bits)&quot;) . 0.7 0.3130372492836676 0.8 0.34558303886925795 0.9 0.38909541511771994 0.95 0.4286600496277916 0.99 0.5068903535050928 . linear . compareFPs(ms1,ms2,lambda x:Chem.RDKFingerprint(x,maxPath=4,branchedPaths=False),&quot;linear RDKit 4 (bits)&quot;) . 0.7 0.22456140350877193 0.8 0.25773195876288657 0.9 0.30864197530864196 0.95 0.35403726708074534 0.99 0.46153846153846156 . compareFPs(ms1,ms2,lambda x:Chem.RDKFingerprint(x,maxPath=5,branchedPaths=False),&quot;linear RDKit 5 (bits)&quot;) . 0.7 0.19756838905775076 0.8 0.22549019607843138 0.9 0.2687224669603524 0.95 0.3090909090909091 0.99 0.40425531914893614 . compareFPs(ms1,ms2,lambda x:Chem.RDKFingerprint(x,maxPath=6,branchedPaths=False),&quot;linear RDKit 6 (bits)&quot;) . 0.7 0.18657937806873978 0.8 0.21005917159763313 0.9 0.24612403100775193 0.95 0.2820069204152249 0.99 0.36476426799007444 . compareFPs(ms1,ms2,lambda x:Chem.RDKFingerprint(x,maxPath=7,branchedPaths=False),&quot;linear RDKit 7 (bits)&quot;) . 0.7 0.18204488778054864 0.8 0.20286085825747724 0.9 0.23367198838896952 0.95 0.2640625 0.99 0.33689024390243905 . Atom pairs and torsions . count-based . compareFPs(ms1,ms2,lambda x:rdMolDescriptors.GetAtomPairFingerprint(x),&quot;Atom Pairs (counts)&quot;) . 0.7 0.17993630573248406 0.8 0.20386266094420602 0.9 0.23671497584541062 0.95 0.26545454545454544 0.99 0.32547169811320753 . compareFPs(ms1,ms2,lambda x:rdMolDescriptors.GetTopologicalTorsionFingerprint(x),&quot;Torsions (counts)&quot;) . 0.7 0.10714285714285714 0.8 0.13 0.9 0.16470588235294117 0.95 0.19387755102040816 0.99 0.26582278481012656 . bit vectors . compareFPs(ms1,ms2,lambda x:rdMolDescriptors.GetHashedAtomPairFingerprintAsBitVect(x),&quot;Atom Pairs (bits)&quot;) . 0.7 0.27488151658767773 0.8 0.3008298755186722 0.9 0.3353658536585366 0.95 0.36342042755344417 0.99 0.4146341463414634 . compareFPs(ms1,ms2,lambda x:rdMolDescriptors.GetHashedTopologicalTorsionFingerprintAsBitVect(x),&quot;Torsions (bits)&quot;) . 0.7 0.1326530612244898 0.8 0.1553398058252427 0.9 0.18840579710144928 0.95 0.2191780821917808 0.99 0.2876712328767123 . Avalon . compareFPs(ms1,ms2,lambda x:pyAvalonTools.GetAvalonFP(x,512),&quot;Avalon 512 (bits)&quot;) . 0.7 0.3693379790940767 0.8 0.4074074074074074 0.9 0.46130952380952384 0.95 0.5054347826086957 0.99 0.5749318801089919 . compareFPs(ms1,ms2,lambda x:pyAvalonTools.GetAvalonFP(x,1024),&quot;Avalon 1024 (bits)&quot;) . 0.7 0.26932668329177056 0.8 0.2972972972972973 0.9 0.3402061855670103 0.95 0.3747016706443914 0.99 0.4490909090909091 . Avalon Counts . compareFPs(ms1,ms2,lambda x:pyAvalonTools.GetAvalonCountFP(x,512),&quot;Avalon 512 (counts)&quot;) . 0.7 0.30028063610851263 0.8 0.332624867162593 0.9 0.3787951807228916 0.95 0.4175461741424802 0.99 0.491005291005291 . compareFPs(ms1,ms2,lambda x:pyAvalonTools.GetAvalonCountFP(x,1024),&quot;Avalon 1024 (counts)&quot;) . 0.7 0.26651162790697674 0.8 0.2988505747126437 0.9 0.34438775510204084 0.95 0.3844486589000271 0.99 0.4624173180998196 .",
            "url": "https://greglandrum.github.io/rdkit-blog/fingerprints/similarity/reference/2021/05/18/fingerprint-thresholds1.html",
            "relUrl": "/fingerprints/similarity/reference/2021/05/18/fingerprint-thresholds1.html",
            "date": " • May 18, 2021"
        }
        
    
  
    
        ,"post20": {
            "title": "Intro to the molecule enumerator",
            "content": "The V3000 mol file format allows a number of interesting and useful advanced query features. Here I&#39;ll look at two of them: position variation bonds (a.k.a. variable attachment points) and link nodes. . This blog post uses features from the 2021.03.1 RDKit release; some of this will not work with older releases. . from rdkit import Chem from rdkit.Chem.Draw import rdDepictor from rdkit.Chem import Draw from rdkit.Chem.Draw import IPythonConsole from rdkit.Chem import rdMolEnumerator import rdkit print(rdkit.__version__) . 2021.03.1 . Position variation bonds . Here&#39;s a molecule with a position variation bond: . pv1 = Chem.MolFromMolBlock(&#39;&#39;&#39; Mrv2007 06232015292D 0 0 0 0 0 999 V3000 M V30 BEGIN CTAB M V30 COUNTS 9 8 0 0 0 M V30 BEGIN ATOM M V30 1 C -1.7083 2.415 0 0 M V30 2 C -3.042 1.645 0 0 M V30 3 C -3.042 0.105 0 0 M V30 4 N -1.7083 -0.665 0 0 M V30 5 C -0.3747 0.105 0 0 M V30 6 C -0.3747 1.645 0 0 M V30 7 * -0.8192 1.3883 0 0 M V30 8 O -0.8192 3.6983 0 0 M V30 9 C 0.5145 4.4683 0 0 M V30 END ATOM M V30 BEGIN BOND M V30 1 1 1 2 M V30 2 2 2 3 M V30 3 1 3 4 M V30 4 2 4 5 M V30 5 1 5 6 M V30 6 2 1 6 M V30 7 1 7 8 ENDPTS=(3 1 5 6) ATTACH=ANY M V30 8 1 8 9 M V30 END BOND M V30 END CTAB M END&#39;&#39;&#39;) pv1 . The query is describing a molecule consisting of a pyriding ring with an methoxy substituted either ortho, meta, or para to the N atom. . The RDKit includes functionality in the rdkit.Chem.rdMolEnumerator module which allows you enumerate all of the molecules which are described by this query. . The function rdMolEnumerator.Enumerate() is straightforward to use: given a molecule with supported query features it returns a MolBundle object which includes each possible expansion of the query: . pv1_bundle = rdMolEnumerator.Enumerate(pv1) pv1_bundle . &lt;rdkit.Chem.rdchem.MolBundle at 0x7fc138399b20&gt; . We can render the molecules in the bundle using Draw.MolsToGridImage(): . Draw.MolsToGridImage(pv1_bundle) . These are pretty ugly since the enumeration hasn&#39;t generated new coordinates for the atom which correspond to the new connectivity. . I&#39;ll use this convenience function to find the common core shared by the molecules in a bundle and generate 2D coordinates for all the molecules with the core oriented consistently: . from rdkit.Chem import rdFMCS def align_bundle_coords(bndl): ps = rdFMCS.MCSParameters() for m in bndl: Chem.SanitizeMol(m) mcs = rdFMCS.FindMCS(bndl,completeRingsOnly=True) q = Chem.MolFromSmarts(mcs.smartsString) rdDepictor.Compute2DCoords(q) for m in bndl: rdDepictor.GenerateDepictionMatching2DStructure(m,q) . Now let&#39;s apply that to our bundle: . pv1_bundle = rdMolEnumerator.Enumerate(pv1) align_bundle_coords(pv1_bundle) Draw.MolsToGridImage(pv1_bundle) . Of course a molecule can have more than one position variation bond: . pv2 = Chem.MolFromMolBlock(&#39;&#39;&#39; Mrv2007 06242006032D 0 0 0 0 0 999 V3000 M V30 BEGIN CTAB M V30 COUNTS 10 8 0 0 0 M V30 BEGIN ATOM M V30 1 C -1.7083 2.415 0 0 M V30 2 C -3.042 1.645 0 0 M V30 3 C -3.042 0.105 0 0 M V30 4 N -1.7083 -0.665 0 0 M V30 5 C -0.3747 0.105 0 0 M V30 6 C -0.3747 1.645 0 0 M V30 7 * -3.042 0.875 0 0 M V30 8 F -5.0434 0.875 0 0 M V30 9 * -1.0415 2.03 0 0 M V30 10 Cl -1.0415 4.34 0 0 M V30 END ATOM M V30 BEGIN BOND M V30 1 1 1 2 M V30 2 2 2 3 M V30 3 1 3 4 M V30 4 2 4 5 M V30 5 1 5 6 M V30 6 2 1 6 M V30 7 1 7 8 ENDPTS=(2 2 3) ATTACH=ANY M V30 8 1 9 10 ENDPTS=(2 1 6) ATTACH=ANY M V30 END BOND M V30 END CTAB M END &#39;&#39;&#39;) pv2 . This is also supported by the enumerator: . pv2_bundle = rdMolEnumerator.Enumerate(pv2) align_bundle_coords(pv2_bundle) Draw.MolsToGridImage(pv2_bundle) . Link nodes . Another useful query feature, link nodes, allow you to describe rings of various sizes or chains with different lengths: . link1 = Chem.MolFromMolBlock(&#39;&#39;&#39;one linknode Mrv2007 06222005102D 0 0 0 0 0 999 V3000 M V30 BEGIN CTAB M V30 COUNTS 6 6 0 0 0 M V30 BEGIN ATOM M V30 1 C 8.25 12.1847 0 0 M V30 2 C 6.9164 12.9547 0 0 M V30 3 C 6.9164 14.4947 0 0 M V30 4 C 9.5836 14.4947 0 0 M V30 5 C 9.5836 12.9547 0 0 M V30 6 O 8.25 10.6447 0 0 M V30 END ATOM M V30 BEGIN BOND M V30 1 1 1 2 M V30 2 1 2 3 M V30 3 1 4 5 M V30 4 1 1 5 M V30 5 1 3 4 M V30 6 1 1 6 M V30 END BOND M V30 LINKNODE 1 4 2 1 2 1 5 M V30 END CTAB M END&#39;&#39;&#39;) link1 . And we can enumerate and display these in the same way. Here there&#39;s not much sense in doing the MCS analysis to get the shared coordinates, so I just generate coordinates for the molecules directly: . link1_bundle = rdMolEnumerator.Enumerate(link1) for m in link1_bundle: Chem.SanitizeMol(m) rdDepictor.Compute2DCoords(m) Draw.MolsToGridImage(link1_bundle) . Combining them . We can also combine link nodes and position variation bonds in the same molecule: . combined = Chem.MolFromMolBlock(&#39;&#39;&#39; Mrv2108 05132110052D 0 0 0 0 0 999 V3000 M V30 BEGIN CTAB M V30 COUNTS 19 20 0 0 0 M V30 BEGIN ATOM M V30 1 N -2.2078 4.3165 0 0 M V30 2 C -2.9544 2.9695 0 0 M V30 3 C -2.1612 1.6495 0 0 M V30 4 C -0.6214 1.6763 0 0 M V30 5 C 0.1252 3.0233 0 0 M V30 6 C -0.668 4.3433 0 0 M V30 7 C 1.6649 3.0501 0 0 M V30 8 C -4.4941 2.9427 0 0 M V30 9 C 2.4581 1.7301 0 0 M V30 10 C 2.985 3.8433 0 0 M V30 11 C 3.7781 2.5233 0 0 M V30 12 C -6.3747 4.5774 0 0 M V30 13 C -6.9764 3.1598 0 0 M V30 14 C -5.8142 2.1495 0 0 M V30 15 C -4.8405 4.4431 0 0 M V30 16 F -7.1678 5.8974 0 0 M V30 17 O 3.3575 5.3376 0 0 M V30 18 * -1.1502 2.5564 0 0 M V30 19 C -1.1502 0.2464 0 0 M V30 END ATOM M V30 BEGIN BOND M V30 1 1 1 2 M V30 2 2 2 3 M V30 3 1 3 4 M V30 4 2 4 5 M V30 5 1 5 6 M V30 6 2 1 6 M V30 7 1 5 7 M V30 8 1 2 8 M V30 9 1 9 11 M V30 10 1 10 11 M V30 11 1 7 9 M V30 12 1 7 10 M V30 13 1 12 13 M V30 14 1 13 14 M V30 15 1 12 15 M V30 16 1 14 8 M V30 17 1 8 15 M V30 18 1 12 16 M V30 19 1 10 17 M V30 20 1 18 19 ENDPTS=(3 6 3 4) ATTACH=ANY M V30 END BOND M V30 LINKNODE 1 2 2 10 7 10 11 M V30 LINKNODE 1 2 2 12 13 12 15 M V30 END CTAB M END &#39;&#39;&#39;) combined . Enumerating that produces 12 molecules: . combined_bundle = rdMolEnumerator.Enumerate(combined) align_bundle_coords(combined_bundle) Draw.MolsToGridImage(combined_bundle,subImgSize=(300,250)) . Using MolBundles for substructure search . MolBundles can also be used as substructure search queries. . Here&#39;s another query molecule: . qry= Chem.MolFromMolBlock(&#39;&#39;&#39; Mrv2108 05132113572D 0 0 0 0 0 999 V3000 M V30 BEGIN CTAB M V30 COUNTS 13 13 0 0 0 M V30 BEGIN ATOM M V30 1 C 1.2124 -2.4845 0 0 M V30 2 N 2.5461 -3.2545 0 0 M V30 3 C 2.5461 -4.7945 0 0 M V30 4 C 1.2124 -5.5645 0 0 M V30 5 C 1.2124 -7.1045 0 0 M V30 6 C -0.0335 -8.0097 0 0 M V30 7 O 0.4424 -9.4744 0 0 M V30 8 C 1.9824 -9.4744 0 0 M V30 9 C 2.4583 -8.0097 0 0 M V30 10 C -0.1212 -4.7945 0 0 M V30 11 C -0.1212 -3.2545 0 0 M V30 12 * 0.5456 -2.8695 0 0 M V30 13 C -0.6094 -0.869 0 0 M V30 END ATOM M V30 BEGIN BOND M V30 1 2 1 2 M V30 2 1 2 3 M V30 3 2 3 4 M V30 4 1 4 5 M V30 5 1 6 7 M V30 6 1 7 8 M V30 7 1 8 9 M V30 8 1 5 9 M V30 9 1 4 10 M V30 10 2 10 11 M V30 11 1 1 11 M V30 12 1 12 13 ENDPTS=(2 11 1) ATTACH=ANY M V30 13 1 5 6 M V30 END BOND M V30 LINKNODE 1 2 2 6 5 6 7 M V30 END CTAB M END &#39;&#39;&#39;) qry . And a set of molecules to search through which I pulled from ChEMBL . smis = &#39;&#39;&#39;Cc1nc(C(C)(C)NC(=O)c2ccc(C3CCOCC3)c(OCC3CC3)n2)no1 CC(C)(CO)NC(=O)c1ccc(C2CCOC2)c(OCC2CC2)n1 CC(C)(NC(=O)c1ccc(C2CCOCC2)c(OCC2CC2)n1)c1nccs1 Cc1c(-c2cncc(C3(O)CCOCC3)c2)cnc2c1CCCN2C(N)=O CC(C)Oc1cc(NC(=O)N2CCCc3cc(C4CCOC4)c(C=O)nc32)ncc1C#N NC(=O)N1CCCc2cc(-c3cncc(C4(O)CCOC4)c3)cnc21 CCC(CC)(NC(=O)c1ccc(C2CCOCC2)c(OCC2CC2)n1)C(=O)NC CC(C)(NC(=O)c1ccc(C2CCOCC2)c(OCC2CC2)n1)c1ncco1 N#Cc1cc(-c2ccoc2)c2ccc(OCc3cncc(C4(O)CCOCC4)c3)cc2c1 Nc1cc(-c2cc(C3CCOCC3)cnc2N)ccc1C(=O)N[C@H](CO)c1ccccc1 Nc1ncc(C2CCOCC2)cc1-c1ccc(C(=O)NCc2cccnc2)cc1 Cc1nc(C(C)(C)NC(=O)c2ccc(C3CCOC3)c(OCC3CC3)n2)no1 CC(C)C[C@H](NC(=O)c1ccc(C2CCOC2)c(OCC2CC2)n1)C(N)=O Nc1ncc(C2CCOCC2)cc1-c1ccc(C(=O)N[C@H](CO)c2ccccc2)cc1Cl NC(=O)[C@H](CC1CC1)NC(=O)c1ccc(C2CCOC2)c(OCC2CC2)n1 &#39;&#39;&#39; mols = [Chem.MolFromSmiles(x.strip()) for x in smis.split(&#39; n&#39;) if x.strip()] . The query itself doesn&#39;t match most of these molecules: . matches = [x for x in mols if x.HasSubstructMatch(qry)] len(mols),len(matches) . (15, 6) . But if we enumerate it into a MolBundle and use that as the substructure query then all the molecules match: . qry_bundle = rdMolEnumerator.Enumerate(qry) matches = [x for x in mols if x.HasSubstructMatch(qry_bundle)] len(mols),len(matches) . (15, 15) . Let&#39;s look at a few of those matches . matches = [] matched_ats = [] for x in mols: match = x.GetSubstructMatch(qry_bundle) if match: matches.append(x) matched_ats.append(match) Draw.MolsToGridImage(matches[:6],highlightAtomLists=matched_ats,subImgSize=(300,250)) . We&#39;re working on expanding support for the MolBundle in other RDKit code. For example, it would be really nice to be able to use them directly as queries for the SubstructLibrary . Final bit: input from CXSMILES . It&#39;s also possible to read both variable attachment points and link nodes from CXSMILES: . m = Chem.MolFromSmiles(&#39;CO*.C1=CC=NC=C1 |c:2,4,6,m:2:3.5.4|&#39;) m . As that example shows, the coordinate generation code is currently not great at setting the atom positions for these. That&#39;s a ToDo for a future release. . m = Chem.MolFromSmiles(&#39;OC1CCCC1 |LN:1:1.4.2.5|&#39;) m . The RDKit currently does not write either link nodes or variable attachment points to CXSMILES, that&#39;s another ToDo for a future release. .",
            "url": "https://greglandrum.github.io/rdkit-blog/tutorial/substructure/2021/05/13/intro-to-the-molecule-enumerator.html",
            "relUrl": "/tutorial/substructure/2021/05/13/intro-to-the-molecule-enumerator.html",
            "date": " • May 13, 2021"
        }
        
    
  
    
        ,"post21": {
            "title": "A new way to use the RDKit from other languages",
            "content": "TL;DR . We’ve added a new API which makes it easy to use the RDKit from programming languages other than C++, Python, Java or C#. . Intro . The majority of the RDKit is written in C++, but we also make wrappers allowing you to use it from other programming languages. The main one of these, and the most complete, is for Python and is written by hand (using Boost::Python). The Java and C# wrappers are generated more or less automatically using SWIG. . Back in 2019 we decided to do a JavaScript (JS) wrapper which follows a slightly different approach: instead of wrapping the whole toolkit the new JS wrappers provide access to a useful subset of RDKit functionality provided as functions. We called this MinimalLib and there’s more information in an earlier blog post. . We’ve now extended MinimalLib and made it useable from any programming language which supports calling into external libraries written in C (often called using a “C Foreign Function Interface”, or CFFI). Since most common programming languages support CFFI, I think this will help bring chemistry to a bunch of other languages. . How it works . This is easiest explained with an example. Since each programming language implements CFFI slightly differently, and I’m not even close to being good at some of the more intersting ones like go, Rust, or Julia, I’ll demonstrate using C itself and sample code adapted from cffi_test.c, one of the files used to test the new interface. . The general pattern when working with rdkit-cffi is to parse a molecule input format to get back a serialized (“pickled”) form of that molecule and then to pass that pickled molecule to other functions which do the chemistry operations you’re interested in. . Parsing molecule formats and operating on molecules . The “hello world” equivalent in cheminformatics is generating canonical SMILES. Here’s a full C program showing how you do that with rdkit-cffi, I will explain the rdkit-cffi functions and how they are used in more detail below: . #include &lt;stdio.h&gt; #include &lt;string.h&gt; #include &lt;stdlib.h&gt; #include &quot;cffiwrapper.h&quot; void canon_smiles(){ char *pkl; size_t pkl_size; pkl = get_mol(&quot;c1cc(O)ccc1&quot;,&amp;pkl_size,&quot;&quot;); char *smiles=get_smiles(pkl,pkl_size,NULL); printf(&quot;Canonical SMILES: %s n&quot;,smiles); free(smiles); free(pkl); } int main(){ enable_logging(); printf(&quot;hello %s n&quot;,version()); canon_smiles(); return 0; } . I compiled this on my linux machine as follows: . % cc -o demo.exe -I $RDBASE/Code demo.c $RDBASE/lib/librdkitcffi.so . Running it produces: . % ./demo.exe hello 2021.09.1pre Canonical SMILES: Oc1ccccc1 . Let’s look at the rdkit-cffi parts of this, starting with the main() function. . We start by enabling the RDKit’s logging system: . enable_logging(); . If you skip this, you won’t see any of the usual RDKit errors or warnings. . Next we use the version() function to get the version of the RDKit which is being used and then print that out. . With that basic initialization out of the way we call the function canon_smiles(), which is where the real work happens. Here we start by parsing a SMILES using the get_mol() function: . pkl = get_mol(&quot;c1cc(O)ccc1&quot;,&amp;pkl_size,&quot;&quot;); . get_mol() returns a binary string with the pickled representation of the molecule and uses the pkl_size argument (an integer) to return the length of that string (this is an unfortunately necessary implementation detail). The final argument to get_mol(), the empty string, can be used to pass in an JSON string containing additional arguments controlling the parsing (we could have also passed this argument as NULL). get_mol() currently supports constructing molecules from SMILES (and CXSMILES), Mol/SDF, and the RDKit’s JSON format; it recognized automatically which parser should be used. We will be expanding the list of supported formats in the future. . After we have the molecule processed we can get the canonical SMILES for it by calling the get_smiles() function: . char *smiles=get_smiles(pkl,pkl_size,NULL); . get_smiles() follows the general pattern for rdkit-cffi functions which operate on molecules: the first two arguments are the pickled molecule and the length of the pickle string, the third argument is a JSON string with additional options to be used when generating the SMILES; in this case we want the defaults, so we pass a NULL pointer (we could also have used the empty string &quot;&quot;). . Finally, and not to be overlooked when working in C, we need to free the memory which was allocated to hold the molecule pickle and the SMILES: . free(smiles); free(pkl); . The functions which are available are declared in cffiwrapper.h. . Modifying molecules . Some rdkit-cffi functions modify the molecule. In this case the general pattern is the modify the molecule in place, i.e. to modify the current molecule instead of returning a new one. . Here’s a simple function which parses a SMILES, add Hs to the molecule, generates a 3D conformer using a fixed random seed, and then prints out the molblock for the modified molecule: . void generate_conformer(){ char *pkl; size_t pkl_size; pkl = get_mol(&quot;c1cc(O)ccc1&quot;,&amp;pkl_size,NULL); add_hs(&amp;pkl,&amp;pkl_size); set_3d_coords(&amp;pkl,&amp;pkl_size,&quot;{ &quot;randomSeed &quot;:42}&quot;); char *molb = get_molblock(pkl,pkl_size,NULL); printf(&quot;%s n&quot;,molb); free(molb); free(pkl); } . We’ve already seen get_mol(). As mentioned above add_hs() modifies the molecule in place, so you need to pass pointers to the pickle string and pickle size so that they can be modifed. set_3d_coords() also modifies the molecule in place to add the conformer. This is also the first time we use the JSON string that most of the functions take as their last argument: here we set the random number seed used in the conformer generation so that we get reproducible results. Finally get_molblock(), like get_smiles(), returns a string with the MOL file data for the molecule. This can be saved to a file and opened in most chemistry software. . An aside about an interesting way rdkit-cffi could be used . The RDKit has a lot of functionality, and covering all of that in the interface exposed by rdkit-cffi is not a goal. We want to provide a useful (hopefully very useful) subset of the functionality for use in other languages. If there’s something you think is missing, please ask about it. . I think you there’s another interesting use case for this though. Suppose you have an idea for some interesting new piece of cheminformatics functionality, and you’d like to work in a language like Rust or Julia but you don’t want to have to deal with all the basic cheminformatics plumbing yourself. rdkit-cffi can really help here. The key functionality for this mode is the get_json() function, which returns an easily parsed JSON representation of the molecule using the RDKit’s extension to the commonchem JSON format. . void json_output(){ char *pkl; size_t pkl_size; pkl = get_mol(&quot;c1cc(O)ccc1&quot;,&amp;pkl_size,&quot;&quot;); char *json=get_json(pkl,pkl_size,NULL); printf(&quot;%s n&quot;,json); free(json); free(pkl); } . The output here (after running through a JSON pretty printer) is: . { &quot;commonchem&quot;: { &quot;version&quot;: 10 }, &quot;defaults&quot;: { &quot;atom&quot;: { &quot;z&quot;: 6, &quot;impHs&quot;: 0, &quot;chg&quot;: 0, &quot;nRad&quot;: 0, &quot;isotope&quot;: 0, &quot;stereo&quot;: &quot;unspecified&quot; }, &quot;bond&quot;: { &quot;bo&quot;: 1, &quot;stereo&quot;: &quot;unspecified&quot; } }, &quot;molecules&quot;: [ { &quot;atoms&quot;: [ { &quot;impHs&quot;: 1 }, { &quot;impHs&quot;: 1 }, {}, { &quot;z&quot;: 8, &quot;impHs&quot;: 1 }, { &quot;impHs&quot;: 1 }, { &quot;impHs&quot;: 1 }, { &quot;impHs&quot;: 1 } ], &quot;bonds&quot;: [ { &quot;bo&quot;: 2, &quot;atoms&quot;: [0,1] }, { &quot;atoms&quot;: [1,2] }, { &quot;atoms&quot;: [2,3] }, { &quot;bo&quot;: 2, &quot;atoms&quot;: [2,4] }, { &quot;atoms&quot;: [4,5] }, { &quot;bo&quot;: 2, &quot;atoms&quot;: [5,6] }, { &quot;atoms&quot;: [6,0] } ], &quot;extensions&quot;: [ { &quot;name&quot;: &quot;rdkitRepresentation&quot;, &quot;formatVersion&quot;: 1, &quot;toolkitVersion&quot;: &quot;2021.09.1pre&quot;, &quot;aromaticAtoms&quot;: [0,1,2,4,5,6], &quot;aromaticBonds&quot;: [0,1,3,4,5,6], &quot;atomRings&quot;: [[0,6,5,4,2,1] ] } ] } ] } . It should be easy to parse this with the JSON parser in any modern programming language, and the format provides all the information you need to reconstruct a molecule in whatever representation you’re using in your language of choice. But you can do it without having to worry about dealing with chemistry perception, ring finding, etc. . Status . The new CFFI interface is currently available on the RDKit master branch. It hasn’t yet been officially released, but I’m publicizing it now because I’d like to try and get people using it and providing feedback and suggestions so that we can get it as polished and useful as possible before the 2021.09 release later this year. . I’ve setup a separate repo in github which has a link to Azure Pipelines to automatically do builds of the CFFI wrappers and make the shared libraries available. The README there also includes links you can use to download the most recent builds for Linux and the Mac (I still need to get the automated Windows builds working). I haven’t figured out how to actually make this easy (unless you have the azure CLI installed, in which case there’s a single command you can execute), so there are a number of clicks needed: . Start by picking the build you want from the README: . Now click the build identifier (this page also has the azure CLI command to get the build directly): . Pick the appropriate job: . Click the “1 artifact” link: . now you can actually download the artifact: . sigh I will try to find a way to make this simpler… . Wrapping up . I will likely do another post on rdkit-cffi before the next release, most likely one looking at things like performance (since that’s something I tend to do). In the meantime please let me know if you start using it! .",
            "url": "https://greglandrum.github.io/rdkit-blog/technical/2021/05/01/rdkit-cffi-part1.html",
            "relUrl": "/technical/2021/05/01/rdkit-cffi-part1.html",
            "date": " • May 1, 2021"
        }
        
    
  
    
        ,"post22": {
            "title": "ETKDG and distance constraints",
            "content": "The RDKit&#39;s conformer generator allows you to provide distance &quot;constraints&quot; to bias the conformers which it produces. Last week I wondered how those constraints interact with the terms which the ETKDG algorithm adds to the &quot;distance geometry force field&quot;. . This post uses a simple example to explore that interaction . See another recent blog post for an overview of how the conformer generator works. . from rdkit import Chem from rdkit.Chem import rdDistGeom from rdkit.Chem.Draw import IPythonConsole from rdkit.Chem import rdMolTransforms IPythonConsole.ipython_3d = True from rdkit.Chem import Draw import rdkit print(rdkit.__version__) %pylab inline . 2020.09.4 Populating the interactive namespace from numpy and matplotlib . Here&#39;s the molecule we&#39;ll use: . m = Chem.AddHs(Chem.MolFromSmiles(&#39;OCCCCCCCN&#39;)) . from rdkit.Chem import rdDepictor m2d = Chem.Mol(m) rdDepictor.Compute2DCoords(m2d) IPythonConsole.drawOptions.addAtomIndices = True m2d . Get the bounds matrix for the molecule and look at the min/max values allowed for the O-N distance: . bounds = rdDistGeom.GetMoleculeBoundsMatrix(m) bounds[8,0],bounds[0,8] . (3.1500000000000004, 9.902933132591349) . Let&#39;s generate a bunch of conformers and look at the distribution of O-N distances: . figsize(6,6) ps = rdDistGeom.ETKDGv3() ps.randomSeed = 0xf00d cids = rdDistGeom.EmbedMultipleConfs(m,500,ps) dists_etkdg = [rdMolTransforms.GetBondLength(conf,0,8) for conf in m.GetConformers()] hist(dists_etkdg,bins=20); title(&#39;ETKDG&#39;); xlabel(&#39;O--N distance&#39;); . Look at one conformer: . print(rdMolTransforms.GetBondLength(m.GetConformer(cids[0]),0,8) ) IPythonConsole.drawMol3D(m,confId=cids[1]) . 5.989729201561945 . You appear to be running in JupyterLab (or JavaScript failed to load for some other reason). You need to install the 3dmol extension: jupyter labextension install jupyterlab_3dmol . Compare the distribution we get doing plain DG: . figsize(6,6) ps = rdDistGeom.EmbedParameters() ps.useExpTorsionAnglePrefs = False ps.useBasicKnowledge = False ps.randomSeed = 0xf00d cids = rdDistGeom.EmbedMultipleConfs(m,500,ps) dists = [rdMolTransforms.GetBondLength(conf,0,8) for conf in m.GetConformers()] hist(dists,bins=20); title(&#39;DG&#39;); xlabel(&#39;O--N distance&#39;); . There&#39;s not a giant difference, but it does look like the DG conformers for this molecule tend to be more extended: the O and N tend to be farther away from each other. . Here&#39;s how we can modify the bounds matrix to bring the O and N closer together: . bounds[0,8] = 4.1 bounds[8,0] = 4.0 from rdkit import DistanceGeometry DistanceGeometry.DoTriangleSmoothing(bounds) . True . Start with using this bounds matrix together with plain DG: . figsize(6,6) ps = rdDistGeom.EmbedParameters() ps.useExpTorsionAnglePrefs = False ps.useBasicKnowledge = False ps.randomSeed = 0xf00d ps.SetBoundsMat(bounds) cids = rdDistGeom.EmbedMultipleConfs(m,500,ps) dists = [rdMolTransforms.GetBondLength(conf,0,8) for conf in m.GetConformers()] hist(dists,bins=20); title(&#39;DG, distance constraints&#39;); xlabel(&#39;O--N distance&#39;); . print(rdMolTransforms.GetBondLength(m.GetConformer(cids[0]),0,8) ) IPythonConsole.drawMol3D(m,confId=cids[0]) . 3.9739942608788374 . You appear to be running in JupyterLab (or JavaScript failed to load for some other reason). You need to install the 3dmol extension: jupyter labextension install jupyterlab_3dmol . When we do ETKDG we add additional terms to the force field that&#39;s used to optimize the structure. Do these override our distance constraints? . figsize(6,6) ps = rdDistGeom.ETKDGv3() ps.randomSeed = 0xf00d ps.SetBoundsMat(bounds) cids = rdDistGeom.EmbedMultipleConfs(m,500,ps) dists = [rdMolTransforms.GetBondLength(conf,0,8) for conf in m.GetConformers()] hist(dists,bins=20); title(&#39;ETKDG with constraints&#39;); xlabel(&#39;O--N distance&#39;); . Most of the distances are longer than what we were looking for, but they are still considerably shorter than what we saw before: . figsize(9,6) ps = rdDistGeom.ETKDGv3() ps.randomSeed = 0xf00d ps.SetBoundsMat(bounds) cids = rdDistGeom.EmbedMultipleConfs(m,500,ps) dists = [rdMolTransforms.GetBondLength(conf,0,8) for conf in m.GetConformers()] hist(dists,bins=20,label=&#39;constraints&#39;); title(&#39;ETKDG&#39;); hist(dists_etkdg,bins=20,label=&#39;no constraints&#39;); legend(); xlabel(&#39;O--N distance&#39;); . So that answers our original question: the &quot;constraints&quot; we place on the conformers by modifying the bounds matrix aren&#39;t strict, so the additional terms added by ETKDG can result in them being violated. But the results are still significant biased towards the region of conformer space we wanted to explore. . Let&#39;s try forcing conformations which have distances consistent with an intra-molecular hydrogen bond. Here we need to modify the bounds matrix elements between both the O and the N as well as the O and one of the Hs attached to the N. If we don&#39;t adjust the O-N distance bounds too we end up with a bounds matrix which cannot be smoothed. . bounds = rdDistGeom.GetMoleculeBoundsMatrix(m) bounds[0,25] = 1.9 bounds[25,0] = 1.8 bounds[0,8] = 3.2 bounds[8,0] = 2.9 from rdkit import DistanceGeometry DistanceGeometry.DoTriangleSmoothing(bounds) . True . figsize(9,6) ps = rdDistGeom.EmbedParameters() ps.useExpTorsionAnglePrefs = False ps.useBasicKnowledge = False ps.randomSeed = 0xf00d ps.SetBoundsMat(bounds) cids = rdDistGeom.EmbedMultipleConfs(m,500,ps) dists = [rdMolTransforms.GetBondLength(conf,0,25) for conf in m.GetConformers()] hist(dists,bins=20); xlabel(&#39;O--H-N distance&#39;); . print(rdMolTransforms.GetBondLength(m.GetConformer(cids[0]),0,25) ) IPythonConsole.drawMol3D(m,confId=cids[0]) . 1.9045497511922502 . You appear to be running in JupyterLab (or JavaScript failed to load for some other reason). You need to install the 3dmol extension: jupyter labextension install jupyterlab_3dmol . Try using ETKDG: . figsize(6,6) ps = rdDistGeom.ETKDGv3() ps.randomSeed = 0xf00d ps.SetBoundsMat(bounds) cids = rdDistGeom.EmbedMultipleConfs(m,500,ps) dists = [rdMolTransforms.GetBondLength(conf,0,25) for conf in m.GetConformers()] hist(dists,bins=20); title(&#39;ETKDG, with constraints&#39;); xlabel(&#39;O--H-N distance&#39;); . print(rdMolTransforms.GetBondLength(m.GetConformer(cids[0]),0,25) ) IPythonConsole.drawMol3D(m,confId=cids[0]) . 2.0641816694294173 . You appear to be running in JupyterLab (or JavaScript failed to load for some other reason). You need to install the 3dmol extension: jupyter labextension install jupyterlab_3dmol . The O--H-N distances here aren&#39;t completely obeying the 1.8-1.9 distance bounds we imposed, but they seem to match a bit better than what we saw above when we constrained the O--N distance. I think that&#39;s likely because now we have an additional constraining term - the O--H distance as well as the O--N distance - to help override the ETKDG preferences. . So to repeat the conclusion: modifying the distance bounds matrix doesn&#39;t act as a hard constraint when we include ETKDG terms in the conformer generation process, but it definitely biases the results towards the areas of conformer space which we were trying to access. .",
            "url": "https://greglandrum.github.io/rdkit-blog/conformers/exploration/2021/02/22/etkdg-and-distance-constraints.html",
            "relUrl": "/conformers/exploration/2021/02/22/etkdg-and-distance-constraints.html",
            "date": " • Feb 22, 2021"
        }
        
    
  
    
        ,"post23": {
            "title": "Looking at random-coordinate embedding",
            "content": "This post discusses and shows the impact of the useRandomCoords option for the RDKit&#39;s conformer generator. . The RDKit&#39;s conformation generator is based on distance geometry. Here are the basic steps for the standard approach: . The molecule&#39;s distance bounds matrix is calculated based on the connection table and a set of rules. | The bounds matrix is smoothed using a triangle-bounds smoothing algorithm. | A random distance matrix that satisfies the bounds matrix is generated. | This distance matrix is embedded in 3 or 4 dimensions (producing coordinates for each atom). | The resulting coordinates are cleaned up somewhat using a crude force field (the &quot;distance geometry force field&quot;) and the bounds matrix. | If 4D embedding was done: another minimization is done with the distance geometry force field including a term to drive the 4th coordinate to zero. | If either experimental torsions (ET) or basic knowledge terms (K) are being used (the default is to use both because the conformations are higher quality), a final minimization is done using the &quot;ET&quot;, &quot;K&quot;, or &quot;ETK&quot; force fields. | Another way to generate the initial set of coordinates is to replace steps 3 and 4 with just picking a set of random coordinates (i.e. scatter the atoms randomly about a 3D box) and then moving on to step 5 and minimizing those using the distance geometry force field mentioned above. I learned of this approach from David Spellmeyer, who published it back in 1997: https://doi.org/10.1016/S1093-3263(97)00014-4 . Starting from random coordinates has been possible within the RDKit more or less since the beginning (I&#39;ve known David a long time ;-), but it&#39;s not the default because my implementation of it was slower than the standard embedding approach in the early testing and validation work I did. I&#39;ve been saying for years that random-coordinate embedding is more robust (though slower), but I haven&#39;t actually gone back and tested/quantified that since my initial experiments. This blog post aims to clear some of that up. . TL;DR: I ran some experiments using a set of 900 molecules with varying numbers of rotatable bonds and two different macrocycle sizes. Each molecule has at least two specified stereocenters. Given the current implementation, random-coordinate embedding is more robust - it&#39;s more likely to produce the requested number of conformers for these structures than the standard metric embedding is - but it still tends to be a bit slower. . Here&#39;s a graphical summary of the results: The main conclusion about timing can be see by comparing the red (metric) and blue (random) data. . Here&#39;s a plot comparing how long it takes to generate each conformer when trying for 50 conformers (left) or 50 more diverse conformers (right), the plot has been zoomed in, so a few extreme outliers (which impact the standard metric embedding more severely than the random-coordinate embedding) are not visible. . . Given that it is certainly more robust and that the overall performance difference isn&#39;t huge, I think I&#39;m likely to switch to using random-coordinate embedding for my future work. Maybe we can think about making it the default in the RDKit too. . For those who are interested, here&#39;s the original literature about ETKDG: . The original ETKDG publication: https://pubs.acs.org/doi/abs/10.1021/acs.jcim.5b00654 | Sereina Riniker&#39;s presentation at the 2015 RDKit UGM: https://github.com/rdkit/UGM_2015/blob/master/Presentations/ETKDG.SereinaRiniker.pdf | An update describing ETKDGv3 and extensions to better handle small rings and macrocycles: https://pubs.acs.org/doi/abs/10.1021/acs.jcim.0c00025 | . If you want to play with the compounds yourself, the SMILES are all in the rdkit_blog github repo . Ok, let&#39;s get to work and generate the data. . from rdkit import Chem from rdkit.Chem import Draw from rdkit.Chem.Draw import IPythonConsole from rdkit.Chem import rdDepictor rdDepictor.SetPreferCoordGen(True) import pandas as pd import rdkit print(rdkit.__version__) %load_ext sql %pylab inline . 2020.09.4 The sql extension is already loaded. To reload it, use: %reload_ext sql Populating the interactive namespace from numpy and matplotlib . Collecting test molecules from ChEMBL . For this exercise I want a set of molecules which have varying numbers of rotatable bonds and which include at least two specified chiral centers. I include the constraint on chiral centers because the RDKit&#39;s conformation generator normally only returns conformations which match the specified stereochemistry. This can make conformation generation slower and I&#39;m curious to see the impact of that as part of this post. . Start with a few queries against my local copy of ChEMBL27 to see how many molecules with at least two specified chiral centers are available with different numbers of rotatable bonds: . %sql postgresql://localhost/chembl_27 select count(*) from compound_properties join compound_structures using (molregno) where rtb = 2 and array_length(regexp_split_to_array(canonical_smiles,&#39;@+&#39;),1)-1 &gt;2; . 1 rows affected. . count . 14904 | . %sql postgresql://localhost/chembl_27 select count(*) from compound_properties join compound_structures using (molregno) where rtb = 5 and array_length(regexp_split_to_array(canonical_smiles,&#39;@+&#39;),1)-1 &gt;2; . 1 rows affected. . count . 20586 | . %sql postgresql://localhost/chembl_27 select count(*) from compound_properties join compound_structures using (molregno) where rtb = 10 and array_length(regexp_split_to_array(canonical_smiles,&#39;@+&#39;),1)-1 &gt;2; . 1 rows affected. . count . 9845 | . %sql postgresql://localhost/chembl_27 select count(*) from compound_properties join compound_structures using (molregno) where rtb = 15 and array_length(regexp_split_to_array(canonical_smiles,&#39;@+&#39;),1)-1 &gt;2; . 1 rows affected. . count . 3834 | . %sql postgresql://localhost/chembl_27 select count(*) from compound_properties join compound_structures using (molregno) where rtb = 25 and array_length(regexp_split_to_array(canonical_smiles,&#39;@+&#39;),1)-1 &gt;2; . 1 rows affected. . count . 1129 | . Looks like we can get plenty of molecules with up to 25 rotatable bonds, so let&#39;s go ahead and collect a set of 100 molecules for each of the rotatable bond counts 1, 2, 5, 10, 15, 20, and 25. I also include two additional sets of 100 molecules: one which contains at least one ring of size 10 and one which contains at least one ring of size 14. These macrocycles show up in what comes below with negative numbers of rotatable bonds: -10 for the compounds with a 10-ring and -14 for compounds with a 14-ring. . overall_data = [] for tgt in (1,2,5,10,15,20,25): d = %sql postgresql://localhost/chembl_27 select * from (select canonical_smiles,chembl_id,rtb from compound_properties join compound_structures using (molregno) join chembl_id_lookup on (molregno=entity_id and entity_type=&#39;COMPOUND&#39;) where rtb = :tgt and mw_freebase = full_mwt and array_length(regexp_split_to_array(canonical_smiles,&#39;@+&#39;),1)-1 &gt;2) tmp order by random() limit 100; overall_data.extend(d) for tgt in (10,14): sma = f&#39;[r{tgt}]&#39; d = %sql postgresql://localhost/chembl_27 select * from (select canonical_smiles,chembl_id,-1 * :tgt from compound_properties join compound_structures using (molregno) join rdk.mols using (molregno) join chembl_id_lookup on (molregno=entity_id and entity_type=&#39;COMPOUND&#39;) where m@&gt;:sma ::qmol and mw_freebase = full_mwt and array_length(regexp_split_to_array(canonical_smiles,&#39;@+&#39;),1)-1 &gt;2) tmp order by random() limit 100; overall_data.extend(d) with open(&#39;../data/chembl27_confgen_tgts.txt&#39;,&#39;w+&#39;) as outf: outf.write(&#39;SMILES CHEMBL_ID RTB n&#39;) for line in overall_data: outf.write(&#39; &#39;.join(str(x) for x in line)+&#39; n&#39;) . 100 rows affected. 100 rows affected. 100 rows affected. 100 rows affected. 100 rows affected. 100 rows affected. 100 rows affected. 100 rows affected. 100 rows affected. . !head ../data/chembl27_confgen_tgts.txt . SMILES CHEMBL_ID RTB C[C@@H]1C[C@@]2(C)[C@@H](CC[C@H]3[C@@H]4CC[C@H](O)[C@@]4(C)CC[C@@H]32)C/C1=N N=C1/C[C@@H]2CC[C@H]3[C@@H]4CC[C@H](O)[C@@]4(C)CC[C@@H]3[C@@]2(C)C[C@H]1C CHEMBL2104408 1 CC(C)[C@@H]1OC(=O)C2(/C=C/c3ccc4ccc(nc4c3)[C@@H](C)NC(=O)[C@@H]3CCCN(N3)C(=O)[C@H](C)NC1=O)CCS(=O)(=O)CC2 CHEMBL4175329 1 CC(=O)O[C@H]1CCC[C@@H]2COC(=O)[C@@H]21 CHEMBL2228334 1 CNC(=O)O[C@H]1OC(=O)[C@H]2[C@H]3C=C[C@H](C3)[C@H]21 CHEMBL3989617 1 CC1(C)CC[C@]2(C)CC[C@]3(C(=O)O)C(=CC[C@@H]4[C@@]5(C)CC[C@H](O)C(C)(C)[C@@H]5CC[C@]43C)[C@@H]2C1 CHEMBL559587 1 CC1(C)[C@@H](O)CC[C@]2(C)C3=C(CC[C@@H]12)[C@@]1(C)CC[C@@]2(C)CC[C@@](C)(CO)C[C@H]2[C@]1(C)CC3 CHEMBL484238 1 C[C@]12CC[C@H](c3cc(F)c(O)cc3F)C[C@H]1CC[C@@H]2O CHEMBL1651144 1 Cc1cncc(C2=CC=C3[C@@H]4CCC5CNC(=O)CC[C@]5(C)[C@H]4CC[C@]23C)c1 CHEMBL3938064 1 C[C@H](O)[C@H]1O[C@@H]2SC(N3CCCC3)=N[C@@H]2[C@@H](O)[C@@H]1O CHEMBL3647379 1 . Run the experiments . Now we read those molecules back in and then start collecting data. . Here are the different experiments: . Generate a single conformer for each molecule. | Try to generate 50 conformers for each molecule. | Try to generate 50 diverse conformers for each molecule using an RMSD filter of 0.5 | Try to generate 50 conformers for each molecule ignoring stereochemistry | We will use ETKDGv3 and repeat each run once starting from standard embedding and once starting from random coordinates. . suppl = Chem.SmilesMolSupplier(&#39;../data/chembl27_confgen_tgts.txt&#39;) ms = [Chem.AddHs(m) for m in suppl] . from rdkit.Chem import AllChem from collections import defaultdict import time import pickle . Single conformer . ps = AllChem.ETKDGv3() ps.randomSeed=0xf00d metric_etkdg_res = [] for i,m in enumerate(ms): if not (i+1)%10: print(f&#39;Doing {i+1} of {len(ms)}&#39;) m = Chem.Mol(m) t1 = time.time() AllChem.EmbedMolecule(m,ps) t2 = time.time() metric_etkdg_res.append((t2-t1,m.GetNumConformers(),m,m.GetIntProp(&#39;RTB&#39;))) with open(&#39;./results/random_coords_expt.pkl&#39;,&#39;wb+&#39;) as outf: pickle.dump((metric_etkdg_res,),outf) . ps = AllChem.ETKDGv3() ps.randomSeed=0xf00d ps.useRandomCoords = True random_etkdg_res = [] for i,m in enumerate(ms): if not (i+1)%10: print(f&#39;Doing {i+1} of {len(ms)}&#39;) m = Chem.Mol(m) t1 = time.time() AllChem.EmbedMolecule(m,ps) t2 = time.time() random_etkdg_res.append((t2-t1,m.GetNumConformers(),m,m.GetIntProp(&#39;RTB&#39;))) with open(&#39;./results/random_coords_expt.pkl&#39;,&#39;wb+&#39;) as outf: pickle.dump((metric_etkdg_res,random_etkdg_res,),outf) . 50 conformers . ps = AllChem.ETKDGv3() ps.randomSeed=0xf00d ps.numThreads = 4 metric_etkdg50_res = [] for i,m in enumerate(ms): if not (i+1)%10: print(f&#39;Doing {i+1} of {len(ms)}&#39;) m = Chem.Mol(m) t1 = time.time() AllChem.EmbedMultipleConfs(m,50,ps) t2 = time.time() metric_etkdg50_res.append((t2-t1,m.GetNumConformers(),m,m.GetIntProp(&#39;RTB&#39;))) with open(&#39;./results/random_coords_expt.pkl&#39;,&#39;wb+&#39;) as outf: pickle.dump((metric_etkdg_res,random_etkdg_res,metric_etkdg50_res,),outf) . ps = AllChem.ETKDGv3() ps.randomSeed=0xf00d ps.numThreads = 4 ps.useRandomCoords = True random_etkdg50_res = [] for i,m in enumerate(ms): if not (i+1)%10: print(f&#39;Doing {i+1} of {len(ms)}&#39;) m = Chem.Mol(m) t1 = time.time() AllChem.EmbedMultipleConfs(m,50,ps) t2 = time.time() random_etkdg50_res.append((t2-t1,m.GetNumConformers(),m,m.GetIntProp(&#39;RTB&#39;))) with open(&#39;./results/random_coords_expt.pkl&#39;,&#39;wb+&#39;) as outf: pickle.dump((metric_etkdg_res,random_etkdg_res,metric_etkdg50_res,random_etkdg50_res,),outf) . Include RMS Pruning . ps = AllChem.ETKDGv3() ps.randomSeed=0xf00d ps.numThreads = 4 ps.pruneRmsThresh = 0.5 metric_etkdg50_rms_res = [] for i,m in enumerate(ms): if not (i+1)%10: print(f&#39;Doing {i+1} of {len(ms)}&#39;) m = Chem.Mol(m) t1 = time.time() AllChem.EmbedMultipleConfs(m,50,ps) t2 = time.time() metric_etkdg50_rms_res.append((t2-t1,m.GetNumConformers(),m,m.GetIntProp(&#39;RTB&#39;))) with open(&#39;./results/random_coords_expt.pkl&#39;,&#39;wb+&#39;) as outf: pickle.dump((metric_etkdg_res,random_etkdg_res,metric_etkdg50_res,random_etkdg50_res, metric_etkdg50_rms_res,),outf) . ps = AllChem.ETKDGv3() ps.randomSeed=0xf00d ps.numThreads = 4 ps.useRandomCoords = True ps.pruneRmsThresh = 0.5 random_etkdg50_rms_res = [] for i,m in enumerate(ms): if not (i+1)%10: print(f&#39;Doing {i+1} of {len(ms)}&#39;) m = Chem.Mol(m) t1 = time.time() AllChem.EmbedMultipleConfs(m,50,ps) t2 = time.time() random_etkdg50_rms_res.append((t2-t1,m.GetNumConformers(),m,m.GetIntProp(&#39;RTB&#39;))) with open(&#39;./results/random_coords_expt.pkl&#39;,&#39;wb+&#39;) as outf: pickle.dump((metric_etkdg_res,random_etkdg_res,metric_etkdg50_res,random_etkdg50_res, metric_etkdg50_rms_res,random_etkdg50_rms_res),outf) . ps = AllChem.ETKDGv3() ps.randomSeed=0xf00d ps.numThreads = 4 ps.enforceChirality = False metric_etkdg50_nochiral_res = [] for i,m in enumerate(ms): if not (i+1)%10: print(f&#39;Doing {i+1} of {len(ms)}&#39;) m = Chem.Mol(m) t1 = time.time() AllChem.EmbedMultipleConfs(m,50,ps) t2 = time.time() metric_etkdg50_nochiral_res.append((t2-t1,m.GetNumConformers(),m,m.GetIntProp(&#39;RTB&#39;))) with open(&#39;./results/random_coords_expt.pkl&#39;,&#39;wb+&#39;) as outf: pickle.dump((metric_etkdg_res,random_etkdg_res,metric_etkdg50_res,random_etkdg50_res, metric_etkdg50_rms_res,random_etkdg50_rms_res,metric_etkdg50_nochiral_res,),outf) . ps = AllChem.ETKDGv3() ps.randomSeed=0xf00d ps.numThreads = 4 ps.useRandomCoords = True ps.enforceChirality = False random_etkdg50_nochiral_res = [] for i,m in enumerate(ms): if not (i+1)%10: print(f&#39;Doing {i+1} of {len(ms)}&#39;) m = Chem.Mol(m) t1 = time.time() AllChem.EmbedMultipleConfs(m,50,ps) t2 = time.time() random_etkdg50_nochiral_res.append((t2-t1,m.GetNumConformers(),m,m.GetIntProp(&#39;RTB&#39;))) with open(&#39;./results/random_coords_expt.pkl&#39;,&#39;wb+&#39;) as outf: pickle.dump((metric_etkdg_res,random_etkdg_res,metric_etkdg50_res,random_etkdg50_res, metric_etkdg50_rms_res,random_etkdg50_rms_res,metric_etkdg50_nochiral_res, random_etkdg50_nochiral_res),outf) . ps = AllChem.ETKDGv3() ps.randomSeed=0xf00d ps.numThreads = 4 ps.useRandomCoords = True ps.boxSizeMult = 1.0 random_etkdg50_box1_res = [] for i,m in enumerate(ms): if not (i+1)%10: print(f&#39;Doing {i+1} of {len(ms)}&#39;) m = Chem.Mol(m) t1 = time.time() AllChem.EmbedMultipleConfs(m,50,ps) t2 = time.time() random_etkdg50_box1_res.append((t2-t1,m.GetNumConformers(),m,m.GetIntProp(&#39;RTB&#39;))) with open(&#39;./results/random_coords_expt.pkl&#39;,&#39;wb+&#39;) as outf: pickle.dump((metric_etkdg_res,random_etkdg_res,metric_etkdg50_res,random_etkdg50_res, metric_etkdg50_rms_res,random_etkdg50_rms_res,metric_etkdg50_nochiral_res, random_etkdg50_nochiral_res, random_etkdg50_box1_res),outf) . ps = AllChem.ETKDGv3() ps.randomSeed=0xf00d ps.numThreads = 4 ps.useRandomCoords = True ps.boxSizeMult = 0.5 random_etkdg50_box2_res = [] for i,m in enumerate(ms): if not (i+1)%10: print(f&#39;Doing {i+1} of {len(ms)}&#39;) m = Chem.Mol(m) t1 = time.time() AllChem.EmbedMultipleConfs(m,50,ps) t2 = time.time() random_etkdg50_box2_res.append((t2-t1,m.GetNumConformers(),m,m.GetIntProp(&#39;RTB&#39;))) with open(&#39;./results/random_coords_expt.pkl&#39;,&#39;wb+&#39;) as outf: pickle.dump((metric_etkdg_res,random_etkdg_res,metric_etkdg50_res,random_etkdg50_res, metric_etkdg50_rms_res,random_etkdg50_rms_res,metric_etkdg50_nochiral_res, random_etkdg50_nochiral_res, random_etkdg50_box1_res, random_etkdg50_box2_res),outf) . Do the Analysis . figsize(15,6) nrots = sorted(set(x[-1] for x in metric_etkdg_res)) subplot(1,2,1) for nrot in nrots: xp = [x[0] for x in metric_etkdg_res if x[-1]==nrot] yp = [x[0] for x in random_etkdg_res if x[-1]==nrot] scatter(xp,yp,label=str(nrot)) legend(); xlim(0,3.5); ylim(0,4); plot((0,4),(0,4)) xlabel(&#39;metric&#39;) ylabel(&#39;random coords&#39;); title(&#39;zoom&#39;); subplot(1,2,2) for nrot in nrots: xp = [x[0] for x in metric_etkdg_res if x[-1]==nrot] yp = [x[0] for x in random_etkdg_res if x[-1]==nrot] scatter(xp,yp,label=str(nrot)) legend(); xlabel(&#39;metric&#39;) ylabel(&#39;random coords&#39;); title(&#39;full range&#39;); . figsize(15,6) nrots = sorted(set(x[-1] for x in metric_etkdg_res)) subplot(1,2,1) for nrot in nrots: xp = [x[0] for x in metric_etkdg50_res if x[-1]==nrot] yp = [x[0] for x in random_etkdg50_res if x[-1]==nrot] scatter(xp,yp,label=str(nrot)) legend(); xlim(0,50); ylim(0,80); plot((0,35),(0,35)) title(&#39;time (s)&#39;) xlabel(&#39;metric&#39;) ylabel(&#39;random coords&#39;); title(&#39;zoom&#39;); subplot(1,2,2) for nrot in nrots: xp = [x[0] for x in metric_etkdg50_res if x[-1]==nrot] yp = [x[0] for x in random_etkdg50_res if x[-1]==nrot] scatter(xp,yp,label=str(nrot)) legend(); #xlim(0,25); #ylim(0,35); plot((0,500),(0,500)) title(&#39;time (s)&#39;) xlabel(&#39;metric&#39;) ylabel(&#39;random coords&#39;); title(&#39;full range&#39;); . Number of conformers generated . figsize(7.5,6) nrots = sorted(set(x[-1] for x in metric_etkdg_res)) print(f&#39;number of mols with below 50 conformers:&#39;) for nrot in nrots: xp = [x[1] for x in metric_etkdg50_res if x[-1]==nrot] yp = [x[1] for x in random_etkdg50_res if x[-1]==nrot] print(f&#39; {nrot} rotatable bonds, metric: {len([1 for x in xp if x!=50])} random: {len([1 for x in yp if x!=50])}&#39;) scatter(xp,yp,label=str(nrot)) legend(); #xlim(0,30); #ylim(0,40); #plot((0,30),(0,30)) title(&#39;num confs generated out of 50&#39;) xlabel(&#39;metric&#39;) ylabel(&#39;random coords&#39;); . number of mols with below 50 conformers: -14 rotatable bonds, metric: 8 random: 0 -10 rotatable bonds, metric: 1 random: 1 1 rotatable bonds, metric: 2 random: 2 2 rotatable bonds, metric: 2 random: 2 5 rotatable bonds, metric: 1 random: 1 10 rotatable bonds, metric: 4 random: 0 15 rotatable bonds, metric: 10 random: 0 20 rotatable bonds, metric: 27 random: 0 25 rotatable bonds, metric: 28 random: 0 . figsize(7.5,6) nrots = sorted(set(x[-1] for x in metric_etkdg_res)) print(f&#39;number of mols with below 50 conformers:&#39;) for nrot in nrots: xp = [x[1] for x in metric_etkdg50_rms_res if x[-1]==nrot] yp = [x[1] for x in random_etkdg50_rms_res if x[-1]==nrot] print(f&#39; {nrot} rotatable bonds, metric: {len([1 for x in xp if x!=50])} random: {len([1 for x in yp if x!=50])}&#39;) scatter(xp,yp,label=str(nrot)) legend(); #xlim(0,30); #ylim(0,40); plot((0,50),(0,50)) title(&#39;num diverse confs generated out of 50&#39;) xlabel(&#39;metric&#39;) ylabel(&#39;random coords&#39;); . number of mols with below 50 conformers: -14 rotatable bonds, metric: 31 random: 17 -10 rotatable bonds, metric: 85 random: 83 1 rotatable bonds, metric: 99 random: 99 2 rotatable bonds, metric: 100 random: 100 5 rotatable bonds, metric: 93 random: 85 10 rotatable bonds, metric: 32 random: 19 15 rotatable bonds, metric: 13 random: 1 20 rotatable bonds, metric: 27 random: 0 25 rotatable bonds, metric: 28 random: 0 . figsize(7.5,6) nrots = sorted(set(x[-1] for x in metric_etkdg_res)) print(f&#39;number of mols with below 50 conformers:&#39;) for nrot in nrots: xp = [x[1] for x in metric_etkdg50_nochiral_res if x[-1]==nrot] yp = [x[1] for x in random_etkdg50_nochiral_res if x[-1]==nrot] print(f&#39; {nrot} rotatable bonds, metric: {len([1 for x in xp if x!=50])} random: {len([1 for x in yp if x!=50])}&#39;) scatter(xp,yp,label=str(nrot)) legend(); #xlim(0,30); #ylim(0,40); #plot((0,30),(0,30)) title(&#39;num nochiral confs generated out of 50&#39;) xlabel(&#39;metric&#39;) ylabel(&#39;random coords&#39;); . number of mols with below 50 conformers: -14 rotatable bonds, metric: 6 random: 0 -10 rotatable bonds, metric: 0 random: 0 1 rotatable bonds, metric: 0 random: 0 2 rotatable bonds, metric: 0 random: 0 5 rotatable bonds, metric: 0 random: 0 10 rotatable bonds, metric: 2 random: 0 15 rotatable bonds, metric: 9 random: 0 20 rotatable bonds, metric: 26 random: 0 25 rotatable bonds, metric: 21 random: 0 . The random coordinate embedding produces 50 conformers in almost every case, while there are a significant number of examples where metric embedding is unable to produce all 50 conformers. . Time per conformer generated . figsize(15,6) nrots = sorted(set(x[-1] for x in metric_etkdg_res)) subplot(1,2,1) for nrot in nrots: keep = [i for i,(x,y) in enumerate(zip(metric_etkdg50_res,random_etkdg50_res)) if x[-1]==nrot and x[1]!=0 and y[1]!=0] xp = [metric_etkdg50_res[x][0]/metric_etkdg50_res[x][1] for x in keep] yp = [random_etkdg50_res[x][0]/random_etkdg50_res[x][1] for x in keep] scatter(xp,yp,label=str(nrot)) legend(); xlim(0,1.5); ylim(0,1.2); plot((0,.8),(0,.8)) title(&#39;time per conformer produced (4 threads)&#39;) xlabel(&#39;metric&#39;) ylabel(&#39;random coords&#39;); subplot(1,2,2) for nrot in nrots: keep = [i for i,(x,y) in enumerate(zip(metric_etkdg50_rms_res,random_etkdg50_rms_res)) if x[-1]==nrot and x[1]!=0 and y[1]!=0] xp = [metric_etkdg50_res[x][0]/metric_etkdg50_rms_res[x][1] for x in keep] yp = [random_etkdg50_res[x][0]/random_etkdg50_rms_res[x][1] for x in keep] scatter(xp,yp,label=str(nrot)) legend(); xlim(0,1.5); ylim(0,2); plot((0,1),(0,1)) title(&#39;time per diverse conformer produced (4 threads)&#39;) xlabel(&#39;metric&#39;) ylabel(&#39;random coords&#39;); . Look at the same thing without cropping outliers. . figsize(15,6) nrots = sorted(set(x[-1] for x in metric_etkdg_res)) subplot(1,2,1) for nrot in nrots: keep = [i for i,(x,y) in enumerate(zip(metric_etkdg50_res,random_etkdg50_res)) if x[-1]==nrot and x[1]!=0 and y[1]!=0] xp = [metric_etkdg50_res[x][0]/metric_etkdg50_res[x][1] for x in keep] yp = [random_etkdg50_res[x][0]/random_etkdg50_res[x][1] for x in keep] scatter(xp,yp,label=str(nrot)) legend(); plot((0,3.5),(0,3.5)) title(&#39;time per conformer produced (4 threads)&#39;) xlabel(&#39;metric&#39;) ylabel(&#39;random coords&#39;); subplot(1,2,2) for nrot in nrots: keep = [i for i,(x,y) in enumerate(zip(metric_etkdg50_rms_res,random_etkdg50_rms_res)) if x[-1]==nrot and x[1]!=0 and y[1]!=0] xp = [metric_etkdg50_res[x][0]/metric_etkdg50_rms_res[x][1] for x in keep] yp = [random_etkdg50_res[x][0]/random_etkdg50_rms_res[x][1] for x in keep] scatter(xp,yp,label=str(nrot)) legend(); plot((0,3.5),(0,3.5)) title(&#39;time per diverse conformer produced (4 threads)&#39;) xlabel(&#39;metric&#39;) ylabel(&#39;random coords&#39;); . Note that these times per conformer cannot be directly compared to the time to generate a single conformer since these were run using multiple threads. . Ignoring chirality . figsize(7.5,6) nrots = sorted(set(x[-1] for x in metric_etkdg_res)) for nrot in nrots: xp = [x[0] for x in metric_etkdg50_nochiral_res if x[-1]==nrot] yp = [x[0] for x in random_etkdg50_nochiral_res if x[-1]==nrot] scatter(xp,yp,label=str(nrot)) legend(); #xlim(0,30); #ylim(0,40); plot((0,15),(0,15)) title(&#39;nochiral time(s)&#39;) xlabel(&#39;metric&#39;) ylabel(&#39;random coords&#39;); . General impact of ignoring chirality . nrots = sorted(set(x[-1] for x in metric_etkdg_res)) figsize(15,6) subplot(1,2,1) for nrot in nrots: xp = [x[0] for x in metric_etkdg50_res if x[-1]==nrot] yp = [x[0] for x in metric_etkdg50_nochiral_res if x[-1]==nrot] scatter(xp,yp,label=str(nrot)) legend(); xlim(0,50); ylim(0,30); plot((0,30),(0,30)) title(&#39;metric embedding time(s)&#39;) xlabel(&#39;chiral&#39;) ylabel(&#39;nochiral&#39;); subplot(1,2,2) for nrot in nrots: xp = [x[0] for x in random_etkdg50_res if x[-1]==nrot] yp = [x[0] for x in random_etkdg50_nochiral_res if x[-1]==nrot] scatter(xp,yp,label=str(nrot)) legend(); xlim(0,50); ylim(0,40); plot((0,40),(0,40)) title(&#39;random embedding time(s)&#39;) xlabel(&#39;chiral&#39;) ylabel(&#39;nochiral&#39;); . Impact of box size on random embedding . nrots = sorted(set(x[-1] for x in metric_etkdg_res)) figsize(15,6) subplot(1,2,1) for nrot in nrots: xp = [x[0] for x in random_etkdg50_res if x[-1]==nrot] yp = [x[0] for x in random_etkdg50_box1_res if x[-1]==nrot] scatter(xp,yp,label=str(nrot)) legend(); xlim(0,80); ylim(0,80); plot((0,60),(0,60)) title(&#39;random embedding time(s)&#39;) xlabel(&#39;mult=2 (default)&#39;) ylabel(&#39;mult=1&#39;); subplot(1,2,2) for nrot in nrots: xp = [x[0] for x in random_etkdg50_res if x[-1]==nrot] yp = [x[0] for x in random_etkdg50_box2_res if x[-1]==nrot] scatter(xp,yp,label=str(nrot)) legend(); xlim(0,80); ylim(0,80); plot((0,60),(0,60)) title(&#39;random embedding time(s)&#39;) xlabel(&#39;mult=2 (default)&#39;) ylabel(&#39;mult=0.5&#39;); . Summaries . def set_box_color(bp, color): setp(bp[&#39;boxes&#39;], color=color) setp(bp[&#39;whiskers&#39;], color=color) setp(bp[&#39;caps&#39;], color=color) setp(bp[&#39;medians&#39;], color=color) setp(bp[&#39;fliers&#39;], markeredgecolor=color) figsize(15,6) ax = axes() ax.set_yscale(&#39;log&#39;); ax.set_ylabel(&#39;time(s)&#39;) ax.set_xlabel(&#39;nrot&#39;) nrots = sorted(set(x[-1] for x in metric_etkdg_res)) d = [[x[0] for x in metric_etkdg50_res if x[-1]==nrot] for nrot in nrots] bp = ax.boxplot(d,positions = [3*x for x in range(len(d))]); set_box_color(bp,&#39;r&#39;) d = [[x[0] for x in random_etkdg50_res if x[-1]==nrot] for nrot in nrots] bp = ax.boxplot(d,positions = [3*x+.5 for x in range(len(d))]); set_box_color(bp,&#39;b&#39;) d = [[x[0] for x in random_etkdg50_nochiral_res if x[-1]==nrot] for nrot in nrots] bp = ax.boxplot(d,positions = [3*x+1 for x in range(len(d))]); set_box_color(bp,&#39;c&#39;) d = [[x[0] for x in random_etkdg50_box1_res if x[-1]==nrot] for nrot in nrots] bp = ax.boxplot(d,positions = [3*x+1.5 for x in range(len(d))]); set_box_color(bp,&#39;m&#39;) d = [[x[0] for x in random_etkdg50_box2_res if x[-1]==nrot] for nrot in nrots] bp = ax.boxplot(d,positions = [3*x+2 for x in range(len(d))]); set_box_color(bp,&#39;y&#39;) #set_axis_style(ax, [str(x) for x in nrots]) ticks = [str(x) for x in nrots] xticks(np.arange(0, len(ticks) * 3, 3)+1, ticks); plot([], c=&#39;r&#39;, label=&#39;metric&#39;) plot([], c=&#39;b&#39;, label=&#39;random&#39;) plot([], c=&#39;c&#39;, label=&#39;random-nochiral&#39;) plot([], c=&#39;m&#39;, label=&#39;random-box1&#39;) plot([], c=&#39;y&#39;, label=&#39;random-box0.5&#39;) legend(); . def set_box_color(bp, color): setp(bp[&#39;boxes&#39;], color=color) setp(bp[&#39;whiskers&#39;], color=color) setp(bp[&#39;caps&#39;], color=color) setp(bp[&#39;medians&#39;], color=color) setp(bp[&#39;fliers&#39;], markeredgecolor=color) figsize(15,6) ax = axes() ax.set_yscale(&#39;log&#39;); ax.set_ylabel(&#39;time per conformer (s)&#39;) ax.set_xlabel(&#39;nrot&#39;) nrots = sorted(set(x[-1] for x in metric_etkdg_res)) d = [[x[0]/x[2].GetNumConformers() for x in metric_etkdg50_res if x[-1]==nrot and x[2].GetNumConformers()!=0] for nrot in nrots] bp = ax.boxplot(d,positions = [3*x for x in range(len(d))]); set_box_color(bp,&#39;r&#39;) d = [[x[0]/x[2].GetNumConformers() for x in metric_etkdg50_rms_res if x[-1]==nrot and x[2].GetNumConformers()!=0] for nrot in nrots] bp = ax.boxplot(d,positions = [3*x+.5 for x in range(len(d))]); set_box_color(bp,&#39;c&#39;) d = [[x[0]/x[2].GetNumConformers() for x in random_etkdg50_res if x[-1]==nrot and x[2].GetNumConformers()!=0] for nrot in nrots] bp = ax.boxplot(d,positions = [3*x+1 for x in range(len(d))]); set_box_color(bp,&#39;b&#39;) d = [[x[0]/x[2].GetNumConformers() for x in random_etkdg50_rms_res if x[-1]==nrot and x[2].GetNumConformers()!=0] for nrot in nrots] bp = ax.boxplot(d,positions = [3*x+1.5 for x in range(len(d))]); set_box_color(bp,&#39;m&#39;) #set_axis_style(ax, [str(x) for x in nrots]) ticks = [str(x) for x in nrots] xticks(np.arange(0, len(ticks) * 3, 3)+1, ticks); plot([], c=&#39;r&#39;, label=&#39;metric&#39;) plot([], c=&#39;c&#39;, label=&#39;metric-diverse&#39;) plot([], c=&#39;b&#39;, label=&#39;random&#39;) plot([], c=&#39;m&#39;, label=&#39;random-diverse&#39;) legend(); . Look at some of the troublesome structures . Which ones couldn&#39;t we generate conformers for? . no_confs_metric_etkdg50 = set([i for i,x in enumerate(metric_etkdg50_res) if x[2].GetNumConformers()==0]) no_confs_random_etkdg50 = set([i for i,x in enumerate(metric_etkdg50_res) if x[2].GetNumConformers()==0]) print(f&#39;metric: {len(no_confs_metric_etkdg50)}, random embedding: {len(no_confs_random_etkdg50)}, overlap: {len(no_confs_metric_etkdg50.union(no_confs_random_etkdg50))}&#39;) . metric: 13, random embedding: 13, overlap: 13 . dms = [Chem.RemoveHs(ms[i]) for i in no_confs_metric_etkdg50] dms = [m for m in dms if m.GetNumAtoms()&lt;75] Draw.MolsToGridImage(dms,subImgSize=(300,250),molsPerRow=3, legends=[m.GetProp(&#39;_Name&#39;) for m in dms]) . dms = [Chem.RemoveHs(ms[i]) for i in no_confs_metric_etkdg50] dms = [m for m in dms if m.GetNumAtoms()&gt;=75] from IPython.display import SVG d2d = Draw.MolDraw2DSVG(800,350) d2d.DrawMolecule(dms[0]) d2d.FinishDrawing() SVG(d2d.GetDrawingText()) . Ok, some of those are quite constrained and have a fair number of chiral centers, so it&#39;s easy to imagine them being hard to embed. Some (like CHEMBL59404) are just peptides though... seems like those should be manageable. Something to look into . What about the structures which embed but take a really long time? . slow_metric_etkdg50 = [y for x,y in sorted([(x[0],i) for i,x in enumerate(metric_etkdg50_res) if x[2].GetNumConformers()],reverse=True)][:5] dms = [Chem.RemoveHs(ms[i]) for i in slow_metric_etkdg50] #dms = [m for m in dms if m.GetNumAtoms()&lt;75] Draw.MolsToGridImage(dms,subImgSize=(300,250),molsPerRow=3, legends=[m.GetProp(&#39;_Name&#39;) for m in dms]) . IPythonConsole.ipython_3d = True metric_etkdg50_res[slow_metric_etkdg50[0]][2] . You appear to be running in JupyterLab (or JavaScript failed to load for some other reason). You need to install the 3dmol extension: jupyter labextension install jupyterlab_3dmol . metric_etkdg50_res[slow_metric_etkdg50[4]][2] . You appear to be running in JupyterLab (or JavaScript failed to load for some other reason). You need to install the 3dmol extension: jupyter labextension install jupyterlab_3dmol .",
            "url": "https://greglandrum.github.io/rdkit-blog/conformers/exploration/2021/01/31/looking-at-random-coordinate-embedding.html",
            "relUrl": "/conformers/exploration/2021/01/31/looking-at-random-coordinate-embedding.html",
            "date": " • Jan 31, 2021"
        }
        
    
  
    
        ,"post24": {
            "title": "Sphere exclusion clustering with the RDKit",
            "content": "Roger Sayle contributed an implementation of sphere-exclusion picking to the RDKit as part of the 2019.09 release and I recently realized that I&#39;d never blogged about that code or how to use it to do compound clustering. So here&#39;s a short(ish) one. . The RDKit has had an implementation of the MaxMin algorithm for picking diverse compounds for quite a while (Roger made this a lot faster back in 2017). The input to the MaxMin picker is the number of diverse compounds you want. The new algorithm is different: you provide the minimum distance allowed between the compounds picked and it returns a set of compounds satisfying that constraint. . Both of these methods for picking diverse compounds can then be converted into clustering algorithms by defining those picked points to be cluster centroids and then assigning non-picked compounds to the nearest centroid. We&#39;ll do that here for the sphere-exclusion algorithm. . Further reading: . for more about the sphere-exclusion picker and/or learn how it works: here&#39;s Roger&#39;s UGM presentation | Roger&#39;s UGM presentation describing his fast implementation of the MaxMin picker is here | Tim Dudgeon&#39;s guest post on this blog provides a nice overview of the new MaxMin picker. | . from rdkit import Chem from rdkit import DataStructs from rdkit.Chem import Draw from rdkit.Chem.Draw import IPythonConsole from rdkit.Chem import rdDepictor, rdMolDescriptors import time rdDepictor.SetPreferCoordGen(True) import rdkit %pylab inline print(rdkit.__version__) . Populating the interactive namespace from numpy and matplotlib 2020.09.1 . First dataset . The dataset we&#39;ll start with is the &quot;new Lessel and Briem&quot; set that I put together as part of this blog post . ms = [x for x in Chem.SmilesMolSupplier(&#39;../data/BLSets_selected_actives.txt&#39;)] len(ms) . 6359 . We&#39;ll use MFP2 fingerprints: . from rdkit.Chem import rdMolDescriptors fps = [rdMolDescriptors.GetMorganFingerprintAsBitVect(m,2,2048) for m in ms] . The new sphere-exclusion code is available using the LeaderPicker: . from rdkit.SimDivFilters import rdSimDivPickers lp = rdSimDivPickers.LeaderPicker() . And we pick compounds by giving the picker the fingerprints and a minimum distance between cluster centroids. Here we&#39;re using a distance threshold of 0.65, which is the random-similarity threshold I found for MFP2 fingeprints. . thresh = 0.65 # &lt;- minimum distance between cluster centroids picks = lp.LazyBitVectorPick(fps,len(fps),thresh) print(len(picks)) . 535 . For reference, here&#39;s how long that takes to run: . %timeit lp.LazyBitVectorPick(fps,len(fps),thresh) . 41.9 ms ± 262 µs per loop (mean ± std. dev. of 7 runs, 10 loops each) . Let&#39;s look at some of those picked compounds: . Draw.MolsToGridImage([ms[x] for x in picks[:12]],molsPerRow=4) . Just to get a feeling for what&#39;s going on, calculate the similarities between the compounds that have been picked. . from rdkit import DataStructs pickfps = [fps[x] for x in picks] nearest = [] simhist = [] for i,fpi in enumerate(pickfps): tfps = pickfps[:] del tfps[i] sims = DataStructs.BulkTanimotoSimilarity(fpi,tfps) nearest.append(max(sims)) simhist.extend(sims) sorted(nearest,reverse=True)[:10] . [0.3492063492063492, 0.3492063492063492, 0.3492063492063492, 0.3492063492063492, 0.3488372093023256, 0.3488372093023256, 0.3488372093023256, 0.3488372093023256, 0.3488372093023256, 0.3488372093023256] . Remember that we defined a distance threshold of 0.65, so there should be no similarity values above 0.35 here. It&#39;s good to see that this is true. . Here&#39;s the histogram of distances . hist(simhist,bins=20); xlabel(&#39;similarity&#39;); . Now let&#39;s assign points to clusters. As mentioned above, we do that by defining the picked compounds to be the centroids and then assign each other compound in the dataset to the nearest cluster centroid. . We don&#39;t currently have a single call for doing this, so here&#39;s a Python function: . from collections import defaultdict import numpy as np def assignPointsToClusters(picks,fps): clusters = defaultdict(list) for i,idx in enumerate(picks): clusters[i].append(idx) sims = np.zeros((len(picks),len(fps))) for i in range(len(picks)): pick = picks[i] sims[i,:] = DataStructs.BulkTanimotoSimilarity(fps[pick],fps) sims[i,i] = 0 best = np.argmax(sims,axis=0) for i,idx in enumerate(best): if i not in picks: clusters[idx].append(i) return clusters . clusters = assignPointsToClusters(picks,fps) hist([len(clusters[x]) for x in clusters]); xlabel(&#39;cluster size&#39;); . hist([len(clusters[x]) for x in clusters],log=True); xlabel(&#39;cluster size&#39;); . Unfortunately this implementation for assigning compounds to clusters isn&#39;t particularly efficient since it makes a bunch of calls across the Python/C++ interface: . %timeit assignPointsToClusters(picks,fps) . 360 ms ± 10.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) . I hope to have the chance to improve the performance of this step in a future RDKit release. . Looking at the clusters . Let&#39;s look at the compounds inside a couple of clusters in order to see how closely related they seem to be: . clusts12 = [x for x in clusters if len(clusters[x])==12] len(clusts12) . 10 . Draw.MolsToGridImage([ms[x] for x in clusters[clusts12[0]]],molsPerRow=4) . We can also look at the intra-cluster similarities . def intracluster_similarities(cluster,fps): res = [] cfps = [fps[x] for x in cluster] for i,fpid in enumerate(cluster): tres = DataStructs.BulkTanimotoSimilarity(cfps[i],cfps) del tres[i] res.extend(tres) return res . hist(intracluster_similarities(clusters[clusts12[0]],fps)); xlabel(&#39;Similarity&#39;); . Draw.MolsToGridImage([ms[x] for x in clusters[clusts12[1]]],molsPerRow=4) . hist(intracluster_similarities(clusters[clusts12[1]],fps)); xlabel(&#39;Similarity&#39;); . Both clusters are clearly include related compounds . Decreasing the sphere radius . What about if we make the clusters tighter by decreasing the threshold distance? . thresh = 0.35 # &lt;- minimum distance between cluster centroids picks = lp.LazyBitVectorPick(fps,len(fps),thresh) print(len(picks)) . 1832 . clusters = assignPointsToClusters(picks,fps) hist([len(clusters[x]) for x in clusters]); xlabel(&#39;cluster size&#39;); . We&#39;ve got more clusters and they are smaller. No big surprise . And let&#39;s look at a couple of those . clusts12 = [x for x in clusters if len(clusters[x])==12] len(clusts12) . 17 . Draw.MolsToGridImage([ms[x] for x in clusters[clusts12[0]]],molsPerRow=4) . hist(intracluster_similarities(clusters[clusts12[0]],fps)); xlabel(&#39;Similarity&#39;); . Draw.MolsToGridImage([ms[x] for x in clusters[clusts12[1]]],molsPerRow=4) . hist(intracluster_similarities(clusters[clusts12[1]],fps)); xlabel(&#39;Similarity&#39;); . Again, those mostly look quite similar to each other, maybe even more similar than before? . Impact of sphere radius on the number of clusters . Look at the number of clusters as a function of the threshold . results = [] for thresh in arange(0.65,0.05,-0.05): tpicks = lp.LazyBitVectorPick(fps,len(fps),thresh) results.append([thresh,len(tpicks)]) . scatter([x for x,y in results],[y for x,y in results]); ylabel(&#39;number of clusters&#39;) xlabel(&#39;distance threshold&#39;) . Text(0.5, 0, &#39;distance threshold&#39;) . Trying a larger dataset . I said that Roger&#39;s implementation was efficient, but the dataset above wasn&#39;t all that big. Let&#39;s try a larger one. . Here we&#39;ll use the full set of compounds I grabbed data for when building the new &quot;Lessel and Briem&quot; datasets. . As an aside, this is also a nice opportunity to demonstrate using the MultithreadedSmilesMolSupplier that Shrey Aryan added to the RDKit as part of his 2020 Google Summer of Code project. This new supplier allows molecules to be constructed in parallel and can, in some situations, really speed things up. . t1 = time.time() fps = [rdMolDescriptors.GetMorganFingerprintAsBitVect(m,2,2048) for m in Chem.MultithreadedSmilesMolSupplier(&#39;../data/BLSets_actives.txt&#39;,numWriterThreads=4,delimiter=&#39; t&#39;) if m is not None] t2 = time.time() print(f&quot;That took {t2-t1 :.2f} seconds to build {len(fps)} fingerprints&quot;) . That took 6.02 seconds to build 91663 fingerprints . Running that single threaded (i.e. using a normal SmilesMolSupplier) took 16.8 seconds on my machine. . Pick the cluster centroids: . lp = rdSimDivPickers.LeaderPicker() thresh = 0.65 # &lt;- minimum distance between cluster centroids picks = lp.LazyBitVectorPick(fps,len(fps),thresh) print(len(picks)) . 2997 . How long does that take? . %timeit lp.LazyBitVectorPick(fps,len(fps),thresh) . 5.14 s ± 320 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) . t1 = time.time() clusters = assignPointsToClusters(picks,fps) t2=time.time() print(f&quot;That took {t2-t1 :.2f} seconds&quot;) hist([len(clusters[x]) for x in clusters]); xlabel(&#39;cluster size&#39;); . That took 43.34 seconds . And, finally, look at the number of clusters and clustering time as a function of the sphere radius . results = [] for thresh in (0.2,0.3,0.4,0.5,0.6,0.7,0.8): lp = rdSimDivPickers.LeaderPicker() t1 = time.time() picks = lp.LazyBitVectorPick(fps,len(fps),thresh) t2 = time.time() print(f&quot;distance threshold {thresh: .2f}, {len(picks)} clusters in {t2-t1 :.2f} seconds&quot;) results.append((thresh,len(picks),t2-t1)) . distance threshold 0.20, 34535 clusters in 66.25 seconds distance threshold 0.30, 20627 clusters in 37.51 seconds distance threshold 0.40, 11799 clusters in 21.47 seconds distance threshold 0.50, 6811 clusters in 12.48 seconds distance threshold 0.60, 4047 clusters in 7.02 seconds distance threshold 0.70, 2021 clusters in 3.07 seconds distance threshold 0.80, 558 clusters in 0.51 seconds . Those two track nicely with each other; more clusters = longer run time: . fig, ax = subplots() ax.plot([x[0] for x in results],[x[1] for x in results]); ax.set_xlabel(&#39;Sphere radius&#39;); ax.set_ylabel(&#39;Num clusters&#39;); ax2 = ax.twinx() ax2.plot([x[0] for x in results],[x[2] for x in results],c=&#39;r&#39;); ax2.set_ylabel(&#39;Time (s)&#39;); .",
            "url": "https://greglandrum.github.io/rdkit-blog/similarity/tutorial/2020/11/18/sphere-exclusion-clustering.html",
            "relUrl": "/similarity/tutorial/2020/11/18/sphere-exclusion-clustering.html",
            "date": " • Nov 18, 2020"
        }
        
    
  
    
        ,"post25": {
            "title": "Setting up an environment to make Python contributions to the RDKit",
            "content": "It has been tricky to contribute code or documentation to the RDKit if you’re a Python programmer who doesn’t want to deal with the complexities of getting an RDKit build working. We want to make it straightforward for people to contribute, so I’m working on some recipes to make thigs easier. This is the first pass at that. . In order to fix bugs or add features in Python you need to be able to clone a local fork of the RDKit from github, modify the code in that local clone, and then run the local code in order to test it. The problem is that most RDKit functionality requires some binary components that need to be built from C++ and installed in the appropriate places. We’re going to work around that problem here by copying the binary components from a recent binary distribution of the RDKit into a local clone of the RDKit repo. . I’m going to explain each of the required steps, but the complete set of steps required is at the bottom of this post. Assuming that you have the prerequisites (explained directly below), I hope that these will “just work” for you, but one never knows… I’d like to be able to include this in the RDKit documentation, so please me know how it goes if you try the recipe out. Please do not add a comment to this blog post, I’ve created a github issue so that we have the comments in one place. If you don’t have a github account, please email me your comments and I’ll add them to the issue. . The steps explained . At the moment this recipe only works on linux and the mac. I will put together a similar recipe for windows and either do a separate post or update this one. . Prerequisites: . you need to have either anaconda python or miniconda installed and in your path | you need to have git installed and in your path | . You should start by changing into the directory where you want to clone the RDKit source repository and then running: . git clone https://github.com/rdkit/rdkit.git . That will clone the repo from github into a local directory called rdkit. We now change into that directory and use it to set our RDBASE environment variable: . cd rdkit export RDBASE=`pwd` . The next step is to create the conda environment that we’re going to use to hold the RDKit binary components and install a recent beta version of the RDKit into that environment: . conda create -y -n py37_rdkit_beta python=3.7 conda activate py37_rdkit_beta conda install -y -c rdkit/label/beta rdkit . If you have other Python packages that you’d like to work with, go ahead and install them into the environment now. . Next we copy the RDKit binary components from that environment into our local clone of the RDKit repo: . cd $CONDA_PREFIX/lib/python3.7/site-packages/rdkit rsync -a -m --include &#39;*/&#39; --include=&#39;*.so&#39; --include=&#39;inchi.py&#39; --exclude=&#39;*&#39; . $RDBASE/rdkit . NOTE: that rsync command should be one long line. . Finally we set our PYTHONPATH and then test that everything is working by importing the RDKit’s Chem module: . export PYTHONPATH=&quot;$RDBASE&quot; cd $RDBASE/rdkit python -c &#39;from rdkit import Chem;print(Chem.__file__)&#39; . That last command should not generate errors and should show you a filename that is in your local github clone. As an example, I started the first step of this process in my /scratch/rdkit_devel directory, so I see: . /scratch/rdkit_devel/rdkit/rdkit/Chem/__init__.py . Running the tests . If you’re planning on making an RDKit contribution, it’s important to know how to run the Python tests to make sure that your changes work and don’t break anything else. For historic reasons the RDKit uses a self-written framework for running tests, but it’s easy enough to use. You need to run the script $RDBASE/rdkit/TestRunner.py and point it to the test_list.py file containing the tests to be run. For example, if you want to run all the tests in the directory $RDBASE/rdkit/Chem (this corresponds to the python module rdkit.Chem), you would do: . cd $RDBASE/rdkit/Chem python $RDBASE/rdkit/TestRunner.py test_list.py . That will take a while and generate a lot of output, including things that look like exceptions and errors, but should finish with something like: . Script: test_list.py. Passed 40 tests in 69.70 seconds . Finishing up . You’re set. The one thing to remember is that whenever you want to use this environment in a new terminal window or shell, you need to activate the py37_rdkit_beta conda environment (don’t delete it!), set RDBASE, and set your PYTHONPATH: . conda activate py37_rdkit_beta cd your_local_rdkit_clone # &lt;- replace this with the real name of the directory export RDBASE=`pwd` export PYTHONPATH=&quot;$RDBASE&quot; . The recipe . Here’s the complete recipe: . git clone https://github.com/rdkit/rdkit.git cd rdkit export RDBASE=`pwd` conda create -y -n py37_rdkit_beta python=3.7 conda activate py37_rdkit_beta conda install -y -c rdkit/label/beta rdkit cd $CONDA_PREFIX/lib/python3.7/site-packages/rdkit rsync -a -m --include &#39;*/&#39; --include=&#39;*.so&#39; --include=&#39;inchi.py&#39; --exclude=&#39;*&#39; . $RDBASE/rdkit export PYTHONPATH=&quot;$RDBASE&quot; cd $RDBASE/rdkit python -c &#39;from rdkit import Chem;print(Chem.__file__)&#39; .",
            "url": "https://greglandrum.github.io/rdkit-blog/contributing/tutorial/2020/03/30/setting-up-an-environment.html",
            "relUrl": "/contributing/tutorial/2020/03/30/setting-up-an-environment.html",
            "date": " • Mar 30, 2020"
        }
        
    
  
    
        ,"post26": {
            "title": "Finding regioisomers",
            "content": "This is one that came up recently on the mailing list that I thought made for a good example to demonstrate how to write Python to do some more advanced structural searches with the RDKit. . from rdkit import Chem from rdkit.Chem import Draw from rdkit.Chem.Draw import IPythonConsole import rdkit print(rdkit.__version__) . 2019.09.3 . RDKit WARNING: [05:43:19] Enabling RDKit 2019.09.3 jupyter extensions . My paraphrasing of the problem: Alexis wanted to be able to do the equivalent of a substructure search that finds all aromatic rings that have both Cl and Br substituents. So he wanted to be able to match the first two of these, but not the second: . ms = [Chem.MolFromSmiles(x) for x in &#39;Clc1c(Br)cccc1 Clc1cc(Br)ccc1 Clc1cccc2c1c(Br)ccc2&#39;.split()] Draw.MolsToGridImage(ms,legends=&#39;match match no-match&#39;.split()) . It&#39;s really non-trivial to do this with SMARTS since it has no way to express that two atoms should be in the same ring without making the ring explicit in the SMARTS. I was able to come up with this SMARTS, which works, but is unwieldy (at best): . p = Chem.MolFromSmarts(&#39;Cl[c;$(c1(Cl)c(Br)cccc1),$(c1(Cl)cc(Br)ccc1),$(c1(Cl)ccc(Br)cc1)]&#39;) print([m.HasSubstructMatch(p) for m in ms]) . [True, True, False] . So that does what we want, but it only handles six rings where every atom is a C. That second part is easy enough to change in the SMARTS, but handling other ring sizes starts to make the SMARTS really long. . A more difficult problem is that, because we use recursive SMARTS, we can&#39;t get the atoms matching the query. The pattern I used above would only return the Cl atom and the C atom it&#39;s connected to. I&#39;m not sure Alexis even wanted to do that, but by this point I was interested in the problem and decided to write some Python to solve the problem flexibly. . Here we go. . Before introducing the code and showing what it can do, a quick intro on the two pieces of functionality I&#39;m going to be using from Python&#39;s itertools module. These are really useful. . Let&#39;s start with using itertools to flatten a sequence of sequences: . import itertools seqs = [[1,2,3],[&#39;a&#39;,&#39;b&#39;],[10,20]] list(itertools.chain.from_iterable(seqs)) . [1, 2, 3, &#39;a&#39;, &#39;b&#39;, 10, 20] . And to generate all the permutations of combinations of those sequences: . list(itertools.product(*seqs)) . [(1, &#39;a&#39;, 10), (1, &#39;a&#39;, 20), (1, &#39;b&#39;, 10), (1, &#39;b&#39;, 20), (2, &#39;a&#39;, 10), (2, &#39;a&#39;, 20), (2, &#39;b&#39;, 10), (2, &#39;b&#39;, 20), (3, &#39;a&#39;, 10), (3, &#39;a&#39;, 20), (3, &#39;b&#39;, 10), (3, &#39;b&#39;, 20)] . Ok, that&#39;s the background, let&#39;s define the functions we&#39;ll use: . import itertools def getAromaticRings(mol): &quot;&quot;&quot; generator returning all aromatic rings (=only aromatic bonds) in a molecule Parameters - mol : Mol Yields set IDs of the atoms in an aromatic ring &quot;&quot;&quot; ri = mol.GetRingInfo() for ring in ri.BondRings(): ats = set() isArom = True for bi in ring: bnd = mol.GetBondWithIdx(bi) if not bnd.GetIsAromatic(): isArom = False break ats.add(bnd.GetBeginAtomIdx()) ats.add(bnd.GetEndAtomIdx()) if isArom: yield ats def getSharedRings(mol,queries,rings=None,excludeQueries=None): &quot;&quot;&quot; generator returning all rings that contain all the atoms defined in queries the first atom matching each query should be in the ring Parameters - mol : Mol queries : sequence of Mols rings : list/tuple/set of list/tuple/sets, optional sequence of rings defined by sequences of atom ids If this isn&#39;t provided, all of the molecule&#39;s rings will be used excludeQueries : sequence of Mols, optional any ring containing an atom matching the first atom in any of these queries will be excluded Yields - set containing atom IDs for a matching ring &quot;&quot;&quot; if rings is None: rings = mol.GetRingInfo().AtomRings() alreadySeen = [] rings = [set(x) for x in rings] matchSets = [[x[0] for x in mol.GetSubstructMatches(q)] for q in queries] if excludeQueries is not None: exclude = [[x[0] for x in mol.GetSubstructMatches(q)] for q in excludeQueries] # flatten the lists of matches into a set: exclude = set(itertools.chain.from_iterable(exclude)) else: exclude = set() for combo in itertools.product(*matchSets): scombo = set(combo) if len(scombo) &lt; len(combo): # degenerate: continue for ring in rings: if ring in alreadySeen: continue if scombo.issubset(ring) and exclude.isdisjoint(ring): alreadySeen.append(ring) yield ring def drawMolWithRings(mol,rings): &quot;&quot;&quot; draws a molecule with a set of rings highlighted Parameters - mol : Mol rings : list/tuple/set of list/tuple/sets sequence of rings defined by sequences of atom IDs Returns - Image &quot;&quot;&quot; bondsToHighlight=[] for bnd in mol.GetBonds(): keep = False ats = set([bnd.GetBeginAtomIdx(),bnd.GetEndAtomIdx()]) for ring in rings: if ats.issubset(ring): keep = True break if keep: bondsToHighlight.append(bnd.GetIdx()) highlightAtoms = list(itertools.chain.from_iterable(rings)) tmol = Draw.PrepareMolForDrawing(mol) d2d = Draw.MolDraw2DCairo(300, 250) d2d.DrawMolecule(tmol, highlightAtoms=highlightAtoms, highlightBonds = bondsToHighlight) d2d.FinishDrawing() return Draw._drawerToImage(d2d) . This is the molecule we&#39;ll work with: . mol = Chem.MolFromSmiles(&#39;c1c(Cl)cc(Br)c2c1CCc3c2cc(Cl)c4c3CCC(Cl)C4Br&#39;) mol . Show what the getAromaticRings() function returns here: . rings = list(getAromaticRings(mol)) rings . [{0, 1, 3, 4, 6, 7}, {10, 11, 12, 13, 15, 16}] . We can use drawMolWithRings() to highlight those atoms: . drawMolWithRings(mol,rings) . Now let&#39;s look at Alexis&#39; question: find all the aromatic rings that have a Cl and a Br attached: . matches = list(getSharedRings(mol,[Chem.MolFromSmarts(sma) for sma in (&#39;[a]-Cl&#39;,&#39;[a]-Br&#39;)], rings=getAromaticRings(mol))) print(matches) drawMolWithRings(mol,matches) . [{0, 1, 3, 4, 6, 7}] . What about aromatic rings that have both a Cl and an aliphatic C attached? . matches = list(getSharedRings(mol,[Chem.MolFromSmarts(sma) for sma in (&#39;[a]-Cl&#39;,&#39;[a]-C&#39;)], rings=getAromaticRings(mol))) print(matches) drawMolWithRings(mol,matches) . [{0, 1, 3, 4, 6, 7}, {16, 10, 11, 12, 13, 15}] . What about just finding any rings (not just aromatic) that have both Cl and Br connected? . Here we just drop the rings argument to getSharedRings(), it will use all of the molecule&#39;s rings: . matches = list(getSharedRings(mol,[Chem.MolFromSmarts(sma) for sma in (&#39;[*]-Cl&#39;,&#39;[*]-Br&#39;)])) print(matches) drawMolWithRings(mol,matches) . [{0, 1, 3, 4, 6, 7}, {15, 16, 17, 18, 19, 21}] . We can also find any rings that have a Cl, but not a Br: . matches = list(getSharedRings(mol,[Chem.MolFromSmarts(sma) for sma in (&#39;[*]-Cl&#39;,)], excludeQueries=[Chem.MolFromSmarts(sma) for sma in (&#39;[*]-Br&#39;,)])) print(matches) drawMolWithRings(mol,matches) . [{10, 11, 12, 13, 15, 16}] . We aren&#39;t limited to just six membered rings, of course. Go back to the original query for aromatic rings with both Cl and Br attached: . mol = Chem.MolFromSmiles(&#39;Clc1[nH]c(Br)c(c2ccc(Cl)c(Br)c2)c1&#39;) matches = list(getSharedRings(mol,[Chem.MolFromSmarts(sma) for sma in (&#39;[*]-Cl&#39;,&#39;[*]-Br&#39;)], rings=getAromaticRings(mol))) print(matches) drawMolWithRings(mol,matches) . [{1, 2, 3, 5, 14}, {6, 7, 8, 9, 11, 13}] . What about aromatic rings that have both Cl and Br attached, but that don&#39;t contain a heteroatom? . mol = Chem.MolFromSmiles(&#39;Clc1[nH]c(Br)c(c2ccc(Cl)c(Br)c2)c1&#39;) matches = list(getSharedRings(mol,[Chem.MolFromSmarts(sma) for sma in (&#39;[*]-Cl&#39;,&#39;[*]-Br&#39;)], rings=getAromaticRings(mol), excludeQueries=[Chem.MolFromSmarts(sma) for sma in (&#39;[a;!#6]&#39;,)])) print(matches) drawMolWithRings(mol,matches) . [{6, 7, 8, 9, 11, 13}] . Hopefully there&#39;s some useful stuff in here for you! .",
            "url": "https://greglandrum.github.io/rdkit-blog/substructure/tutorial/2020/01/30/finding-regioisomers.html",
            "relUrl": "/substructure/tutorial/2020/01/30/finding-regioisomers.html",
            "date": " • Jan 30, 2020"
        }
        
    
  
    
        ,"post27": {
            "title": "Trying out the new tautomer canonicalization code",
            "content": "During the 2018 RDKit Google Summer of Code (GSoC) project to port MolVS to C++, doing the tautomer enumeration and canonicalization were stretch goals. Susan actually managed to complete the tautomer enumeration, but since canonicalization wasn&#39;t complete, we didn&#39;t publicize this particularly widely. As part of the work for the 2020.03 release, I implemented Matt&#39;s canonicalization scheme and we recently merged that into the RDKit core. Since this is a topic that may be contentious, and since making changes to the canonicalization algorithm post-release will have be done very deliberately, I&#39;d like to collect some feedback before we do the release in a couple of months. . The implementation attempts to exactly duplicate what is currently being done in MolVS. Here&#39;s how Matt describes the process in the MolVS documentation: . Enumerate all possible tautomers using transform rules. | Use scoring system to determine canonical tautomer. | Canonical tautomer should be “reasonable” from a chemist’s point of view, but isn’t guaranteed to be the most energetically favourable. | The scoring scheme: . aromatic ring (defined by all bonds being aromatic) consisting entirely of carbons: 250 points | other aromatic rings : 100 points | a set of substructures are scored (if present). Here&#39;s the current (as of this writing) set of substructures and their associated scores (these are defined here): . {&quot;benzoquinone&quot;, &quot;[#6]1([#6]=[#6][#6]([#6]=[#6]1)=,:[N,S,O])=,:[N,S,O]&quot;, 25}, {&quot;oxim&quot;, &quot;[#6]=[N][OH]&quot;, 4}, {&quot;C=O&quot;, &quot;[#6]=,:[#8]&quot;, 2}, {&quot;N=O&quot;, &quot;[#7]=,:[#8]&quot;, 2}, {&quot;P=O&quot;, &quot;[#15]=,:[#8]&quot;, 2}, {&quot;C=hetero&quot;, &quot;[#6]=[!#1;!#6]&quot;, 1}, {&quot;methyl&quot;, &quot;[CX4H3]&quot;, 1}, {&quot;guanidine terminal=N&quot;, &quot;[#7][#6](=[NR0])[#7H0]&quot;, 1}, {&quot;guanidine endocyclic=N&quot;, &quot;[#7;R][#6;R]([N])=[#7;R]&quot;, 2}, {&quot;aci-nitro&quot;, &quot;[#6]=[N+]([O-])[OH]&quot;, -4}}; . | one point is subtracted for each H attached to P, S, Se, or Te . | . The highest scoring tautomer is selected. In the event of ties, the tautomer with the lexicographically smaller canonical SMILES is picked. . If this is something you feel strongly about, please try the code out and see what you think. If you see behavior you really don&#39;t like, or that you think is a bug, please add a comment to the associated issue in github: https://github.com/rdkit/rdkit/issues/2908 (preferred) or reply to the thread that I will create on the rdkit-discuss mailing list. . Remember that the goal of the exercise here is not to produce the &quot;best&quot; tautomer, but to produce a canonical one (always the same result for molecules which are tautomerically equivalent). We hope that this is also reasonable - in that it doesn&#39;t make a chemist&#39;s eyes burn - but that&#39;s not the primary goal. . So how can you try it out? . This is C++ code, so you need an RDKit build done from the github master. I&#39;ve done conda builds and made them available for people to try. . At the moment I&#39;ve only built the beta version for python 3.7 on linux and windows. If you would like to do some testing on the Mac, let me know and I can do a build there too. . Here&#39;s how to setup a conda environment to use the beta: . % conda create -n py37_tautomer_beta python=3.7 jupyter % conda activate py37_tautomer_beta % conda install -c rdkit/label/beta rdkit . Ok, let&#39;s look at some examples: . from rdkit import Chem from rdkit.Chem.Draw import IPythonConsole from rdkit.Chem import Draw import rdkit print(rdkit.__version__) . 2020.03.1dev1 . RDKit WARNING: [11:00:33] Enabling RDKit 2020.03.1dev1 jupyter extensions . from rdkit.Chem.MolStandardize import rdMolStandardize . enumerator = rdMolStandardize.TautomerEnumerator() . m = Chem.MolFromSmiles(&#39;Oc1c(cccc3)c3nc2ccncc12&#39;) m . Get the canonical tautomer: . enumerator.Canonicalize(m) . The canonicalizer starts by enumerating a molecule&#39;s tautomers. If you want to see those, you can use the Enumerate() method: . tauts = enumerator.Enumerate(m) Draw.MolsToGridImage(tauts) . I find this function, which reorders the list of tautomers so that the canonical one is in the first position, really useful: . def reorderTautomers(m): enumerator = rdMolStandardize.TautomerEnumerator() canon = enumerator.Canonicalize(m) csmi = Chem.MolToSmiles(canon) res = [canon] tauts = enumerator.Enumerate(m) smis = [Chem.MolToSmiles(x) for x in tauts] stpl = sorted((x,y) for x,y in zip(smis,tauts) if x!=csmi) res += [y for x,y in stpl] return res . So now we can display all the tautomers found for a molecule. The first one drawn is the canonical one: . Draw.MolsToGridImage(reorderTautomers(m)) . Draw.MolsToGridImage(reorderTautomers(Chem.MolFromSmiles(&#39;CN=c1nc[nH]cc1&#39;))) . Draw.MolsToGridImage(reorderTautomers(Chem.MolFromSmiles(&#39;CC=CO&#39;))) . As an aside, it&#39;s worth noticing that double bond stereochemistry is removed in all tautomers if the double bond is involved in the tautomerization: . m = Chem.MolFromSmiles(&#39;C/C=C(/O)F&#39;) tauts = reorderTautomers(m) print(&#39;Original SMILES:&#39;,Chem.MolToSmiles(m)) print(&#39;Tautomers (canonical first):&#39;,[Chem.MolToSmiles(x) for x in tauts]) . Original SMILES: C/C=C(/O)F Tautomers (canonical first): [&#39;CCC(=O)F&#39;, &#39;CC=C(O)F&#39;] .",
            "url": "https://greglandrum.github.io/rdkit-blog/prototypes/technical/2020/01/25/trying-the-tautomer-canonicalization-code.html",
            "relUrl": "/prototypes/technical/2020/01/25/trying-the-tautomer-canonicalization-code.html",
            "date": " • Jan 25, 2020"
        }
        
    
  
    
        ,"post28": {
            "title": "Some thoughts on the performance of the RDKit cartridge",
            "content": "EDITED on 23.01.2020 John Mayfield pointed out that the way I had constructed the set of 10 million molecules wasn’t reproducible. This update fixes that, but it also changes the results. . It’s been a while since I did a post about the cartridge! This one is a little bit ranty, but hopefully it’s still useful. . Some background and disclaimers . I normally do performance testing on the cartridge using ChEMBL, but since that’s “only” around 1.7 million compounds I wanted to try something a bit bigger. But how big? I don’t see the point in shoving 100 million compounds (or a billion) into PostgreSQL (there’s a mini-rant explaining this at the bottom of the post), so I went with 10 million. That’s more than five times bigger than ChEMBL, but it’s still not unimaginable that you’d actually have a relational schema with a molecule table this size that has data about most of those molecules in separate tables (again, see the mini-rant). . My goal here is to get a sense for what kind of performance you can expect for doing “normal” chemical queries using a local PostgreSQL instance without having to spend time optimizing the database or hardware configuration. I generated all the numbers below on my Linux desktop - which is 4-5 years old at this point - using an out-of-the-box install of PostgreSQL 12 (the only configuration tuning was to increase the size of shared_buffers to 4096M and work_mem as described in the RDKit docs). I was also using the machine for other things (like reading email or writing this post in Chrome) while these queries ran, so the numbers are really just ballpark estimates. . So which molecules to use? Rather than agonizing overly much about this, I just grabbed a PubChem Compound SMILES dump and took the first 10 million molecules from that. . I hedged above by saying “normal” chemical queries. I have a longer rant about that topic that I will spare you the details of, but I generally think that including worst-case queries (i.e. things that return tens or hundreds of thousands of rows) in real-world benchmarking examples is pointless. It’s definitely useful to understand the worst-case performance of a system, but that’s not what I’m doing here. So my queries will often limit the number of rows returned to what I think is a “reasonable” number for interactive usage. . Creating the database . This tends to be time consuming, particularly creating the molecule index. Start by creating the database from the command line and loading all of the raw data: . glandrum@otter:/tmp/pubchem_load$ createdb pubchem_compound glandrum@otter:/tmp/pubchem_load$ psql -c &#39;create extension rdkit&#39; pubchem_compound CREATE EXTENSION glandrum@otter:/tmp/pubchem_load$ psql -c &#39;create table raw_data (id SERIAL,cid integer, smiles text)&#39; pubchem_compound CREATE TABLE glandrum@otter:/tmp/pubchem_load$ zcat CID-SMILES.gz | sed &#39;s/ / /g&#39; | psql -c &quot;copy raw_data (cid,smiles) from stdin with delimiter E&#39; t&#39;&quot; pubchem_compound COPY 102397130 . Now create the molecule table and build the index: . pubchem_compound=# alter table raw_data add primary key (cid); ALTER TABLE pubchem_compound=# timing Timing is on. pubchem_compound=# select * into mols from (select cid,mol_from_smiles(smiles::cstring) m from raw_data order by cid limit 10000000) tmp where m is not null; ... lots of info about failing molecules deleted here WARNING: could not create molecule from SMILES &#39;[B+]12(CC3CC(C1)CC(C2)C3)NCC[O-]&#39; WARNING: could not create molecule from SMILES &#39;[B+]12(CC3CC(C1)CC(C2)C3)NCCO&#39; SELECT 9999165 Time: 1722464.775 ms (28:42.465) pubchem_compound=# create index molidx on mols using gist(m); CREATE INDEX Time: 3735718.147 ms (01:02:15.718) . Add fingerprints and their index along with the primary keys we’ll use to link things: . pubchem_compound=# create index fps_mfp2_idx on fps using gist(mfp2); CREATE INDEX Time: 155112.279 ms (02:35.112) pubchem_compound=# alter table mols add primary key (cid); ALTER TABLE Time: 44271.680 ms (00:44.272) pubchem_compound=# alter table fps add primary key (cid); ALTER TABLE Time: 27675.441 ms (00:27.675) . Now let’s do some queries. . Substructure queries . Note that all of the results below are done with a “warm” disk cache: I ran a substructure search and similarity search to try and ensure that at least parts of the indices are being cached by the operating system. . Picking the queries for a demo is always tricky, and can obviously completely slant the results one way or another, so I went to the ASAP page for J Med Chem and pulled stuff from there. . Let’s start with a query for parts of the “head” and “gate” from this paper: https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b01912 . pubchem_compound=# select * from mols where m@&gt;&#39;CC1=C(C=C(C=C1)C(N)=O)C#CC1=CN=CC=C1&#39; limit 10; cid | m -+- 11526637 | Cc1ccc(C(=O)Nc2cc(OC[C@@H]3CCCN3C)cc(C(F)(F)F)c2)cc1C#Cc1cnc2nc[nH]c2c1 (1 row) Time: 5359.046 ms (00:05.359) . Here’s the one hit: . . Now the core from: https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b01427 . pubchem_compound=# select * from mols where m@&gt;&#39;CC1=CC2=C(S1)C(=O)NC(C)=N2&#39; limit 10; cid | m -+ 3758971 | CCOC(=O)C1CCCn2c1nc1cc(-c3ccccc3)sc1c2=O 10622152 | COc1ccc(NC(=S)Nn2c(C)nc3cc(-c4ccccc4)sc3c2=O)cc1 1040399 | COC(=O)[C@@H]1CCc2nc3cc(-c4ccc(OC)cc4)sc3c(=O)n21 1040400 | COC(=O)[C@H]1CCc2nc3cc(-c4ccc(OC)cc4)sc3c(=O)n21 3310123 | O=c1c2sc(-c3ccccc3)cc2nc2n1CCCCC2 4376566 | CCOC(=O)C1CCCn2c1nc1cc(-c3ccc(OC)cc3)sc1c2=O 10574247 | COc1ccccc1NC(=S)Nn1c(C)nc2cc(-c3ccccc3)sc2c1=O 11404362 | Cc1cc2nc(-c3ccccc3)n(-c3ccccc3)c(=O)c2s1 10716322 | Cc1cccc(NC(=S)Nn2c(C)nc3cc(-c4ccccc4)sc3c2=O)c1 661611 | COc1ccc(-c2cc3nc4n(c(=O)c3s2)CCOC4)cc1 (10 rows) Time: 6.532 ms . And the results: . . And, finally, the core from: https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b01684 . pubchem_compound=# select * from mols where m@&gt;&#39;CN1C(=O)N(C)C2=C1C=NC(N)=N2&#39; limit 10; cid | m -+ 10359733 | C=CCn1c(=O)n(CCCCCCCC)c2nc(N)nc(Cl)c21 10452174 | Nc1nc2c(c(=O)n1N)n(CCCl)c(=O)n2[C@@H]1O[C@H](CO)[C@@H](O)[C@H]1O 10048317 | Nc1nc2c(c(=O)n1N)n(C/C=C/c1ccccc1)c(=O)n2[C@@H]1O[C@H](CO)[C@@H](O)[C@H]1O 10454396 | [N-]=[N+]=NCC(O)Cn1c(=O)n([C@@H]2O[C@H](CO)[C@@H](O)[C@H]2O)c2nc(N)n(N)c(=O)c21 10476329 | Nc1nc2c(c(=O)n1N)n(Cc1ccccc1)c(=O)n2[C@@H]1O[C@H](CO)[C@@H](O)[C@H]1O 11428584 | C=CCn1c(=O)n([C@@H]2O[C@H](CO)[C@@H](O)[C@H]2O)c2nc(N)nc(OCC)c21 11453816 | C=CCn1c(=O)n([C@@H]2O[C@H](CO)[C@@H](O)[C@H]2O)c2nc(N)nc(OCN(C)C(=O)OCC)c21 9980347 | COc1ccc(Cn2c(=O)n([C@@H]3O[C@H](CO)[C@@H](O)[C@H]3O)c3nc(N)n(N)c(=O)c32)cc1 10085856 | Cn1c(=O)n2c3c1c(=O)nc(N)n3C[C@H]1O[C@@H]2[C@H](O)[C@@H]1O 9994808 | C=CCn1c(=O)n(CCCCO)c2nc(N)nc(Cl)c21 (10 rows) Time: 107.934 ms . And the first results: . . These queries are, in general, pretty quick. I’m certainly likely to spend more time looking at the results than I am waiting for them to come back. . One point it’s worth making is that queries that don’t return any results tend to be pretty fast. Here’s an example of that: . pubchem_compound=# select * from mols where m@&gt;&#39;O1C=NC2=C1N=C1N=CN=CC1=N2&#39; limit 5; cid | m --+ (0 rows) Time: 9.778 ms . Note that this is definitely not always true… the index does not work particularly well for queries that have massively repeating common substructures: . pubchem_compound=# select * from mols where m@&gt;&#39;COCOCOCOCOCOCOCOCOCOCOCOCOCOCOCOCOCOCCOCOCOCOCOCCO&#39; limit 5; cid | m --+ (0 rows) Time: 150521.647 ms (02:30.522) . Remember what I said about about worst-case performance? There ya go. . Similarity queries . Now let’s do some similarity searches using the molecule drawn in the graphical abstract as queries. For this blog post I’m going to use the cartridge’s “neighbor” operator &lt;%&gt; to order the results and allow the N closest neighbors of each query molecule to be retrieved. Here’s the simple SQL function that I use for doing that: . pubchem_compound=# pubchem_compound=# create or replace function get_mfp2_neighbors2(smiles text) returns table(cid integer, m mol, similarity double precision) as $$ select cid,m,tanimoto_sml(morganbv_fp(mol_from_smiles($1::cstring)),mfp2) as similarity from fps join mols using (cid) order by morganbv_fp(mol_from_smiles($1::cstring))&lt;%&gt;mfp2; $$ language sql stable ; . That’s adapted from the function get_mfp2_neighbors that is in the RDKit cartridge documentation. . Let’s start with a query for the five nearest neighbors of balovaptan (https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b01478): . pubchem_compound=# select * from get_mfp2_neighbors2(&#39;CN1CC2=NN=C(C3CCC(CC3)OC3=CC=CC=N3)N2C2=CC=C(Cl)C=C2C1&#39;) limit 5; cid | m | similarity -+-+-- 11237434 | CN1Cc2cc(Cl)ccc2-n2c(nnc2C2CCN(c3ccccn3)CC2)C1 | 0.7049180327868853 11237433 | CN1Cc2cc(Cl)ccc2-n2c(nnc2C2CCN(c3ccccn3)CC2)C1.Cl.Cl.Cl | 0.6935483870967742 10070061 | CN1CCc2cc(Cl)ccc2-n2c(nnc2C2CCN(c3ccccn3)CC2)C1 | 0.6212121212121212 11270862 | Cc1ccccc1CC(=O)N1CCC(c2nnc3n2-c2ccc(Cl)cc2CN(C)C3)CC1 | 0.5797101449275363 11442570 | CN1Cc2cc(Cl)ccc2-n2c(nnc2C2CCN(C(=O)c3c[nH]c4ccccc34)CC2)C1 | 0.5774647887323944 (5 rows) Time: 239.879 ms . It’s easy (and quick) to expand that to the ten nearest neighbors: . pubchem_compound=# select * from get_mfp2_neighbors2(&#39;CN1CC2=NN=C(C3CCC(CC3)OC3=CC=CC=N3)N2C2=CC=C(Cl)C=C2C1&#39;) limit 10; cid | m | similarity -+-+-- 11237434 | CN1Cc2cc(Cl)ccc2-n2c(nnc2C2CCN(c3ccccn3)CC2)C1 | 0.7049180327868853 11237433 | CN1Cc2cc(Cl)ccc2-n2c(nnc2C2CCN(c3ccccn3)CC2)C1.Cl.Cl.Cl | 0.6935483870967742 10070061 | CN1CCc2cc(Cl)ccc2-n2c(nnc2C2CCN(c3ccccn3)CC2)C1 | 0.6212121212121212 11270862 | Cc1ccccc1CC(=O)N1CCC(c2nnc3n2-c2ccc(Cl)cc2CN(C)C3)CC1 | 0.5797101449275363 11442570 | CN1Cc2cc(Cl)ccc2-n2c(nnc2C2CCN(C(=O)c3c[nH]c4ccccc34)CC2)C1 | 0.5774647887323944 11486399 | CN1Cc2cc(Cl)ccc2-n2c(nnc2C2CCN(C(=O)CC3CC3)CC2)C1 | 0.5757575757575758 11349733 | CCCC(=O)N1CCC(c2nnc3n2-c2ccc(Cl)cc2CN(C)C3)CC1 | 0.5757575757575758 11305733 | CN1Cc2cc(Cl)ccc2-n2c(nnc2C2CCN(C(=O)c3cc4ccccc4[nH]3)CC2)C1 | 0.5694444444444444 11166614 | CN1Cc2cc(Cl)ccc2-n2c(nnc2C2CCN(C(=O)C3(C)CCCCC3)CC2)C1 | 0.5671641791044776 10028677 | CN1CCOC(CN2Cc3cc(Cl)ccc3-n3c(nnc3C3CCN(c4ccccn4)CC3)C2)C1 | 0.5616438356164384 (10 rows) Time: 189.425 ms . Here are the first few of those, along with the similarity values: . . The five nearest neighbors for AZD7648 (https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b01684) aren’t particularly similar: . pubchem_compound=# select * from get_mfp2_neighbors2(&#39;CN1C(=O)N(C2CCOCC2)C2=C1C=NC(NC1=CN3N=CN=C3C=C1C)=N2&#39;) limit 5; cid | m | similarity -+--+ 11504903 | Cn1c(=O)c(=O)n(C2CCCC2)c2nc(Nc3ccc(C(=O)NC4CCC(N5CCOCC5)CC4)cc3)ncc21 | 0.4166666666666667 11406590 | Cn1c(=O)c(Oc2ccc(F)cc2F)cc2cnc(NC3CCOCC3)nc21 | 0.3924050632911392 10230233 | Cc1cc(=O)n(C2CCCC2)c2nc(Nc3ccc(N4CCC(CCCN5CCOCC5)CC4)cc3)ncc12 | 0.3595505617977528 9801449 | Cc1nc2cnc(Nc3ccc(N4CCOCC4)cc3)nc2n(C2CCCC2)c1=O | 0.35443037974683544 10224126 | Cc1cc(=O)n(C2CCCC2)c2nc(Nc3ccc(N4CCOCC4)c(F)c3)ncc12 | 0.3488372093023256 (5 rows) Time: 219.653 ms . As we can see: . . The performance of these queries isn’t quite as good as what you can do with specialized open-source tools like chemfp, gpusimilarity, or FPSim2, but I think it’s reasonable for retrieving a set of neighbors that I’m then going to do (probably more time consuming) further analysis on. . Note that the similarity queries were considerably slower in the original version of this blog post. This was likely due to me doing a bad job of warming up the disk cache. . Some technical details: . Sizes of the tables and indices . pubchem_compound=# d+ List of relations Schema | Name | Type | Owner | Size | Description --+--+-+-++- public | fps | table | glandrum | 964 MB | public | mols | table | glandrum | 4236 MB | public | raw_data | table | glandrum | 9091 MB | public | raw_data_id_seq | sequence | glandrum | 8192 bytes | (4 rows) pubchem_compound=# di+ List of relations Schema | Name | Type | Owner | Table | Size | Description --++-+-+-++- public | fps_mfp2_idx | index | glandrum | fps | 1226 MB | public | fps_pkey | index | glandrum | fps | 214 MB | public | molidx | index | glandrum | mols | 4060 MB | public | mols_pkey | index | glandrum | mols | 214 MB | public | raw_data_pkey | index | glandrum | raw_data | 2193 MB | (5 rows) . Performance of the substructure indices . Here are results for the substructure queries executed above. For the purposes of this analysis I removed the limit on the query: . pubchem_compound=# explain analyze select * from mols where m@&gt;&#39;CC1=C(C=C(C=C1)C(N)=O)C#CC1=CN=CC=C1&#39;; QUERY PLAN Bitmap Heap Scan on mols (cost=2157.91..37897.03 rows=9999 width=398) (actual time=167.546..168.902 rows=1 loops=1) Recheck Cond: (m @&gt; &#39;Cc1ccc(C(N)=O)cc1C#Cc1cccnc1&#39;::mol) Rows Removed by Index Recheck: 328 Heap Blocks: exact=309 -&gt; Bitmap Index Scan on molidx (cost=0.00..2155.41 rows=9999 width=0) (actual time=137.703..137.703 rows=329 loops=1) Index Cond: (m @&gt; &#39;Cc1ccc(C(N)=O)cc1C#Cc1cccnc1&#39;::mol) Planning Time: 0.119 ms Execution Time: 169.178 ms (8 rows) pubchem_compound=# explain analyze select * from mols where m@&gt;&#39;CC1=CC2=C(S1)C(=O)NC(C)=N2&#39;; QUERY PLAN -- Bitmap Heap Scan on mols (cost=2157.91..37897.03 rows=9999 width=398) (actual time=436.998..510.558 rows=46 loops=1) Recheck Cond: (m @&gt; &#39;Cc1nc2cc(C)sc2c(=O)[nH]1&#39;::mol) Rows Removed by Index Recheck: 14 Heap Blocks: exact=55 -&gt; Bitmap Index Scan on molidx (cost=0.00..2155.41 rows=9999 width=0) (actual time=436.902..436.902 rows=60 loops=1) Index Cond: (m @&gt; &#39;Cc1nc2cc(C)sc2c(=O)[nH]1&#39;::mol) Planning Time: 0.113 ms Execution Time: 510.801 ms (8 rows) pubchem_compound=# explain analyze select * from mols where m@&gt;&#39;CN1C(=O)N(C)C2=C1C=NC(N)=N2&#39;; QUERY PLAN - Bitmap Heap Scan on mols (cost=2157.91..37897.03 rows=9999 width=398) (actual time=5111.590..5113.136 rows=38 loops=1) Recheck Cond: (m @&gt; &#39;Cn1c(=O)n(C)c2nc(N)ncc21&#39;::mol) Rows Removed by Index Recheck: 10 Heap Blocks: exact=48 -&gt; Bitmap Index Scan on molidx (cost=0.00..2155.41 rows=9999 width=0) (actual time=5081.767..5081.768 rows=48 loops=1) Index Cond: (m @&gt; &#39;Cn1c(=O)n(C)c2nc(N)ncc21&#39;::mol) Planning Time: 0.058 ms Execution Time: 5113.296 ms (8 rows) . All of those show that the index is doing a reasonably good job of pruning compounds - the worst case query (the first one) only ends up trying at 329 substructure queries (instead of 10 million!) to find the 1 actual match. . Warming up the disk cache . There are tons of ways to do this. Here’s the approach I used for this post: . pubchem_compound=# select cid,mol_murckoscaffold(m) scaff into temporary table scaffs from mols order by cid desc limit 10; SELECT 10 pubchem_compound=# select count(*) from mols cross join scaffs where mols.m@&gt;scaffs.scaff; count -- 178828 (1 row) pubchem_compound=# select * into blah from fps order by cid desc limit 10; SELECT 10 pubchem_compound=# select count(*) from fps cross join blah where blah.mfp2%fps.mfp2; count - 401 (1 row) . That takes ~10 minutes to run for me. . Doing the queries and making the images . Since I’m not doing this one from a jupyter notebook, here’s the code snippet I’m using in jupyter to do the substructure queries and display the results: . q=&#39;CN1C(=O)N(C)C2=C1C=NC(N)=N2&#39; t1=time.time() d = %sql postgresql://localhost/pubchem_compound select * from mols where m@&gt;:q limit 10; t2 = time.time() print(f&#39;{t2-t1:.2f} seconds&#39;) ms = [Chem.MolFromSmiles(x) for x in [q]+[x[1] for x in d]] ls = [&#39;query&#39;]+[str(x[0]) for x in d] Draw.MolsToGridImage(ms[:8],legends=ls,molsPerRow=4) . And the equivalent thing for nearest-neighbor queries: . q=&#39;CN1CC2=NN=C(C3CCC(CC3)OC3=CC=CC=N3)N2C2=CC=C(Cl)C=C2C1&#39; t1=time.time() d = %sql postgresql://localhost/pubchem_compound select * from get_mfp2_neighbors2(:q) limit 10; t2 = time.time() print(f&#39;{t2-t1:.2f} seconds&#39;) ms = [Chem.MolFromSmiles(x) for x in [q]+[x[1] for x in d]] ls = [&#39;query&#39;]+[f&#39;{x[0]} {x[2] :.2f}&#39; for x in d] Draw.MolsToGridImage(ms[:8],legends=ls,molsPerRow=4) . Both of these are using the fantastic sql-magic for jupyter from Catherine Devlin. . Mini-rant . PostgreSQL is a general purpose relational database, it lets you store collections of tables with links (relations) between them and makes it easy to do queries that combine data across tables. If you have data on a bunch of molecules that can’t be logically captured in a single table (like ChEMBL!), a relational database is a great place to put that. If you have a single table with a bunch of columns (i.e. molecules and values or fingerprints computed from them), you may want to look to another type of system. If you have a huge number of rows that you are really only interested in doing chemical queries (substructure and similarity searches) against, and you care about performance, then you almost certainly should be using a specialized system. There are plenty to choose from! .",
            "url": "https://greglandrum.github.io/rdkit-blog/cartridge/2020/01/21/some-thoughts-on-cartridge-performance.html",
            "relUrl": "/cartridge/2020/01/21/some-thoughts-on-cartridge-performance.html",
            "date": " • Jan 21, 2020"
        }
        
    
  
    
        ,"post29": {
            "title": "Similarity maps with the new drawing code",
            "content": "As part of the 2019.09 release we added a C++ implementation of the RDKit&#39;s similarity map functionality (https://jcheminf.biomedcentral.com/articles/10.1186/1758-2946-5-43). I forgot to mention this during the &quot;What&#39;s New&quot; bit of my presentation at the UGM, but I think it&#39;s worth calling attention to. So here&#39;s a quick blog post. . from rdkit import Chem from rdkit.Chem import Draw from rdkit.Chem.Draw import SimilarityMaps from IPython.display import SVG import io from PIL import Image import numpy as np import rdkit print(rdkit.__version__) . RDKit WARNING: [11:53:45] Enabling RDKit 2019.09.2 jupyter extensions . 2019.09.2 . I start by using &quot;classic&quot; similarity map functionality to show why atorvastatin (Lipitor) and rosuvastatin (Crestor) are similar to each other when using the Morgan fingerprint. . Here are the two molecules: . atorvastatin = Chem.MolFromSmiles(&#39;O=C(O)C[C@H](O)C[C@H](O)CCn2c(c(c(c2c1ccc(F)cc1)c3ccccc3)C(=O)Nc4ccccc4)C(C)C&#39;) rosuvastatin = Chem.MolFromSmiles(&#39;OC(=O)C[C@H](O)C[C@H](O) C=C c1c(C(C)C)nc(N(C)S(=O)(=O)C)nc1c2ccc(F)cc2&#39;) Draw.MolsToGridImage((atorvastatin,rosuvastatin)) . To use the new drawing code, we create a Draw2D object and pass that to SimilarityMaps.GetSimilarityMapForFingerprint: . def show_png(data): bio = io.BytesIO(data) img = Image.open(bio) return img . d = Draw.MolDraw2DCairo(400, 400) _, maxWeight = SimilarityMaps.GetSimilarityMapForFingerprint(atorvastatin, rosuvastatin, lambda m, i: SimilarityMaps.GetMorganFingerprint(m, i, radius=2, fpType=&#39;bv&#39;), draw2d=d) d.FinishDrawing() show_png(d.GetDrawingText()) . We can do the same thing with count-based fingerprints: . d = Draw.MolDraw2DCairo(400, 400) _, maxWeight = SimilarityMaps.GetSimilarityMapForFingerprint(atorvastatin, rosuvastatin, lambda m, i: SimilarityMaps.GetMorganFingerprint(m, i, radius=2, fpType=&#39;count&#39;), draw2d=d) d.FinishDrawing() show_png(d.GetDrawingText()) . The other GetSimilarityMapFrom... functions also accept the optional draw2d argument. Here&#39;s a visualization of the contributions made by the atoms in atorvastatin to its calculatied logp value: . from rdkit.Chem import rdMolDescriptors ator_contribs = rdMolDescriptors._CalcCrippenContribs(atorvastatin) d = Draw.MolDraw2DCairo(400, 400) SimilarityMaps.GetSimilarityMapFromWeights(atorvastatin,[x[0] for x in ator_contribs],draw2d=d) d.FinishDrawing() show_png(d.GetDrawingText()) . And a couple more visualizations of various partial charge schemes. . Starting with Gasteiger-Marsilli charges: . from rdkit.Chem import rdPartialCharges rdPartialCharges.ComputeGasteigerCharges(atorvastatin) chgs = [x.GetDoubleProp(&quot;_GasteigerCharge&quot;) for x in atorvastatin.GetAtoms()] d = Draw.MolDraw2DCairo(400, 400) SimilarityMaps.GetSimilarityMapFromWeights(atorvastatin,chgs,draw2d=d) d.FinishDrawing() show_png(d.GetDrawingText()) . And also the partial charges calculated with extended Hueckel theory (eHT) using Mulliken analysis: . from rdkit.Chem import rdEHTTools from rdkit.Chem import rdDistGeom mh = Chem.AddHs(atorvastatin) rdDistGeom.EmbedMolecule(mh) _,res = rdEHTTools.RunMol(mh) static_chgs = res.GetAtomicCharges()[:atorvastatin.GetNumAtoms()] d = Draw.MolDraw2DCairo(400, 400) SimilarityMaps.GetSimilarityMapFromWeights(atorvastatin,list(static_chgs),draw2d=d) d.FinishDrawing() show_png(d.GetDrawingText()) . As one final demo, I&#39;ll use the method to visualize the variability of the eHT charges with conformation for atorvastatin. . Start by generating 10 diverse conformers, calculating the charges for each, and plotting the average: . mh = Chem.AddHs(atorvastatin) ps = rdDistGeom.ETKDGv2() ps.pruneRmsThresh = 0.5 ps.randomSeed = 0xf00d rdDistGeom.EmbedMultipleConfs(mh,10,ps) print(f&#39;Found {mh.GetNumConformers()} conformers&#39;) chgs = [] for conf in mh.GetConformers(): _,res = rdEHTTools.RunMol(mh,confId=conf.GetId()) chgs.append(res.GetAtomicCharges()[:atorvastatin.GetNumAtoms()]) chgs = np.array(chgs) mean_chgs = np.mean(chgs,axis=0) std_chgs = np.std(chgs,axis=0) d = Draw.MolDraw2DCairo(400, 400) SimilarityMaps.GetSimilarityMapFromWeights(atorvastatin,list(mean_chgs),draw2d=d) d.FinishDrawing() show_png(d.GetDrawingText()) . Found 10 conformers . That doesn&#39;t look hugely different from what we saw above. . To show the variability, plot the standard deviation of the charges across the 10 conformers: . print(std_chgs) print(max(std_chgs),min(std_chgs)) d = Draw.MolDraw2DCairo(400, 400) SimilarityMaps.GetSimilarityMapFromWeights(atorvastatin,list(std_chgs),draw2d=d) d.FinishDrawing() show_png(d.GetDrawingText()) . [0.01292592 0.00743163 0.01971312 0.01433223 0.01063085 0.01283745 0.01219511 0.00748435 0.01234194 0.01492494 0.00640842 0.02264999 0.02481744 0.00987842 0.00843151 0.01289956 0.00560632 0.00498617 0.00604883 0.005569 0.00452067 0.00796675 0.00718033 0.00581337 0.00702613 0.00634237 0.00699789 0.00539868 0.00521868 0.02412709 0.03131741 0.03709349 0.00657276 0.01175903 0.00674661 0.01012909 0.0050995 0.01139418 0.00831795 0.00581207 0.00960073] 0.03709348867462464 0.00452067345998171 . The deviations aren&#39;t huge (the printed array shows that), but the largest value is clearly the amide N. . There&#39;s definitely a ToDo here to improve the way the negative contours are drawn so that the fact that they are being drawn with dashed lines is visible. .",
            "url": "https://greglandrum.github.io/rdkit-blog/tutorial/2020/01/03/similarity-maps-with-new-drawing-code.html",
            "relUrl": "/tutorial/2020/01/03/similarity-maps-with-new-drawing-code.html",
            "date": " • Jan 3, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About this blog",
          "content": "The repo with the original Jupyter notebooks and data is here . The hub for information about the RDKit is rdkit.org . If you’re an Anaconda Python user, installing the RDKit is as simple as conda install -c conda-forge rdkit . Professional support and services for the RDKit are provided by T5 Informatics GmbH. Contact us if you are interested in RDKit support. . . This blog is powered by fastpages. .",
          "url": "https://greglandrum.github.io/rdkit-blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  

  
  

  
      ,"page11": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://greglandrum.github.io/rdkit-blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}